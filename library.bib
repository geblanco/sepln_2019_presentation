Automatically generated by Mendeley Desktop 1.19.5
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Zou2014,
abstract = {RDF question/answering (Q/A) allows users to ask questions in natural languages over a knowledge base represented by RDF. To answer a national language question, the existing work takes a two-stage approach: question understanding and query evaluation. Their focus is on question understanding to deal with the disambiguation of the natural language phrases. The most common technique is the joint disambiguation, which has the exponential search space. In this paper, we propose a systematic framework to answer nat-ural language questions over RDF repository (RDF Q/A) from a graph data-driven perspective. We propose a semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is reduced to subgraph matching problem. More importantly, we resolve the ambiguity of natural language questions at the time when matches of query are found. The cost of disambiguation is saved if there are no matching found. We compare our method with some state-of-the-art RDF Q/A systems in the benchmark dataset. Extensive experi-ments confirm that our method not only improves the precision but also speeds up query performance greatly.},
author = {Zou, Lei and Huang, Ruizhe and Wang, Haixun and Yu, Jeffrey Xu and He, Wenqiang and Zhao, Dongyan},
doi = {10.1145/2588555.2610525},
file = {:home/gb/Downloads/Telegram Desktop/Zouetal{\_}Unknown{\_}NaturalLanguageQ.pdf:pdf;:home/gb/Documents/Docs/papers/zou2018{\_}review/zou2018{\_}review.pdf:pdf},
title = {{Natural Language Question Answering over RDF — A Graph Data Driven Approach}},
year = {2014}
}
@article{French1999,
author = {French, R},
doi = {10.1016/S1364-6613(99)01294-2},
file = {:home/gb/Downloads/Catastrophic{\_}forgetting{\_}in{\_}connectionist{\_}networks.pdf:pdf},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
month = {apr},
number = {4},
pages = {128--135},
title = {{Catastrophic forgetting in connectionist networks}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661399012942},
volume = {3},
year = {1999}
}
@article{liu2013,
author = {Liu, Miao and Wang, Mingjun and Wang, Jun and Li, Duo},
doi = {10.1016/J.SNB.2012.11.071},
issn = {0925-4005},
journal = {Sensors and Actuators B: Chemical},
month = {feb},
pages = {970--980},
publisher = {Elsevier},
title = {{Comparison of random forest, support vector machine and back propagation neural network for electronic tongue data classification: Application to the recognition of orange beverage and Chinese vinegar}},
url = {http://www.sciencedirect.com/science/article/pii/S0925400512012671},
volume = {177},
year = {2013}
}
@article{Frank2007,
abstract = {We present an implemented approach for domain-restricted question answering from structured knowledge sources, based on robust semantic analysis in a hybrid NLP system architecture. We perform question interpretation and answer extraction in an architecture that builds on a lexical-conceptual structure for question interpretation, which is interfaced with domain-specific concepts and properties in a structured knowledge base. Question interpretation involves a limited amount of domain-specific inferences, and accounts for higher-level quantificational questions. Question interpretation and answer extraction are modular components that interact in clearly defined ways. We derive so-called proto queries from the linguistic representations, which provide partial constraints for answer extraction from the underlying knowledge sources. The search queries we construct from proto queries effectively compute minimal spanning trees from the underlying knowledge sources. Our approach naturally extends to multilingual question answering, and has been developed as a prototype system for two application domains: the domain of Nobel prize winners, and the domain of Language Technology, on the basis of the large ontology underlying the information portal LT World. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
author = {Frank, Anette and Krieger, Hans Ulrich and Xu, Feiyu and Uszkoreit, Hans and Crysmann, Berthold and J{\"{o}}rg, Brigitte and Sch{\"{a}}fer, Ulrich},
doi = {10.1016/j.jal.2005.12.006},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Frank et al. - 2007 - Question answering from structured knowledge sources.pdf:pdf},
issn = {15708683},
journal = {Journal of Applied Logic},
keywords = {Data base queries,Hybrid NLP,Multilinguality,Ontology modeling,QA,Question semantics,RMRS},
title = {{Question answering from structured knowledge sources}},
year = {2007}
}
@article{Fisher1936,
abstract = {Reproduced with permission of Cambridge University Press},
author = {Fisher, Ronald Aylmer, Sir, 1890-1962},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fisher - 1936 - 138 The Use of Multiple Measurements in Taxonomic Problems.pdf:pdf},
keywords = {Journal article},
title = {{138: The Use of Multiple Measurements in Taxonomic Problems.}},
url = {https://digital.library.adelaide.edu.au/dspace/handle/2440/15227},
year = {1936}
}
@article{Kari2008,
author = {Kari, Lila and Rozenberg, Grzegorz},
doi = {10.1145/1400181.1400200},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kari, Rozenberg - 2008 - The many facets of natural computing.pdf:pdf},
issn = {00010782},
journal = {Communications of the ACM},
month = {oct},
number = {10},
pages = {72},
publisher = {ACM},
title = {{The many facets of natural computing}},
url = {http://portal.acm.org/citation.cfm?doid=1400181.1400200},
volume = {51},
year = {2008}
}
@article{Ji2010,
author = {Ji, H and Grishman, R and 2010), HT Dang - {\ldots} (TAC and 2010, Undefined},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ji et al. - 2010 - Overview of the TAC 2010 knowledge base population track.pdf:pdf},
journal = {pdfs.semanticscholar.org},
title = {{Overview of the TAC 2010 knowledge base population track}},
url = {https://pdfs.semanticscholar.org/5a81/75b16a6e78308e7473e0fa9e5783e008575b.pdf https://nlp.cs.rpi.edu/paper/kbp2010overview.pdf},
year = {2010}
}
@inproceedings{tjong2003introduction,
abstract = {We describe the CoNLL-2003 shared task: language-independent named entity recognition. We give background information on the data sets (English and German) and the evaluation method, present a general overview of the systems that have taken part in the task and discuss their performance.},
archivePrefix = {arXiv},
arxivId = {cs/0306050},
author = {Sang, Erik F. Tjong Kim and {De Meulder}, Fien},
booktitle = {Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003-Volume 4},
doi = {10.3115/1119176.1119195},
eprint = {0306050},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sang, De Meulder - 2003 - Introduction to the CoNLL-2003 Shared Task Language-Independent Named Entity Recognition(2).pdf:pdf},
organization = {Association for Computational Linguistics},
pages = {142--147},
primaryClass = {cs},
title = {{Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition}},
url = {http://arxiv.org/abs/cs/0306050},
year = {2003}
}
@article{Fawagreh2014,
abstract = {Ensemble classification is a data mining approach that utilizes a number of classifiers that work together in order to identify the class label for unlabeled instances. Random forest (RF) is an ensemble classification approach that has proved its high accuracy and superiority. With one common goal in mind, RF has recently received considerable attention from the research community to further boost its performance. In this paper, we look at developments of RF from birth to present. The main aim is to describe the research done to date and also identify potential and future developments to RF. Our approach in this review paper is to take a historical view on the development of this notably successful classification technique. We start with developments that were found before Breiman's introduction of the technique in 2001, by which RF has borrowed some of its components. We then delve into dealing with the main technique proposed by Breiman. A number of developments to enhance the original technique are the...},
author = {Fawagreh, Khaled and Gaber, Mohamed Medhat and Elyan, Eyad},
doi = {10.1080/21642583.2014.956265},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fawagreh, Gaber, Elyan - 2014 - Random forests from early developments to recent advancements.pdf:pdf},
issn = {2164-2583},
journal = {Systems Science {\&} Control Engineering},
keywords = {bagging,ensemble learning,random forests,supervised learning},
month = {dec},
number = {1},
pages = {602--609},
publisher = {Taylor {\&} Francis},
title = {{Random forests: from early developments to recent advancements}},
url = {http://www.tandfonline.com/doi/abs/10.1080/21642583.2014.956265},
volume = {2},
year = {2014}
}
@article{Payton2001,
author = {Payton, David and Daily, Mike and Estowski, Regina and Howard, Mike and Lee, Craig},
doi = {10.1023/A:1012411712038},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Payton et al. - 2001 - Pheromone Robotics.pdf:pdf},
issn = {09295593},
journal = {Autonomous Robots},
number = {3},
pages = {319--324},
publisher = {Kluwer Academic Publishers},
title = {{Pheromone Robotics}},
url = {http://link.springer.com/10.1023/A:1012411712038},
volume = {11},
year = {2001}
}
@article{Ishiwataria,
abstract = {In this paper, we propose a new approach for multiple source localization tasks of multiple robots. Our approach controls robots by mobile agents that behave based on particle swarm optimization. The key process of our algorithm is to make subgroups in the population. In order to make subgroups, we indirectly transfer information using mobile agents instead of through direct communications. We have implemented our approach in a simulator, and conducted experiments to show effec-tiveness of our approach. Through the experimental results, we have con-firmed that our approach is more efficient and less susceptible to initial placement than other approaches.},
author = {Ishiwatari, Naoya and Sumikawa, Yasunobu and Takimoto, Munehiro and Kambayashi, Yasushi},
doi = {10.1007/978-3-319-61833-3},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ishiwatari et al. - Unknown - Cooperative Control of Multi-robot System Using Mobile Agent for Multiple Source Localization.pdf:pdf},
keywords = {Mobile agent,Swarm intelligence {\textperiodcentered},Swarm robotics {\textperiodcentered}},
title = {{Cooperative Control of Multi-robot System Using Mobile Agent for Multiple Source Localization}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1392651/mod{\_}label/intro/978-3-319-61833-3{\_}22.pdf}
}
@book{Rosenblatt1962,
author = {Rosenblatt, Frank.},
publisher = {Washington,},
title = {{Principles of neurodynamics;perceptrons and the theory of brain mechanisms.}},
url = {http://hdl.handle.net/2027/mdp.39015039846566},
year = {1962}
}
@article{Kirkpatrick2016,
abstract = {The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Neural networks are not, in general, capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks which they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on the MNIST hand written digit dataset and by learning several Atari 2600 games sequentially.},
archivePrefix = {arXiv},
arxivId = {1612.00796},
author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
eprint = {1612.00796},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kirkpatrick et al. - 2016 - Overcoming catastrophic forgetting in neural networks.pdf:pdf},
month = {dec},
title = {{Overcoming catastrophic forgetting in neural networks}},
url = {http://arxiv.org/abs/1612.00796},
year = {2016}
}
@inproceedings{Zhu2017,
author = {Zhu, Jiangcheng and Xu, Chao},
booktitle = {2017 Chinese Automation Congress (CAC)},
doi = {10.1109/CAC.2017.8244165},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhu, Xu - 2017 - A comprehensive simulation testbench for aerial robot in dynamic scenario using gazebo-ros.pdf:pdf},
isbn = {978-1-5386-3524-7},
month = {oct},
pages = {7664--7669},
publisher = {IEEE},
title = {{A comprehensive simulation testbench for aerial robot in dynamic scenario using gazebo-ros}},
url = {http://ieeexplore.ieee.org/document/8244165/},
year = {2017}
}
@book{Bishop1995,
abstract = {1. Statistical Pattern Recognition -- 2. Probability Density Estimation -- 3. Single-Layer Networks -- 4. The Multi-layer Perceptron -- 5. Radial Basis Functions -- 6. Error Functions -- 7. Parameter Optimization Algorithms -- 8. Pre-processing and Feature Extraction -- 9. Learning and Generalization -- 10. Bayesian Techniques.},
author = {Bishop, Christopher M.},
isbn = {9780198538646},
pages = {482},
publisher = {Clarendon Press},
title = {{Neural networks for pattern recognition}},
url = {https://global.oup.com/academic/product/neural-networks-for-pattern-recognition-9780198538646?cc=fr{\&}lang=en{\&}},
year = {1995}
}
@article{Zhang2017a,
abstract = {Knowledge graph (KG) is known to be helpful for the task of question answering (QA), since it provides well-structured relational information between entities, and allows one to further infer indirect facts. However, it is challenging to build QA systems which can learn to reason over knowledge graphs based on question-answer pairs alone. First, when people ask questions, their expressions are noisy (for example, typos in texts, or variations in pronunciations), which is non-trivial for the QA system to match those mentioned entities to the knowledge graph. Second, many questions require multi-hop logic reasoning over the knowledge graph to retrieve the answers. To address these challenges, we propose a novel and unified deep learning architecture, and an end-to-end variational learning algorithm which can handle noise in questions, and learn multi-hop reasoning simultaneously. Our method achieves state-of-the-art performance on a recent benchmark dataset in the literature. We also derive a series of new benchmark datasets, including questions for multi-hop reasoning, questions paraphrased by neural translation model, and questions in human voice. Our method yields very promising results on all these challenging datasets.},
archivePrefix = {arXiv},
arxivId = {1709.04071},
author = {Zhang, Yuyu and Dai, Hanjun and Kozareva, Zornitsa and Smola, Alexander J. and Song, Le},
eprint = {1709.04071},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - Variational Reasoning for Question Answering with Knowledge Graph.pdf:pdf},
month = {sep},
title = {{Variational Reasoning for Question Answering with Knowledge Graph}},
url = {http://arxiv.org/abs/1709.04071},
year = {2017}
}
@article{Couzin2002,
abstract = {We show how the movement rules of individual ants on trails can lead to a collective choice of direction and the formation of distinct traffic lanes that minimize congestion. We develop and evaluate the results of a new model with a quantitative study of the behaviour of the army ant Eciton burchelli. Colonies of this species have up to 200 000 foragers and transport more than 3000 prey items per hour over raiding columns that exceed 100 m. It is an ideal species in which to test the predictions of our model because it forms pheromone trails that are densely populated with very swift ants. The model explores the influ-ences of turning rates and local perception on traffic flow. The behaviour of real army ants is such that they occupy the specific region of parameter space in which lanes form and traffic flow is maximized.},
author = {Couzin, I D and Franks, N R},
doi = {10.1098/rspb.2002.2210},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Couzin, Franks - 2002 - Self-organized lane formation and optimized traffic flow in Self-organized lane formation and optimized traffic.pdf:pdf},
journal = {Proc. R. Soc. Lond. B},
keywords = {computer simulation,mathematical model,self-organization,social insects},
pages = {139--146},
title = {{Self-organized lane formation and optimized traffic flow in Self-organized lane formation and optimized traffic flow in army ants}},
url = {http://rspb.royalsocietypublishing.org/content/270/1511/139{\#}related-urls},
volume = {2210},
year = {2002}
}
@article{Labroche2003,
abstract = {In this paper, we propose a new ant-based clustering algo-rithm called AntClust. It is inspired from the chemical recognition sys-tem of ants. In this system, the continuous interactions between the nestmates generate a " Gestalt " colonial odor. Similarly, our clustering algorithm associates an object of the data set to the odor of an ant and then simulates meetings between ants. At the end, artificial ants that share a similar odor are grouped in the same nest, which provides the expected partition. We compare AntClust to the K-Means method and to the AntClass algorithm. We present new results on artificial and real data sets. We show that AntClust performs well and can extract mean-ingful knowledge from real Web sessions.},
author = {Labroche, Nicolas and Monmarch{\'{e}}, Nicolas and Venturini, Gilles},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Labroche, Monmarch{\'{e}}, Venturini - Unknown - AntClust Ant Clustering and Web Usage Mining.pdf:pdf},
title = {{AntClust: Ant Clustering and Web Usage Mining}},
url = {http://www.antsearch.univ-tours.fr/},
year = {2003}
}
@article{Mur-Artal2015,
abstract = {This paper presents ORB-SLAM, a feature-based monocular SLAM system that operates in real time, in small and large, indoor and outdoor environments. The system is robust to severe motion clutter, allows wide baseline loop closing and relocalization, and includes full automatic initialization. Building on excellent algorithms of recent years, we designed from scratch a novel system that uses the same features for all SLAM tasks: tracking, mapping, relocalization, and loop closing. A survival of the fittest strategy that selects the points and keyframes of the reconstruction leads to excellent robustness and generates a compact and trackable map that only grows if the scene content changes, allowing lifelong operation. We present an exhaustive evaluation in 27 sequences from the most popular datasets. ORB-SLAM achieves unprecedented performance with respect to other state-of-the-art monocular SLAM approaches. For the benefit of the community, we make the source code public.},
archivePrefix = {arXiv},
arxivId = {1502.00956},
author = {Mur-Artal, Raul and Montiel, J. M. M. and Tardos, Juan D.},
doi = {10.1109/TRO.2015.2463671},
eprint = {1502.00956},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mur-Artal, Montiel, Tardos - 2015 - ORB-SLAM a Versatile and Accurate Monocular SLAM System.pdf:pdf},
month = {feb},
title = {{ORB-SLAM: a Versatile and Accurate Monocular SLAM System}},
url = {http://arxiv.org/abs/1502.00956 http://dx.doi.org/10.1109/TRO.2015.2463671},
year = {2015}
}
@article{hoffner2017survey,
author = {H{\"{o}}ffner, Konrad and Walter, Sebastian and Marx, Edgard and Usbeck, Ricardo and Lehmann, Jens and {Ngonga Ngomo}, Axel-Cyrille},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/H{\"{o}}ffner et al. - 2017 - Survey on challenges of question answering in the semantic web.pdf:pdf},
journal = {Semantic Web},
number = {6},
pages = {895--920},
publisher = {IOS Press},
title = {{Survey on challenges of question answering in the semantic web}},
volume = {8},
year = {2017}
}
@inproceedings{Nodelman:2002:CTB:2073876.2073921,
address = {San Francisco, CA, USA},
author = {Nodelman, Uri and Shelton, Christian R and Koller, Daphne},
booktitle = {Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nodelman, Shelton, Koller - 2002 - Continuous Time Bayesian Networks.pdf:pdf},
isbn = {1-55860-897-4},
pages = {378--387},
publisher = {Morgan Kaufmann Publishers Inc.},
series = {UAI'02},
title = {{Continuous Time Bayesian Networks}},
url = {http://dl.acm.org/citation.cfm?id=2073876.2073921},
year = {2002}
}
@book{Brueckner2005,
abstract = {"The book comprises revised versions of papers presented at the Engineering Self-organising Applications (ESOA 2004) workshop, held during the Autonomous Agents and Multi-agent Systems conference (AAMAS 2004) in New York in July 2004, and selected invited papers from leading contributors in the self-organisation field"--Pref., p. vi. Self-organisation, self-regulation, self-repair, and self-maintenance are promising conceptual approaches to deal with the ever increasing complexity of distributed interacting software and information handling systems. Self-organising applications are able to dynamically change their functionality and structure without direct user intervention to respond to changes in requirements and the environment. This book comprises revised and extended papers presented at the International Workshop on Engineering Self-Organising Applications, ESOA 2004, held in New York, NY, USA in July 2004 at AAMAS as well as invited papers from leading researchers. The papers are organized in topical sections on state of the art, synthesis and design methods, self-assembly and robots, stigmergy and related topics, and industrial applications. State of the Art -- Emergence Versus Self-Organisation: Different Concepts but Promising When Combined -- About Engineering Complex Systems: Multiscale Analysis and Evolutionary Engineering -- Adaptive Information Infrastructures for the e-Society -- Synthesis and Design Methods -- Agent-Based Modelling of Stem Cell Self-organisation in a Niche -- Ambient Cognitive Environments and the Distributed Synthesis of Visual Ambiences -- Using the Experimental Method to Produce Reliable Self-Organised Systems -- An Architecture for Self-Organising Evolvable Virtual Machines -- Self-Organising, Open and Cooperative P2P Societies – From Tags to Networks -- Self- ssembly and Robots -- Self-Organizing Spatial Shapes in Mobile Particles: The TOTA Approach -- Directed Self-assembly of 2-Dimensional Mesoblocks Using Top-Down/Bottom-Up Design -- Analysis of a Stochastic Model of Adaptive Task Allocation in Robots -- Emergent Team Formation: Applying Division of Labour Principles to Robot Soccer -- Stigmergy and Related Topics -- Analyzing Stigmergic Learning for Self-Organizing Mobile Ad-Hoc Networks (MANET's) -- Emergent Forecasting Using a Stigmergy Approach in Manufacturing Coordination and Control -- IDReAM: Intrusion Detection and Response Executed with Agent Mobility -- Managing Dynamic Flows in Production Chains Through Self-Organization -- Industrial Applications -- A Self-Organizing and Fault-Tolerant Wired Peer-to-Peer Sensor Network for Textile Applications -- Applying Distributed Adaptive Optimization to Digital Car Body Development -- Adaptive Service Placement Algorithms for Autonomous Service Networks.},
author = {{De Wolf}, Tom and Holvoet, Tom},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Wolf, Holvoet - 2005 - Engineering self-organising systems methodologies and applications.pdf:pdf},
isbn = {354026180X},
pages = {297},
publisher = {Springer},
title = {{Engineering self-organising systems : methodologies and applications}},
url = {http://dl.acm.org/citation.cfm?id=2167659},
year = {2005}
}
@article{Scanagatta2017a,
abstract = {We present a novel approach for score-based structure learning of Bayesian network, which couples an existing ordering-based algorithm for structure optimization with a novel op-erator for exploring the neighborhood of a given order in the space of the orderings. Our approach achieves state-of-the-art performances in data sets containing thousands of vari-ables.},
author = {Scanagatta, Mauro and {Ch Idsia}, Mauro@idsia and Supsi, Usi-Lugano and Corani, Switzerland Giorgio and {Ch Idsia}, Giorgio@idsia and Marco, Switzerland and {Ch Idsia}, Zaffalon Zaffalon@idsia and -Lugano, Switzerland},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scanagatta et al. - 2017 - Improved Local Search in Bayesian Networks Structure Learning(2).pdf:pdf},
journal = {Proceedings of Machine Learning Research},
keywords = {Bayesian networks,Heuristic Search,Learning Graphical Models},
pages = {45--56},
title = {{Improved Local Search in Bayesian Networks Structure Learning}},
url = {http://proceedings.mlr.press/v73/scanagatta17a/scanagatta17a.pdf},
volume = {73},
year = {2017}
}
@article{Diefenbach2018b,
abstract = {Thanks to the development of the Semantic Web, a lot of new structured data has become available on the Web in the form of knowledge bases (KBs). Making this valuable data accessible and usable for end-users is one of the main goals of Question Answering (QA) over KBs. Most current QA systems query one KB, in one language (namely English). The existing approaches are not designed to be easily adaptable to new KBs and languages. We first introduce a new approach for translating natural language questions to SPARQL queries. It is able to query several KBs simultaneously, in different languages, and can easily be ported to other KBs and languages. In our evaluation, the impact of our approach is proven using 5 different well-known and large KBs: Wikidata, DBpedia, MusicBrainz, DBLP and Freebase as well as 5 different languages namely English, German, French, Italian and Spanish. Second, we show how we integrated our approach, to make it easily accessible by the research community and by end-users. To summarize, we provided a conceptional solution for multilingual, KB-agnostic Question Answering over the Semantic Web. The provided first approximation validates this concept.},
archivePrefix = {arXiv},
arxivId = {1803.00832},
author = {Diefenbach, Dennis and Both, Andreas and Singh, Kamal and Maret, Pierre},
eprint = {1803.00832},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Diefenbach et al. - 2018 - Towards a Question Answering System over the Semantic Web.pdf:pdf},
month = {mar},
title = {{Towards a Question Answering System over the Semantic Web}},
url = {http://arxiv.org/abs/1803.00832},
year = {2018}
}
@article{Devlin2018,
abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE benchmark to 80.4{\%} (7.6{\%} absolute improvement), MultiNLI accuracy to 86.7 (5.6{\%} absolute improvement) and the SQuAD v1.1 question answering Test F1 to 93.2 (1.5{\%} absolute improvement), outperforming human performance by 2.0{\%}.},
archivePrefix = {arXiv},
arxivId = {1810.04805},
author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
eprint = {1810.04805},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Devlin et al. - 2018 - BERT Pre-training of Deep Bidirectional Transformers for Language Understanding.pdf:pdf},
month = {oct},
title = {{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}},
url = {http://arxiv.org/abs/1810.04805},
year = {2018}
}
@inproceedings{Abujabal2018,
address = {New York, New York, USA},
author = {Abujabal, Abdalghani and {Saha Roy}, Rishiraj and Yahya, Mohamed and Weikum, Gerhard},
booktitle = {Proceedings of the 2018 World Wide Web Conference on World Wide Web  - WWW '18},
doi = {10.1145/3178876.3186004},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abujabal et al. - 2018 - Never-Ending Learning for Open-Domain Question Answering over Knowledge Bases(2).pdf:pdf},
isbn = {9781450356398},
keywords = {never-ending learning,question answering,user feedback},
pages = {1053--1062},
publisher = {ACM Press},
title = {{Never-Ending Learning for Open-Domain Question Answering over Knowledge Bases}},
url = {http://dl.acm.org/citation.cfm?doid=3178876.3186004},
year = {2018}
}
@article{Wu2017,
abstract = {In this work, we propose to apply trust region optimization to deep reinforcement learning using a recently proposed Kronecker-factored approximation to the curvature. We extend the framework of natural policy gradient and propose to optimize both the actor and the critic using Kronecker-factored approximate curvature (K-FAC) with trust region; hence we call our method Actor Critic using Kronecker-Factored Trust Region (ACKTR). To the best of our knowledge, this is the first scalable trust region natural gradient method for actor-critic methods. It is also a method that learns non-trivial tasks in continuous control as well as discrete control policies directly from raw pixel inputs. We tested our approach across discrete domains in Atari games as well as continuous domains in the MuJoCo environment. With the proposed methods, we are able to achieve higher rewards and a 2- to 3-fold improvement in sample efficiency on average, compared to previous state-of-the-art on-policy actor-critic methods. Code is available at https://github.com/openai/baselines},
archivePrefix = {arXiv},
arxivId = {1708.05144},
author = {Wu, Yuhuai and Mansimov, Elman and Liao, Shun and Grosse, Roger and Ba, Jimmy},
eprint = {1708.05144},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2017 - Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation.pdf:pdf},
month = {aug},
title = {{Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation}},
url = {http://arxiv.org/abs/1708.05144},
year = {2017}
}
@article{rotors2016,
annote = {ISBN:978-3-319-26052-5},
author = {Furrer, Fadri and Burri, Michael and Achtelik, Markus and Siegwart, Roland},
journal = {Studies Comp.Intelligence Volume Number:625},
number = {978-3-319-26052-5},
pages = {Chapter 23},
title = {{Robot Operating System (ROS)}},
volume = {The Comple},
year = {2016}
}
@article{Reimers2017,
abstract = {Selecting optimal parameters for a neural network architecture can often make the difference between mediocre and state-of-the-art performance. However, little is published which parameters and design choices should be evaluated or selected making the correct hyperparameter optimization often a "black art that requires expert experiences" (Snoek et al., 2012). In this paper, we evaluate the importance of different network design choices and hyperparameters for five common linguistic sequence tagging tasks (POS, Chunking, NER, Entity Recognition, and Event Detection). We evaluated over 50.000 different setups and found, that some parameters, like the pre-trained word embeddings or the last layer of the network, have a large impact on the performance, while other parameters, for example the number of LSTM layers or the number of recurrent units, are of minor importance. We give a recommendation on a configuration that performs well among different tasks.},
archivePrefix = {arXiv},
arxivId = {1707.06799},
author = {Reimers, Nils and Gurevych, Iryna},
eprint = {1707.06799},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reimers, Gurevych - 2017 - Optimal Hyperparameters for Deep LSTM-Networks for Sequence Labeling Tasks.pdf:pdf},
month = {jul},
title = {{Optimal Hyperparameters for Deep LSTM-Networks for Sequence Labeling Tasks}},
url = {http://arxiv.org/abs/1707.06799},
year = {2017}
}
@article{Haack2011,
abstract = {—We describe a swarming-agent-based, mixed-initiative approach to infrastructure defense where teams of humans and software agents defend cooperating organizations in tandem by sharing insights and solutions without violating proprietary boundaries. The system places human administrators at the appropriate level: where they provide system guidance while lower-level agents carry out tasks humans are unable to perform quickly enough to mitigate today's security threats. Cooperative Infrastructure Defense, or CID, uses our ant-based approach to enable dialogue between humans and agents to foster a collaborative problem-solving environment, to increase human situational awareness and to influence using visualization and shared control. We discuss theoretical implementation characteristics along with results from recent proof-of-concept implementations.},
author = {Haack, Jereme N and Fink, Glenn A and Maiden, Wendy M and Mckinnon, A David and Templeton, Steven J and Fulp, Errin W},
doi = {10.1109/ITNG.2011.159},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haack et al. - 2011 - Ant-Based Cyber Security.pdf:pdf},
keywords = {agents,digital ants,digital pheromone,security},
title = {{Ant-Based Cyber Security}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1327632/mod{\_}label/intro/Ant-based cyber security.pdf},
year = {2011}
}
@article{Lazic2015,
abstract = {We present Plato, a probabilistic model for entity resolution that includes a novel approach for handling noisy or uninformative features, and supplements labeled training data derived from Wikipedia with a very large unlabeled text corpus. Training and inference in the proposed model can easily be distributed across many servers, allowing it to scale to over 10{\^{}}7 entities. We evaluate Plato on three standard datasets for entity resolution. Our approach achieves the best results to-date on TAC KBP 2011 and is highly competitive on both the CoNLL 2003 and TAC KBP 2012 datasets.},
author = {Lazic, Nevena and Subramanya, Amarnag and Ringgaard, Michael and Pereira, Fernando},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Association for Computational Linguistics et al. - 2015 - Transactions of the Association for Computational Linguistics.pdf:pdf},
issn = {2307-387X},
journal = {Acl2016},
month = {oct},
number = {0},
pages = {503--515},
title = {{Plato: A Selective Context Model for Entity Resolution}},
url = {https://transacl.org/ojs/index.php/tacl/article/view/637 https://tacl2013.cs.columbia.edu/ojs/index.php/tacl/article/view/637},
volume = {3},
year = {2015}
}
@inproceedings{voorhees1999trec,
author = {Voorhees, Ellen M and Tice, Dawn M},
booktitle = {TREC},
pages = {82},
title = {{The TREC-8 Question Answering Track Evaluation.}},
volume = {1999},
year = {1999}
}
@article{Diaz,
abstract = {Although barely explored so far, swarm intelligence can arguably have a profound impact on video games; for instance, as a simple yet effective approach for the realistic intelligent behavior of Non-Player Characters (NPCs). In this context, we describe the application of particle swarm optimization to the behavioral design of NPCs in a first-person shooter video game. The feasibility and performance of our method is analyzed through some computer experiments. They show that the proposed approach performs very well and can be successfully used in a fully automatic (i.e., without any human player) and efficient way.},
author = {D{\'{i}}az, Guillermo and Iglesias, Andr{\'{e}}s},
doi = {10.1007/978-3-319-61824-1},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/D{\'{i}}az, Iglesias - Unknown - Intelligent Behavioral Design of Non-player Characters in a FPS Video Game Through PSO.pdf:pdf},
keywords = {Intelligent behavioral design,Non-player characters {\textperiodcentered},Particle swarm optimization {\textperiodcentered},Swarm intelligence {\textperiodcentered},Video game {\textperiodcentered}},
title = {{Intelligent Behavioral Design of Non-player Characters in a FPS Video Game Through PSO}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1327619/mod{\_}label/intro/diaz-nonPlayerVideoGamepso-2017.pdf}
}
@article{kontschieder,
abstract = {We present Deep Neural Decision Forests – a novel ap-proach that unifies classification trees with the representa-tion learning functionality known from deep convolutional networks, by training them in an end-to-end manner. To combine these two worlds, we introduce a stochastic and differentiable decision tree model, which steers the rep-resentation learning usually conducted in the initial lay-ers of a (deep) convolutional network. Our model differs from conventional deep networks because a decision for-est provides the final predictions and it differs from con-ventional decision forests since we propose a principled, joint and global optimization of split and leaf node param-eters. We show experimental results on benchmark machine learning datasets like MNIST and ImageNet and find on-par or superior results when compared to state-of-the-art deep models. Most remarkably, we obtain Top5-Errors of only 7.84{\%}/6.38{\%} on ImageNet validation data when in-tegrating our forests in a single-crop, single/seven model GoogLeNet architecture, respectively. Thus, even without any form of training data set augmentation we are improv-ing on the 6.67{\%} error obtained by the best GoogLeNet ar-chitecture (7 models, 144 crops).},
author = {Kontschieder, Peter and Fiterau, Madalina and Criminisi, Antonio and {Rotabu{\`{i}} O}, Samuel and Kessler, Fondazione Bruno},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kontschieder et al. - Unknown - Deep Neural Decision Forests.pdf:pdf},
journal = {International Journal of Computer Vision},
title = {{Deep Neural Decision Forests}},
url = {https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/ICCV15{\_}DeepNDF{\_}main.pdf},
year = {2015}
}
@article{Sampedro2017,
abstract = {{\textcopyright} 2017 IEEE. In this paper, a fully-autonomous quadrotor aerial robot for solving the different missions proposed in the 2016 International Micro Air Vehicle (IMAV) Indoor Competition is presented. The missions proposed in the IMAV 2016 competition involve the execution of high-level missions such as entering and exiting a building, exploring an unknown indoor environment, recognizing and interacting with objects, landing autonomously on a moving platform, etc. For solving the aforementioned missions, a fully-autonomous quadrotor aerial robot has been designed, based on a complete hardware configuration and a versatile software architecture, which allows the aerial robot to complete all the missions in a fully autonomous and consecutive manner. A thorough evaluation of the proposed system has been carried out in both simulated flights, using the Gazebo simulator in combination with PX4 Software-In-The-Loop, and real flights, demonstrating the appropriate capabilities of the proposed system for performing high-level missions and its flexibility for being adapted to a wide variety of applications.},
author = {Sampedro, Carlos and Bavle, Hriday and Rodr{\'{i}}guez-Ramos, Alejandro and Carrio, Adrian and Fern{\'{a}}ndez, Ramon A.Su{\'{a}}rez and Sanchez-Lopez, Jose Luis and Campoy, Pascual},
doi = {10.1109/ICUAS.2017.7991442},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sampedro et al. - 2017 - A fully-autonomous aerial robotic solution for the 2016 International Micro Air Vehicle competition.pdf:pdf},
isbn = {9781509044948},
journal = {2017 International Conference on Unmanned Aircraft Systems, ICUAS 2017},
pages = {989--998},
title = {{A fully-autonomous aerial robotic solution for the 2016 International Micro Air Vehicle competition}},
year = {2017}
}
@inproceedings{dang2007overview,
author = {Dang, Hoa Trang and Kelly, Diane and Lin, Jimmy J},
booktitle = {Trec},
pages = {63},
title = {{Overview of the TREC 2007 Question Answering Track.}},
volume = {7},
year = {2007}
}
@article{Mnih2016,
abstract = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.},
archivePrefix = {arXiv},
arxivId = {1602.01783},
author = {Mnih, Volodymyr and Badia, Adri{\`{a}} Puigdom{\`{e}}nech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P. and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
eprint = {1602.01783},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mnih et al. - 2016 - Asynchronous Methods for Deep Reinforcement Learning.pdf:pdf},
month = {feb},
title = {{Asynchronous Methods for Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1602.01783},
year = {2016}
}
@article{GarcíaArnau2007127,
annote = {{\{}AI{\}} 2006The 26th {\{}SGAI{\}} International Conference on Innovative Techniques and Applications of Artificial Intelligence},
author = {Garc{\'{i}}a-Arnau, M and Manrique, D and R{\'{i}}os, J and Rodr{\'{i}}guez-Pat{\'{o}}n, A},
doi = {https://doi.org/10.1016/j.knosys.2006.11.006},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garc{\'{i}}a-Arnau et al. - 2007 - Initialization method for grammar-guided genetic programming.pdf:pdf},
issn = {0950-7051},
journal = {Knowledge-Based Systems},
keywords = {Breast cancer prognosis,Grammar-guided genetic programming,Initialization method,Tree-generation algorithm},
number = {2},
pages = {127--133},
title = {{Initialization method for grammar-guided genetic programming}},
url = {http://www.sciencedirect.com/science/article/pii/S0950705106001973},
volume = {20},
year = {2007}
}
@article{diaz2006,
abstract = {Selection of relevant genes for sample classification is a common task in most gene expression studies, where researchers try to identify the smallest possible set of genes that can still achieve good predictive performance (for instance, for future use with diagnostic purposes in clinical practice). Many gene selection approaches use univariate (gene-by-gene) rankings of gene relevance and arbitrary thresholds to select the number of genes, can only be applied to two-class problems, and use gene selection ranking criteria unrelated to the classification algorithm. In contrast, random forest is a classification algorithm well suited for microarray data: it shows excellent performance even when most predictive variables are noise, can be used when the number of variables is much larger than the number of observations and in problems involving more than two classes, and returns measures of variable importance. Thus, it is important to understand the performance of random forest with microarray data and its possible use for gene selection. We investigate the use of random forest for classification of microarray data (including multi-class problems) and propose a new method of gene selection in classification problems based on random forest. Using simulated and nine microarray data sets we show that random forest has comparable performance to other classification methods, including DLDA, KNN, and SVM, and that the new gene selection procedure yields very small sets of genes (often smaller than alternative methods) while preserving predictive accuracy. Because of its performance and features, random forest and gene selection using random forest should probably become part of the "standard tool-box" of methods for class prediction and gene selection with microarray data.},
author = {D{\'{i}}az-Uriarte, Ram{\'{o}}n and {Alvarez de Andr{\'{e}}s}, Sara},
doi = {10.1186/1471-2105-7-3},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/D{\'{i}}az-Uriarte, Alvarez de Andr{\'{e}}s - 2006 - Gene selection and classification of microarray data using random forest.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Algorithms,Bioinformatics,Combinatorial Libraries,Computational Biology/Bioinformatics,Computer Appl. in Life Sciences,Microarrays},
month = {jan},
number = {1},
pages = {3},
publisher = {BioMed Central},
title = {{Gene selection and classification of microarray data using random forest}},
url = {http://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-7-3},
volume = {7},
year = {2006}
}
@article{Lison2015,
abstract = {We present a new modelling framework for dialogue management based on the concept of probabilistic rules. Probabilistic rules are defined as structured mappings between logical conditions and probabilistic effects. They function as high-level templates for probabilistic graphical models and may include unknown parameters whose values are estimated from data using Bayesian inference. Thanks to their use of logical abstractions, probabilistic rules are able to encode the probability and utility models employed in dialogue management in a compact and human-readable form. As a consequence, they can reduce the amount of dialogue data required for parameter estimation and allow system designers to directly incorporate their expert domain knowledge into the dialogue models. Empirical results of a user evaluation in a human-robot interaction task with 37 participants show that a dialogue manager structured with probabilistic rules outperforms both purely hand-crafted and purely statistical methods on a range of subjective and objective quality metrics. The framework is implemented in a software toolkit called OpenDial, which can be used to develop various types of dialogue systems based on probabilistic rules.},
author = {Lison, Pierre},
doi = {10.1016/j.csl.2015.01.001},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lison - 2015 - A hybrid approach to dialogue management based on probabilistic rules.pdf:pdf},
issn = {10958363},
journal = {Computer Speech and Language},
keywords = {Bayesian inference,Dialogue management,Human-robot interaction,Probabilistic graphical models,Spoken dialogue systems},
number = {1},
pages = {232--255},
publisher = {Elsevier Ltd},
title = {{A hybrid approach to dialogue management based on probabilistic rules}},
url = {http://dx.doi.org/10.1016/j.csl.2015.01.001},
volume = {34},
year = {2015}
}
@article{Roy2005,
abstract = {A theoretical framework for grounding language is introduced that provides a computational path from sensing and motor action to words and speech acts. The approach combines concepts from semiotics and schema theory to develop a holistic approach to linguistic meaning. Schemas serve as structured beliefs that are grounded in an agent's physical environment through a causal-predictive cycle of action and perception. Words and basic speech acts are interpreted in terms of grounded schemas. The framework reflects lessons learned from implementations of several language processing robots. It provides a basis for the analysis and design of situated, multimodal communication systems that straddle symbolic and non-symbolic realms. {\textcopyright} 2005 Published by Elsevier B.V.},
author = {Roy, Deb},
doi = {10.1016/j.artint.2005.04.007},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Roy - 2005 - Semiotic schemas A framework for grounding language in action and perception.pdf:pdf},
isbn = {00043702},
issn = {00043702},
journal = {Artificial Intelligence},
keywords = {Action,Cross-modal,Embodied,Grounding,Language,Meaning,Multimodal,Perception,Representation,Schemas,Semiotic,Situated},
number = {1-2},
pages = {170--205},
title = {{Semiotic schemas: A framework for grounding language in action and perception}},
volume = {167},
year = {2005}
}
@article{Bajaj2018,
abstract = {We introduce a large scale MAchine Reading COmprehension dataset, which we name MS MARCO. The dataset comprises of 1,010,916 anonymized questions---sampled from Bing's search query logs---each with a human generated answer and 182,669 completely human rewritten generated answers. In addition, the dataset contains 8,841,823 passages---extracted from 3,563,535 web documents retrieved by Bing---that provide the information necessary for curating the natural language answers. A question in the MS MARCO dataset may have multiple answers or no answers at all. Using this dataset, we propose three different tasks with varying levels of difficulty: (i) predict if a question is answerable given a set of context passages, and extract and synthesize the answer as a human would (ii) generate a well-formed answer (if possible) based on the context passages that can be understood with the question and passage context, and finally (iii) rank a set of retrieved passages given a question. The size of the dataset and the fact that the questions are derived from real user search queries distinguishes MS MARCO from other well-known publicly available datasets for machine reading comprehension and question-answering. We believe that the scale and the real-world nature of this dataset makes it attractive for benchmarking machine reading comprehension and question-answering models.},
archivePrefix = {arXiv},
arxivId = {1611.09268},
author = {Bajaj, Payal and Campos, Daniel and Craswell, Nick and Deng, Li and Gao, Jianfeng and Liu, Xiaodong and Majumder, Rangan and McNamara, Andrew and Mitra, Bhaskar and Nguyen, Tri and Rosenberg, Mir and Song, Xia and Stoica, Alina and Tiwary, Saurabh and Wang, Tong},
eprint = {1611.09268},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bajaj et al. - 2016 - MS MARCO A Human Generated MAchine Reading COmprehension Dataset.pdf:pdf},
month = {nov},
title = {{MS MARCO: A Human Generated MAchine Reading COmprehension Dataset}},
url = {http://arxiv.org/abs/1611.09268},
year = {2018}
}
@article{Goyal,
abstract = {The recently developed variational autoencoders (VAEs) have proved to be an effective confluence of the rich repre-sentational power of neural networks with Bayesian meth-ods. However, most work on VAEs use a rather simple prior over the latent variables such as standard normal distribu-tion, thereby restricting its applications to relatively sim-ple phenomena. In this work, we propose hierarchical non-parametric variational autoencoders, which combines tree-structured Bayesian nonparametric priors with VAEs, to en-able infinite flexibility of the latent representation space. Both the neural parameters and Bayesian priors are learned jointly using tailored variational inference. The resulting model induces a hierarchical structure of latent semantic concepts underlying the data corpus, and infers accurate representations of data instances. We apply our model in video representation learning. Our method is able to dis-cover highly interpretable activity hierarchies, and obtain improved clustering accuracy and generalization capacity based on the learned rich representations.},
author = {Goyal, Prasoon and Hu, Zhiting and Liang, Xiaodan and Wang, Chenyu and Xing, Eric P},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goyal et al. - Unknown - Nonparametric Variational Auto-encoders for Hierarchical Representation Learning.pdf:pdf},
title = {{Nonparametric Variational Auto-encoders for Hierarchical Representation Learning}},
url = {http://openaccess.thecvf.com/content{\_}ICCV{\_}2017/papers/Goyal{\_}Nonparametric{\_}Variational{\_}Auto-Encoders{\_}ICCV{\_}2017{\_}paper.pdf}
}
@inproceedings{bollacker2008freebase,
author = {Bollacker, Kurt and Evans, Colin and Paritosh, Praveen and Sturge, Tim and Taylor, Jamie},
booktitle = {Proceedings of the 2008 ACM SIGMOD international conference on Management of data},
organization = {AcM},
pages = {1247--1250},
title = {{Freebase: a collaboratively created graph database for structuring human knowledge}},
year = {2008}
}
@article{murTRO2015,
author = {{Mur-Artal Ra{\'{u}}l}, Montiel J M M and Tard{\'{o}}s, Juan D},
doi = {10.1109/TRO.2015.2463671},
journal = {IEEE Transactions on Robotics},
number = {5},
pages = {1147--1163},
title = {{ORB-SLAM: a Versatile and Accurate Monocular SLAM System}},
volume = {31},
year = {2015}
}
@article{Cooper1992,
author = {Cooper, Gregory F. and Herskovits, Edward},
doi = {10.1007/BF00994110},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cooper, Herskovits - 1992 - A Bayesian method for the induction of probabilistic networks from data.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
month = {oct},
number = {4},
pages = {309--347},
publisher = {Kluwer Academic Publishers},
title = {{A Bayesian method for the induction of probabilistic networks from data}},
url = {http://link.springer.com/10.1007/BF00994110},
volume = {9},
year = {1992}
}
@article{Rajpurkar2016,
abstract = {We present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0{\%}, a significant improvement over a simple baseline (20{\%}). However, human performance (86.8{\%}) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at https://stanford-qa.com},
archivePrefix = {arXiv},
arxivId = {1606.05250},
author = {Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
eprint = {1606.05250},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rajpurkar et al. - 2016 - SQuAD 100,000 Questions for Machine Comprehension of Text.pdf:pdf},
month = {jun},
title = {{SQuAD: 100,000+ Questions for Machine Comprehension of Text}},
url = {http://arxiv.org/abs/1606.05250},
year = {2016}
}
@article{DeCampos2000,
abstract = {In the paper we describe a new independence-based approach for learning Belief Networks. The proposed algorithm avoids some of the drawbacks of this approach by making an intensive use of low order conditional independence tests. Particularly, the set of zero- and first-order independence statements are used in order to obtain a prior skeleton of the network, and also to fix and remove arrows from this skeleton. Then, a refinement procedure, based on minimum cardinality d-separating sets, which uses a small number of conditional independence tests of higher order, is carried out to produce the final graph. Our algorithm needs an ordering of the variables in the model as the input. An algorithm that partially overcomes this problem is also presented.},
author = {de Campos, Luis M. and Huete, Juan F.},
doi = {10.1016/S0888-613X(99)00042-0},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Campos, Huete - 2000 - A new approach for learning belief networks using independence criteria.pdf:pdf},
issn = {0888-613X},
journal = {International Journal of Approximate Reasoning},
month = {apr},
number = {1},
pages = {11--37},
publisher = {Elsevier},
title = {{A new approach for learning belief networks using independence criteria}},
url = {http://www.sciencedirect.com/science/article/pii/S0888613X99000420},
volume = {24},
year = {2000}
}
@article{Sivagaminathan,
abstract = {One of the significant research problems in multivariate analysis is the selection of a subset of input variables that can predict the desired output with an acceptable level of accuracy. This goal is attained through the elimination of the variables that produce noise or, are strictly correlated with other already selected variables. Feature subset selection (selection of the input variables) is important in correlation analysis and in the field of classification and modeling. This paper presents a hybrid method based on ant colony optimi-zation and artificial neural networks (ANNs) to address feature selection. The proposed hybrid model is demonstrated using data sets from the domain of medical diagnosis, yielding promising results.},
author = {Sivagaminathan, Rahul Karthik and Ramakrishnan, Sreeram},
doi = {10.1016/j.eswa.2006.04.010},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sivagaminathan, Ramakrishnan - Unknown - A hybrid approach for feature subset selection using neural networks and ant colony optimizatio.pdf:pdf},
keywords = {Ant colony optimization,Feature subset selection,Neural networks},
title = {{A hybrid approach for feature subset selection using neural networks and ant colony optimization}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132239/mod{\_}label/intro/karthik-featureSetSelection-ANN-ACO-2007.pdf}
}
@article{Campo,
abstract = {In this paper, we study the cooperative transport of a heavy object by a group of robots towards a goal. We investigate the case in which robots have partial and noisy knowledge of the goal direction and can not perceive the goal itself. The robots have to coordinate their motion to apply enough force on the object to move it. Furthermore, the robots should share knowledge in order to collectively improve their estimate of the goal direction and transport the object as fast and as accurately as possible towards the goal. We propose a bio-inspired mechanism of negotiation of direction that is fully distributed. Four different strategies are implemented and their performances are compared on a group of four real robots, varying the goal direction and the level of noise. We identify a strategy that enables efficient coordination of motion of the robots. Moreover, this strategy lets the robots improve their knowledge of the goal direction. Despite significant noise in the robots' communication, we achieve effective co-operative transport towards the goal and observe that the negotiation of direction entails interesting properties of robustness.},
author = {Campo, Alexandre and Nouyan, Shervin and Birattari, Mauro and Gro{\ss}, Roderich and Dorigo, Marco},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Campo et al. - Unknown - Negotiation of Goal Direction for Cooperative Transport.pdf:pdf},
title = {{Negotiation of Goal Direction for Cooperative Transport}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132253/mod{\_}label/intro/{\%}23 negotiation of goal direction {\%}28Campos et al{\%}2C 06{\%}29.pdf}
}
@article{Ogrady,
abstract = {We explore the problem of resource allocation in a system made up of autonomous agents that can either carry out tasks indi-vidually or, when necessary, cooperate by forming physical connections with each other. We consider a group transport scenario that involves transporting broken robots to a repair zone. Some broken robots can be transported by an individual 'rescue' robot, whereas other broken robots are heavier and therefore require the rescue robots to self-assemble into a larger and stronger composite entity. We present a distributed controller that solves this task while efficiently allocating resources. We conduct a series of real-world experiments to show that our system can i) transport separate broken robots in parallel, ii) trigger self-assembly into compos-ite entities when necessary to overcome the physical limitations of indi-vidual agents, iii) efficiently allocate resources and iv) resolve deadlock situations.},
author = {{O 'grady}, Rehan and Pinciroli, Carlo and Gro{\ss}, Roderich and Christensen, Anders Lyhne and Mondada, Francesco and Bonani, Michael and Dorigo, Marco},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/O 'grady et al. - Unknown - Swarm-Bots to the Rescue.pdf:pdf},
title = {{Swarm-Bots to the Rescue}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132253/mod{\_}label/intro/Swarm-bots to the rescue {\%}28OGrady et al{\%}2C 09{\%}29.pdf}
}
@misc{Culurciello2017,
abstract = {Light Revision of network architectures through time},
author = {Culurciello, Eugenio},
keywords = {AI,AlexNET,Architecture,Inception,Neural Networks},
mendeley-tags = {AI,AlexNET,Architecture,Inception,Neural Networks},
pages = {5},
title = {{Neural Network Architectures – Towards Data Science – Medium}},
url = {https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba},
urldate = {2017-06-06},
year = {2017}
}
@article{Yang2017,
abstract = {We formulate language modeling as a matrix factorization problem, and show that the expressiveness of Softmax-based models (including the majority of neural language models) is limited by a Softmax bottleneck. Given that natural language is highly context-dependent, this further implies that in practice Softmax with distributed word embeddings does not have enough capacity to model natural language. We propose a simple and effective method to address this issue, and improve the state-of-the-art perplexities on Penn Treebank and WikiText-2 to 47.69 and 40.68 respectively. The proposed method also excels on the large-scale 1B Word dataset, outperforming the baseline by over 5.6 points in perplexity.},
annote = {Interesting: Mixtures of Softmaxes, how does it relate to Hierarchichal Softmaxes?},
archivePrefix = {arXiv},
arxivId = {1711.03953},
author = {Yang, Zhilin and Dai, Zihang and Salakhutdinov, Ruslan and Cohen, William W.},
eprint = {1711.03953},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - 2017 - Breaking the Softmax Bottleneck A High-Rank RNN Language Model.pdf:pdf},
month = {nov},
title = {{Breaking the Softmax Bottleneck: A High-Rank RNN Language Model}},
url = {http://arxiv.org/abs/1711.03953},
year = {2017}
}
@article{Blodow2013,
abstract = {Unstructured information management (UIM) has proven itself as a powerful para- digm for scaling intelligent information and question answering systems towards real-world complexity. Complexity in UIM is handled by identifying (or hypothesiz- ing) pieces of structured information in unstructured documents, by applying ensem- bles of experts for annotating information pieces, and by testing and integrating these isolated annotations into a comprehensive interpretation of the document. In this thesis the paradigm of unstructured information management is applied to the problem of robot perception of realistic scenes containing objects of daily use. In this view, the documents in UIM correspond to camera and depth images taken by the robot, the structured information pieces such as furniture pieces and objects to be manipulated to object hypotheses, and the ensembles of experts to sets of object perception methods. We believe that the application of the UIM principle to robot perception can achieve similar scaling effects as it did for intelligent information systems. We will present ROBOSHERLOCK, an open source software framework for unstruc- tured information processing in robot perception and sketch a feasibility study of a perception system built on top of the framework that indicates the potential of the paradigm for real-world scene perception. A large number of perception meth- ods have been implemented or integrated into ROBOSHERLOCK that span detection of different kinds of objects, annotators that compute appearance or spatial feature de- scriptors, shape classification, and object reconstruction as well as tracking and entity resolution methods. Web services have been incorporated to provide additional, vi- sual or non-visual information such as text and logo recognition, or product matches from online stores. The object descriptions obtained with ROBOSHERLOCK show a richness and versatility that we believe to be unrivaled in the field and is demonstrated within experiments over numerous scenes containing arrangements of objects of varying kinds.},
author = {Blodow, Nico},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blodow - 2013 - Managing Belief States for Service Robots Dynamic Scene Perception and Spatio-temporal Memory.pdf:pdf},
pages = {235},
title = {{Managing Belief States for Service Robots: Dynamic Scene Perception and Spatio-temporal Memory}},
year = {2013}
}
@article{Chickering2004,
abstract = {In this paper, we provide new complexity results for algorithms that learn discrete-variable Bayesian networks from data. Our results apply whenever the learning algorithm uses a scoring criterion that favors the simplest structure for which the model is able to represent the generative distribution ex-actly. Our results therefore hold whenever the learning algorithm uses a consistent scoring criterion and is applied to a sufficiently large dataset. We show that identifying high-scoring structures is NP-hard, even when any combination of one or more of the following hold: the generative distribution is perfect with respect to some DAG containing hidden variables; we are given an independence oracle; we are given an inference oracle; we are given an information oracle; we restrict potential solutions to structures in which each node has at most k parents, for all k ≥ 3. Our proof relies on a new technical result that we establish in the appendices. In particular, we provide a method for constructing the local distributions in a Bayesian network such that the resulting joint distribution is provably perfect with respect to the structure of the network.},
author = {Chickering, David Maxwell and Heckerman, David and Com, Meek@microsoft},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chickering, Heckerman, Com - 2004 - Large-Sample Learning of Bayesian Networks is NP-Hard Christopher Meek.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {NP-Hard,large-sample data,learning Bayesian networks,search complexity},
pages = {1287--1330},
title = {{Large-Sample Learning of Bayesian Networks is NP-Hard Christopher Meek}},
url = {http://www.maxchickering.com/publications/jmlr04a.pdf},
volume = {5},
year = {2004}
}
@article{Deng,
abstract = {The performance of an ACO depends extremely on the cognition of each subpath, which is represented by the pheromone trails. This paper designs an experiment to explore a subpath's exact role in the full-path generation. It gives three factors, sequential similarity ratio (SSR), iterative best similarity ratio (IBSR) and global best similarity ratio (GBSR), to evaluate some selected subpaths called r-rank subpaths in each iteration. The result shows that r-rank subpaths keep a rather stable proportion in the found best route. And then, by counting the crossed ants of a subpath in each iteration, a subpath-based pheromone modification rule is proposed to enhance the pheromone depositing strategy. It is combined with the iteration-best pheromone update rule to solve the traveling salesman problem (TSP), and experiments show that the new ACO has a good performance and robustness.},
author = {Deng, Xiangyang and Zhang, Limin and Feng, Jiawen},
doi = {10.1007/978-3-319-61824-1_28},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deng, Zhang, Feng - Unknown - An Improved Ant Colony Optimization with Subpath-Based Pheromone Modification Strategy.pdf:pdf},
keywords = {Ant colony optimization {\'{A}},Meta-heuristic algorithm {\'{A}},Pheromone trails,Subpath-based pheromone modification strategy {\'{A}},Travel salesman problem {\'{A}}},
title = {{An Improved Ant Colony Optimization with Subpath-Based Pheromone Modification Strategy}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1392651/mod{\_}label/intro/deng-acoWithSubpathPheromoneModification-2017.pdf}
}
@article{Szegedy2016,
abstract = {Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question of whether there are any benefit in combining the Inception architecture with residual connections. Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4, we achieve 3.08 percent top-5 error on the test set of the ImageNet classification (CLS) challenge},
archivePrefix = {arXiv},
arxivId = {1602.07261},
author = {Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alex},
doi = {10.1016/j.patrec.2014.01.008},
eprint = {1602.07261},
isbn = {0167-8655},
issn = {01678655},
title = {{Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning}},
year = {2016}
}
@article{radoevlama,
author = {Radoev, Nikolay and Tremblay, Mathieu and Zouaq, Amal and Gagnon, Michel},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Radoev et al. - 2018 - LAMA a Language Adaptive Method for Question Answering.pdf:pdf},
title = {{LAMA: a Language Adaptive Method for Question Answering}},
year = {2018}
}
@article{Wang2017,
author = {Wang, Quan and Mao, Zhendong and Wang, Bin and Guo, Li},
doi = {10.1109/TKDE.2017.2754499},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2017 - Knowledge Graph Embedding A Survey of Approaches and Applications(2).pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = {dec},
number = {12},
pages = {2724--2743},
title = {{Knowledge Graph Embedding: A Survey of Approaches and Applications}},
url = {http://ieeexplore.ieee.org/document/8047276/},
volume = {29},
year = {2017}
}
@article{Reijers2007,
abstract = {The assignment of tasks to human performers is a critical component in people-centric business process management systems. Workflow management systems typically assign work items using strategies that only consider qualified resources. There are, however, situations, where this approach falls short. For instance, in emergency response situations, tasks need to be carried out by resources that are available immediately, even if they do not match all skill requirements. This paper compares the performance of a set of six task assignment mechanisms for workflow applications using a scenario from the emergency management domain. In particular, we develop and simulate assignment strategies inspired by stimulus/response models derived from swarm intelligence, and benchmark these strategies against conventional task assignment strategies. Our findings show that swarm intelligence-based approaches outperform the traditional assignment of tasks in ad-hoc organizations, and that workflow-based emergency management systems could benefit significantly from these novel task assignment strategies.},
author = {Reijers, Hajo A and Jansen-Vullers, Monique H and {Zur Muehlen}, Michael and Appl, Winfried},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reijers et al. - 2007 - Workflow Management Systems Swarm Intelligence = Dynamic Task Assignment for Emergency Management Applications.pdf:pdf},
journal = {LNCS},
keywords = {Business Process Management,Swarm Intelligence,Task Assignment,Workflow},
pages = {125--140},
title = {{Workflow Management Systems + Swarm Intelligence = Dynamic Task Assignment for Emergency Management Applications}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132216/mod{\_}label/intro/reijers-workflowManagement.pdf},
volume = {4714},
year = {2007}
}
@article{Alonso2017,
abstract = {Bayesian networks learning is computationally expensive even in the case of sacrificing the optimality of the result. Many methods aim at obtaining quality solutions in affordable times. Most of them are based on local search algorithms, as they allow evaluating candidate networks in a very efficient way, and can be further improved by using local search-based metaheuristics to avoid getting stuck in local optima. This approach has been successfully applied in searching for network structures in the space of directed acyclic graphs. Other algorithms search for the networks in the space of equivalence classes. The most important of these is GES (Greedy Equivalence Search). It guarantees obtaining the optimal network under certain conditions. However, it can also get stuck in local optima when learning from datasets with limited size. This article proposes the use of local search-based metaheuristics as a way to improve the behaviour of GES in such circumstances. These methods also guarantee asymptotical optimality, and the experiments show that they improve upon the score of the networks obtained with GES.},
author = {Alonso, Juan I. and DelaOssa, Luis and G{\'{a}}mez, Jos{\'{e}} A. and Puerta, Jos{\'{e}} M.},
doi = {10.1016/j.asoc.2017.12.011},
issn = {15684946},
journal = {Applied Soft Computing},
month = {dec},
title = {{On the use of local search heuristics to improve GES-based Bayesian network learning}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1568494617307263},
year = {2017}
}
@article{Zou2005,
author = {Zou, M. and Conzen, S. D.},
doi = {10.1093/bioinformatics/bth463},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zou, Conzen - 2005 - A new dynamic Bayesian network (DBN) approach for identifying gene regulatory networks from time course microarray.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
month = {jan},
number = {1},
pages = {71--79},
publisher = {Oxford University Press},
title = {{A new dynamic Bayesian network (DBN) approach for identifying gene regulatory networks from time course microarray data}},
url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/bth463},
volume = {21},
year = {2005}
}
@book{Ripley1996,
abstract = {Subject: DSU Title III 2007-2012. Introduction and examples -- Statistical decision theory -- Linear discriminant analysis -- Flexible discriminants -- Feed-forward neural networks -- Non-parametric methods -- Tree-structured classifiers -- Belief networks -- Unsupervised methods -- Finding good pattern features.},
author = {Ripley, Brian D.},
isbn = {0521460867},
pages = {403},
publisher = {Cambridge University Press},
title = {{Pattern recognition and neural networks}},
url = {http://www.stats.ox.ac.uk/{~}ripley/PRbook/},
year = {1996}
}
@techreport{rapidly_exp_rand_trees,
author = {Lavalle, Steven M},
title = {{Rapidly-Exploring Random Trees: A New Tool for Path Planning}},
year = {1998}
}
@article{Leonard2000,
author = {Leonard, John J. and Leonard, John J. and Feder, Hans Jacob S.},
pages = {169----176},
title = {{A computationally efficient method for large-scale concurrent mapping and localization}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.122.4705},
year = {2000}
}
@article{Akaike1974,
author = {Akaike, H.},
doi = {10.1109/TAC.1974.1100705},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
month = {dec},
number = {6},
pages = {716--723},
title = {{A new look at the statistical model identification}},
url = {http://ieeexplore.ieee.org/document/1100705/},
volume = {19},
year = {1974}
}
@article{Lison2010a,
abstract = {To interact naturally with humans, robots need to be aware of their own surroundings. This awareness is usually encoded in some implicit or explicit representation of the situated context. In this paper, we present a new framework for constructing rich belief models of the robot's environment. Key to our approach is the use of Markov Logic as a unified framework for inference over these beliefs. Markov Logic is a combination of first-order logic and probabilistic graphical models. Its expressive power allows us to capture both the rich relational structure of the environment and the uncertainty arising from the noise and incompleteness of low-level sensory data. The constructed belief models evolve dynamically over time and incorporate various contextual information such as spatio-temporal framing, multi-agent epistemic status, and saliency measures. Beliefs can also be referenced and extended {\&}{\#}x201C;top-down{\&}{\#}x201D; via linguistic communication. The approach is being integrated into a cognitive architecture for mobile robots interacting with humans using spoken dialogue.},
author = {Lison, Pierre and Ehrler, Carsten and Kruijff, Geert Jan M.},
doi = {10.1109/ROMAN.2010.5598723},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lison, Ehrler, Kruijff - 2010 - Belief modelling for situation awareness in human-robot interaction(2).pdf:pdf},
isbn = {9781424479917},
issn = {1944-9445},
journal = {Proceedings - IEEE International Workshop on Robot and Human Interactive Communication},
number = {March 2010},
pages = {138--143},
title = {{Belief modelling for situation awareness in human-robot interaction}},
volume = {2010},
year = {2010}
}
@incollection{Font2011,
author = {Font, Jos{\'{e}} M. and Manrique, Daniel and Pascua, Eduardo},
doi = {10.1007/978-3-642-21344-1_7},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Font, Manrique, Pascua - 2011 - Grammar-Guided Evolutionary Construction of Bayesian Networks.pdf:pdf},
pages = {60--69},
publisher = {Springer, Berlin, Heidelberg},
title = {{Grammar-Guided Evolutionary Construction of Bayesian Networks}},
url = {http://link.springer.com/10.1007/978-3-642-21344-1{\_}7},
year = {2011}
}
@inproceedings{trivedi2017lc,
author = {Trivedi, Priyansh and Maheshwari, Gaurav and Dubey, Mohnish and Lehmann, Jens},
booktitle = {International Semantic Web Conference},
organization = {Springer},
pages = {210--218},
title = {{Lc-quad: A corpus for complex question answering over knowledge graphs}},
year = {2017}
}
@article{Yuan2013a,
abstract = {In this paper, learning a Bayesian network structure that optimizes a scoring function for a given dataset is viewed as a shortest path problem in an implicit state-space search graph. This perspective highlights the importance of two research issues: the development of search strategies for solving the shortest path problem, and the design of heuristic func-tions for guiding the search. This paper introduces several techniques for addressing the issues. One is an A* search algorithm that learns an optimal Bayesian network structure by only searching the most promising part of the solution space. The others are mainly two heuristic functions. The first heuristic function represents a simple relaxation of the acyclicity constraint of a Bayesian network. Although admissible and consistent, the heuris-tic may introduce too much relaxation and result in a loose bound. The second heuristic function reduces the amount of relaxation by avoiding directed cycles within some groups of variables. Empirical results show that these methods constitute a promising approach to learning optimal Bayesian network structures.},
author = {Yuan, Changhe and Malone, Brandon},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuan, Malone - 2013 - Learning Optimal Bayesian Networks A Shortest Path Perspective(2).pdf:pdf},
journal = {Journal of Artificial Intelligence Research},
pages = {23--65},
title = {{Learning Optimal Bayesian Networks: A Shortest Path Perspective}},
url = {https://www.jair.org/media/4039/live-4039-7355-jair.pdf},
volume = {48},
year = {2013}
}
@inproceedings{Rublee2011,
author = {Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
booktitle = {2011 International Conference on Computer Vision},
doi = {10.1109/ICCV.2011.6126544},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rublee et al. - 2011 - ORB An efficient alternative to SIFT or SURF.pdf:pdf},
isbn = {978-1-4577-1102-2},
month = {nov},
pages = {2564--2571},
publisher = {IEEE},
title = {{ORB: An efficient alternative to SIFT or SURF}},
url = {http://ieeexplore.ieee.org/document/6126544/},
year = {2011}
}
@article{Haberman,
abstract = {Sensor networks are traditionally built using battery-powered, collaborative devices. These sensor nodes do not rely on dedicated infrastructure services (e.g., rou-ters) to relay data. Rather, a communal effort is employed where the sensor nodes both generate data as well as for-ward data for other nodes. A routing protocol is needed in order for the sensors to determine viable paths through the network, but routing protocols designed for wired networks and even ad hoc networks are not sufficient given the energy overhead needed to operate them. We propose an energy-aware routing protocol, based on overlapping swarms of particles, that offers reliable path selection while reducing the energy consumption for the route selection process. Our particle-based routing with overlapping swarms for energy-efficiency algorithm shows promise in extending the life of battery-powered networks while still providing robust routing functionality to maintain network reliability.},
author = {Haberman, Brian K and Sheppard, John W},
doi = {10.1007/s11276-011-0404-1},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haberman, Sheppard - Unknown - Overlapping particle swarms for energy-efficient routing in sensor networks.pdf:pdf},
keywords = {Overlapping swarms {\'{A}},Quality-of-service,Routing {\'{A}},Sensor networks {\'{A}}},
title = {{Overlapping particle swarms for energy-efficient routing in sensor networks}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132260/mod{\_}label/intro/haberman-overlappingPSO-routingSensorNetwork-2012.pdf}
}
@article{Davis1993,
abstract = {Although knowledge representation is one of the central and, in some ways, most familiar concepts in AI, the most fundamental question about it -- What is it? -- has rarely been answered directly. Numerous papers have lobbied for one or another variety of representation, other papers have argued for various properties a representation should have, and still others have focused on properties that are important to the notion of representation in general. In this article, we go back to basics to address the question directly. We believe that the answer can best be understood in terms of five important and distinctly different roles that a representation plays, each of which places different and, at times, conflicting demands on the properties a representation should have. We argue that keeping in mind all five of these roles provides a usefully broad perspective that sheds light on some longstanding disputes and can invigorate both research and practice in the field.},
author = {Davis, Randall and Shrobe, Howard and Szolovits, Peter},
doi = {10.1609/AIMAG.V14I1.1029},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Davis, Shrobe, Szolovits - 1993 - What Is a Knowledge Representation.pdf:pdf},
issn = {0738-4602},
journal = {AI Magazine},
month = {mar},
number = {1},
pages = {17},
title = {{What Is a Knowledge Representation?}},
url = {https://www.aaai.org/ojs/index.php/aimagazine/article/view/1029},
volume = {14},
year = {1993}
}
@article{Choudhary,
abstract = {Recommendation Systems have found extensive use in today's web environment as they improve the overall user experience by providing users with personalized suggestions. Along with the traditional techniques like Col-laborative and Content-based filtering, researchers have explored computational intelligence techniques to improve the performance of recommendation systems. In this paper, a similar approach has been taken in the form of applying a heuristic based technique on recommendation systems. The paper proposes a recommendation system based on a less explored nature-inspired technique called Gravitational Search Algorithm. The performance of this system is compared with that of a system using Particle Swarm Optimisation, which is a similar optimisation technique. The results show that Gravitational Search Algorithm excels in improving the accuracy of the recommendation model and also surpasses the model using Particle Swarm Optimization.},
author = {Choudhary, Vedant and Mullick, Dhruv and Nagpal, Sushama},
doi = {10.1007/978-3-319-61833-3_63},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Choudhary, Mullick, Nagpal - Unknown - Gravitational Search Algorithm in Recommendation Systems.pdf:pdf},
keywords = {Algorithm {\'{A}},Collaborative filtering,Computational intelligence {\'{A}},Gravitational,Optimisation {\'{A}},Particle,Recommendation systems {\'{A}},Search,Swarm},
title = {{Gravitational Search Algorithm in Recommendation Systems}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1392651/mod{\_}label/intro/978-3-319-61833-3{\_}63.pdf}
}
@article{Suarez,
abstract = {Autonomous navigation (i.e., without human intervention) in indoor spaces such as houses and office buildings has many important applications; for instance, in areas affected by building collapse due to natural or artificial disasters. However, it is also a difficult task because any prescribed trajectory can be suddenly interrupted by unexpected obstacles. Arguably, a group of simple autonomous drones driven by swarm intelligence might be more efficient than a sophisticated robot for navigation within such environments. Based on this idea, this work presents a method that applies a powerful swarm intelligence tech-nique called bat algorithm to the autonomous coordinated navigation of a swarm of virtual bots in dynamic indoor environments. Some com-putational experiments are conducted to test the performance of this approach.},
author = {Su{\'{a}}rez, Patricia and G{\'{a}}lvez, Akemi and Iglesias, Andr{\'{e}}s},
doi = {10.1007/978-3-319-61833-3},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Su{\'{a}}rez, G{\'{a}}lvez, Iglesias - Unknown - Autonomous Coordinated Navigation of Virtual Swarm Bots in Dynamic Indoor Environments by Bat Alg.pdf:pdf},
keywords = {Autonomous coordi-nated navigation {\textperiodcentered},Bat algorithm {\textperiodcentered},Dynamic indoor scenes {\textperiodcentered},Swarm intelligence {\textperiodcentered},Virtual swarm bots},
title = {{Autonomous Coordinated Navigation of Virtual Swarm Bots in Dynamic Indoor Environments by Bat Algorithm}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1392651/mod{\_}label/intro/978-3-319-61833-3{\_}19.pdf}
}
@article{doi:10.1080/00031305.1992.10475879,
abstract = {Nonparametric regression is a set of techniques for es- timating a regression curve without making strong as- sumptions about the shape of the true regression func- tion. These techniques are therefore useful for building and checking parametric models, as well as for data description. Kernel and nearest-neighbor regression es- timators are local versions of univariate location esti- mators, and so they can readily be introduced to be- ginning students and consulting clients who are familiar with such summaries as the sample mean and median.},
author = {Altman, N. S.},
doi = {10.1080/00031305.1992.10475879},
isbn = {0003-1305},
issn = {0003-1305},
journal = {The American Statistician},
number = {3},
pages = {175--185},
title = {{An Introduction to Kernel and Nearest-Neighbor Nonparametric Regression}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1992.10475879},
volume = {46},
year = {1992}
}
@article{He2014,
abstract = {Though recent advanced convolutional neural networks (CNNs) have been improving the image recognition accuracy, the models are getting more complex and time-consuming. For real-world applications in industrial and commercial scenarios, engineers and developers are often faced with the requirement of constrained time budget. In this paper, we investigate the accuracy of CNNs under constrained time cost. Under this constraint, the designs of the network architectures should exhibit as trade-offs among the factors like depth, numbers of filters, filter sizes, etc. With a series of controlled comparisons, we progressively modify a baseline model while preserving its time complexity. This is also helpful for understanding the importance of the factors in network designs. We present an architecture that achieves very competitive accuracy in the ImageNet dataset (11.8{\%} top-5 error, 10-view test), yet is 20{\%} faster than "AlexNet" (16.0{\%} top-5 error, 10-view test).},
archivePrefix = {arXiv},
arxivId = {1412.1710},
author = {He, Kaiming and Sun, Jian},
eprint = {1412.1710},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He, Sun - 2014 - Convolutional Neural Networks at Constrained Time Cost.pdf:pdf},
month = {dec},
title = {{Convolutional Neural Networks at Constrained Time Cost}},
url = {http://arxiv.org/abs/1412.1710},
year = {2014}
}
@article{shen2015entity,
author = {Shen, Wei and Wang, Jianyong and Han, Jiawei},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shen, Wang, Han - 2015 - Entity linking with a knowledge base Issues, techniques, and solutions.pdf:pdf},
journal = {IEEE Transactions on Knowledge and Data Engineering},
number = {2},
pages = {443--460},
publisher = {IEEE},
title = {{Entity linking with a knowledge base: Issues, techniques, and solutions}},
volume = {27},
year = {2015}
}
@misc{clerc2000a,
annote = {http://clerc.maurice.free.fr/pso/pso tsp/Discrete PSO TSP.zip},
author = {Clerc, M},
title = {{Discrete Particle Swarm Optimization, illustrated by the Traveling Salesman Problem. Website}}
}
@article{Grisetti2007,
author = {Grisetti, Giorgio and Stachniss, Cyrill and Burgard, Wolfram},
doi = {10.1109/TRO.2006.889486},
issn = {1552-3098},
journal = {IEEE Transactions on Robotics},
month = {feb},
number = {1},
pages = {34--46},
title = {{Improved Techniques for Grid Mapping With Rao-Blackwellized Particle Filters}},
url = {http://ieeexplore.ieee.org/document/4084563/},
volume = {23},
year = {2007}
}
@article{Barsalou1986,
abstract = {In this article, we attempt to distinguish between the properties of moderator and mediator variables at a number of levels. First, we seek to make theorists and researchers aware of the importance of not using the terms moderator and mediator interchangeably by carefully elaborating, both conceptually and strategically, the many ways in which moderators and mediators differ. We then go beyond this largely pedagogical function and delineate the conceptual and strategic implications of making use of such distinctions with regard to a wide range of phenomena, including control and stress, attitudes, and personality traits. We also provide a specific compendium of analytic procedures appropriate for making the most effective use of the moderator and mediator distinction, both separately and in terms of a broader causal system that includes both moderators and mediators.},
author = {Barsalou, L W and Baron, R M and Kenny, D A},
doi = {10.1017/S0140525X99532147},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barsalou, Baron, Kenny - 1986 - Perceptual symbol systems.pdf:pdf},
isbn = {0140525X},
issn = {0140525X},
journal = {The Behavioral and brain sciences},
keywords = {analogue processing,and much more,categories,concepts,frames,imagery,images,in the power of,knowledge,much infe-,perception,pursuits makes learned men,representation,representations,rior to the average,sensory-motor,simulation,symbol grounding,symbol systems,the habit of abstract,visualization},
number = {4},
pages = {577--609; discussion 610--660},
pmid = {11301525},
title = {{Perceptual symbol systems.}},
volume = {22},
year = {1986}
}
@inproceedings{chen-etal-2014-feature,
address = {Dublin, Ireland},
author = {Chen, Wenliang and Zhang, Yue and Zhang, Min},
booktitle = {Proceedings of {\{}COLING{\}} 2014, the 25th International Conference on Computational Linguistics: Technical Papers},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Zhang, Zhang - 2014 - Feature Embedding for Dependency Parsing.pdf:pdf},
pages = {816--826},
publisher = {Dublin City University and Association for Computational Linguistics},
title = {{Feature Embedding for Dependency Parsing}},
url = {https://www.aclweb.org/anthology/C14-1078},
year = {2014}
}
@incollection{wang2003a,
author = {Wang, K P and Huang, L and Zhou, C G and {and W. Pang}},
booktitle = {Proc. 2nd Int. Conf. on Machine Learning and Cybernetics},
pages = {1583--1585},
title = {{Particle swarm optimization for traveling salesman problem}},
volume = {3}
}
@article{Campos2006,
author = {de Campos, Luis M.},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Campos - 2006 - A Scoring Function for Learning Bayesian Networks based on Mutual Information and Conditional Independence Tests.pdf:pdf},
issn = {ISSN 1533-7928},
journal = {Journal of Machine Learning Research},
number = {Oct},
pages = {2149--2187},
title = {{A Scoring Function for Learning Bayesian Networks based on Mutual Information and Conditional Independence Tests}},
url = {http://www.jmlr.org/papers/v7/decampos06a.html},
volume = {7},
year = {2006}
}
@article{Tang,
abstract = {This paper presents a stigmergetic search method for swarm robots, in which an indirect information interaction mechanism, namely stigmergy, is used for the coordination of swarm robots via the environ-ment. RFID tags are arranged in the environment as a carrier of the pheromone. Robots move in the environment while reading and writing pheromone that contain the search experience of robots. The reading and writing algorithms are established. The pheromone map can be used to guide robots' motion without any localization system, and it can be built by robots according to their search experience. The method is verified by ample numerical experiments. Results show the applicability of the stigmergy mechanism for swarm robots target search.},
author = {Tang, Qirong and Yu, Fangchao and Zhang, Yuan and Ding, Lu and Eberhard, Peter},
doi = {10.1007/978-3-319-61833-3},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tang et al. - Unknown - A Stigmergy Based Search Method for Swarm Robots.pdf:pdf},
keywords = {Pheromone {\textperiodcentered} RFID,Stigmergy {\textperiodcentered},Swarm robots {\textperiodcentered},Target search {\textperiodcentered}},
title = {{A Stigmergy Based Search Method for Swarm Robots}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1392651/mod{\_}label/intro/978-3-319-61833-3{\_}21.pdf}
}
@article{Srivastava2015,
abstract = {There is plenty of theoretical and empirical evidence that depth of neural networks is a crucial ingredient for their success. However, network training becomes more difficult with increasing depth and training of very deep networks remains an open problem. In this extended abstract, we introduce a new architecture designed to ease gradient-based training of very deep networks. We refer to networks with this architecture as highway networks, since they allow unimpeded information flow across several layers on "information highways". The architecture is characterized by the use of gating units which learn to regulate the flow of information through a network. Highway networks with hundreds of layers can be trained directly using stochastic gradient descent and with a variety of activation functions, opening up the possibility of studying extremely deep and efficient architectures.},
archivePrefix = {arXiv},
arxivId = {1505.00387},
author = {Srivastava, Rupesh Kumar and Greff, Klaus and Schmidhuber, J{\"{u}}rgen},
eprint = {1505.00387},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Srivastava, Greff, Schmidhuber - 2015 - Highway Networks.pdf:pdf},
month = {may},
title = {{Highway Networks}},
url = {http://arxiv.org/abs/1505.00387},
year = {2015}
}
@book{handbook,
author = {Siciliano, Bruno and Khatib, Oussama},
edition = {2nd},
isbn = {3319325507, 9783319325507},
publisher = {Springer Publishing Company, Incorporated},
title = {{Springer Handbook of Robotics}},
year = {2016}
}
@article{Lecun1998,
author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
doi = {10.1109/5.726791},
issn = {00189219},
journal = {Proceedings of the IEEE},
number = {11},
pages = {2278--2324},
title = {{Gradient-based learning applied to document recognition}},
url = {http://ieeexplore.ieee.org/document/726791/},
volume = {86},
year = {1998}
}
@book{Rumelhart1986a,
abstract = {Vol. 2 by James L. McClelland, David E. Rumelhart, and the PDP Research Group. "A Bradford book." v. 1. Foundations -- v. 2. Psychological and biological models.},
author = {Rumelhart, David E. and McClelland, James L. and {University of California}, San Diego. PDP Research Group.},
isbn = {9780262181204},
publisher = {MIT Press},
title = {{Parallel distributed processing : explorations in the microstructure of cognition}},
url = {https://mitpress.mit.edu/books/parallel-distributed-processing},
year = {1986}
}
@article{Wyatt2010,
abstract = {There are many different approaches to building a system that can engage in autonomous mental development. In this paper, we present an approach based on what we term self-understanding, by which we mean the explicit representation of and reasoning about what a system does and does not know, and how that knowledge changes under action. We present an architecture and a set of representations used in two robot systems that exhibit a limited degree of autonomous mental development, which we term self-extension. The contributions include: representations of gaps and uncertainty for specific kinds of knowledge, and a goal management and planning system for setting and achieving learning goals.},
author = {Wyatt, Jeremy L. and Aydemir, Alper and Brenner, Michael and Hanheide, Marc and Hawes, Nick and Jensfelt, Patric and Kristan, Matej and Kruijff, Geert Jan M. and Lison, Pierre and Pronobis, Andrzej and Sj{\"{o}}{\"{o}}, Kristoffer and Vrecko, Alen and Zender, Hendrik and Zillich, Michael and Skocaj, Danijel},
doi = {10.1109/TAMD.2010.2090149},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wyatt et al. - 2010 - Self-understanding and self-extension A systems and representational approach.pdf:pdf},
isbn = {1943-0604 VO  - 2},
issn = {19430604},
journal = {IEEE Transactions on Autonomous Mental Development},
keywords = {Architectures,representations,robot learning,robotics},
number = {4},
pages = {282--303},
title = {{Self-understanding and self-extension: A systems and representational approach}},
volume = {2},
year = {2010}
}
@inproceedings{artiles2007semeval,
author = {Artiles, Javier and Gonzalo, Julio and Sekine, Satoshi},
booktitle = {Proceedings of the fourth international workshop on semantic evaluations (semeval-2007)},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Artiles, Gonzalo, Sekine - 2007 - The semeval-2007 weps evaluation Establishing a benchmark for the web people search task.pdf:pdf},
pages = {64--69},
title = {{The semeval-2007 weps evaluation: Establishing a benchmark for the web people search task}},
year = {2007}
}
@article{and2009a,
author = {{M. Paolucci}, D.Anghinolfi},
journal = {European Journal of Operational Research},
pages = {73--85},
title = {{A new discrete particle swarm optimization approach for the single-machine total weighted tardiness scheduling problem with sequence-dependent setup times}},
volume = {193}
}
@article{Freedman2009,
author = {Freedman, Sanford T and Adams, Julie A},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Freedman, Adams - 2009 - HUMAN-INSPIRED ROBOTIC FORGETTING FILTERING TO IMPROVE ESTIMATION ACCURACY.pdf:pdf},
keywords = {artificial intelligence,filtering through human-inspired,forgetting,robot design and architecture,robot sensing and fusion,tential means of realizing},
pages = {434--441},
title = {{HUMAN-INSPIRED ROBOTIC FORGETTING : FILTERING TO IMPROVE ESTIMATION ACCURACY}},
year = {2009}
}
@article{Guivant2001,
author = {Guivant, J.E. and Nebot, E.M.},
doi = {10.1109/70.938382},
issn = {1042296X},
journal = {IEEE Transactions on Robotics and Automation},
month = {jun},
number = {3},
pages = {242--257},
title = {{Optimization of the simultaneous localization and map-building algorithm for real-time implementation}},
url = {http://ieeexplore.ieee.org/document/938382/},
volume = {17},
year = {2001}
}
@article{Lam1994,
author = {Lam, Wai and Bacchus, Fahiem},
doi = {10.1111/j.1467-8640.1994.tb00166.x},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lam, Bacchus - 1994 - LEARNING BAYESIAN BELIEF NETWORKS AN APPROACH BASED ON THE MDL PRINCIPLE.pdf:pdf},
issn = {0824-7935},
journal = {Computational Intelligence},
keywords = {Bayes nets,Key words: knowledge acquisition,uncertainty reasoning.},
month = {aug},
number = {3},
pages = {269--293},
publisher = {Blackwell Publishing Ltd},
title = {{LEARNING BAYESIAN BELIEF NETWORKS: AN APPROACH BASED ON THE MDL PRINCIPLE}},
url = {http://doi.wiley.com/10.1111/j.1467-8640.1994.tb00166.x},
volume = {10},
year = {1994}
}
@article{Yuan2013,
abstract = {In this paper, learning a Bayesian network structure that optimizes a scoring function for a given dataset is viewed as a shortest path problem in an implicit state-space search graph. This perspective highlights the importance of two research issues: the development of search strategies for solving the shortest path problem, and the design of heuristic func-tions for guiding the search. This paper introduces several techniques for addressing the issues. One is an A* search algorithm that learns an optimal Bayesian network structure by only searching the most promising part of the solution space. The others are mainly two heuristic functions. The first heuristic function represents a simple relaxation of the acyclicity constraint of a Bayesian network. Although admissible and consistent, the heuris-tic may introduce too much relaxation and result in a loose bound. The second heuristic function reduces the amount of relaxation by avoiding directed cycles within some groups of variables. Empirical results show that these methods constitute a promising approach to learning optimal Bayesian network structures.},
author = {Yuan, Changhe and Malone, Brandon},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yuan, Malone - 2013 - Learning Optimal Bayesian Networks A Shortest Path Perspective(2).pdf:pdf},
journal = {Journal of Artificial Intelligence Research},
pages = {23--65},
title = {{Learning Optimal Bayesian Networks: A Shortest Path Perspective}},
url = {https://www.jair.org/media/4039/live-4039-7355-jair.pdf},
volume = {48},
year = {2013}
}
@incollection{and1997a,
author = {{R. C. Eberhart}, J.Kennedy},
booktitle = {Proc. IEEE Int. Conf. on Systems, Man, and Cybernetics},
pages = {4104--4108},
title = {{A discrete binary version of the particle swarm algorithm}},
volume = {5}
}
@article{Barrena2018,
author = {Barrena, Ander and Soroa, Aitor and Agirre, Eneko},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barrena, Soroa, Agirre - 2018 - Learning Text Representations for {\{}500K{\}} Classification Tasks on Named Entity Disambiguation.pdf:pdf},
journal = {Proceedings of the 22nd Conference on Computational Natural Language Learning},
pages = {171--180},
title = {{Learning Text Representations for {\{}500K{\}} Classification Tasks on Named Entity Disambiguation}},
url = {https://aclanthology.coli.uni-saarland.de/papers/K18-1017/k18-1017},
year = {2018}
}
@article{Lewis,
author = {Lewis, Anthony and Bekey, George},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lewis, Bekey - Unknown - The Behavioral Self-Organization of Nanorobots Using Local Rules.pdf:pdf},
title = {{The Behavioral Self-Organization of Nanorobots Using Local Rules}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132260/mod{\_}label/intro/lewis-nanobotTumor-92.pdf}
}
@article{lecun1989,
address = {Cambridge, MA, USA},
author = {LeCun, Y and Boser, B and Denker, J S and Henderson, D and Howard, R E and Hubbard, W and Jackel, L D},
doi = {10.1162/neco.1989.1.4.541},
issn = {0899-7667},
journal = {Neural Comput.},
number = {4},
pages = {541--551},
publisher = {MIT Press},
title = {{Backpropagation Applied to Handwritten Zip Code Recognition}},
url = {http://dx.doi.org/10.1162/neco.1989.1.4.541},
volume = {1},
year = {1989}
}
@article{Gauci,
abstract = {We present a method for a large-scale robot collective to autonomously form a wide range of user-specified shapes. In contrast to most existing work, our method uses a subtractive approach rather than an additive one, and is the first such method to be demonstrated on robots that operate in continuous space. An initial dense, stationary configuration of robots distributively forms a coordinate system, and each robot decides if it is part of the desired shape. Non-shape robots then re-move themselves from the configuration using a single external light source as a motion guide. The subtractive approach allows for a higher degree of motion paral-lelism than additive approaches; it is also tolerant of much lower-precision motion. Experiments with 725 Kilobot robots allow us to compare our method against an additive one that was previously evaluated on the same platform. The subtractive method leads to higher reliability and an order-of-magnitude improvement in shape formation speed.},
author = {Gauci, Melvin and Nagpal, Radhika and Rubenstein, Michael},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gauci, Nagpal, Rubenstein - Unknown - Programmable Self-Disassembly for Shape Formation in Large-Scale Robot Collectives.pdf:pdf},
title = {{Programmable Self-Disassembly for Shape Formation in Large-Scale Robot Collectives}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132229/mod{\_}label/intro/{\%}23{\%}23 dars2016.pdf}
}
@inproceedings{Moravec:1981:RVO:1623264.1623304,
address = {San Francisco, CA, USA},
author = {Moravec, Hans P},
booktitle = {Proceedings of the 7th International Joint Conference on Artificial Intelligence - Volume 2},
pages = {785--790},
publisher = {Morgan Kaufmann Publishers Inc.},
series = {IJCAI'81},
title = {{Rover Visual Obstacle Avoidance}},
url = {http://dl.acm.org/citation.cfm?id=1623264.1623304},
year = {1981}
}
@article{Bengio:1994:LLD:2325857.2328340,
address = {Piscataway, NJ, USA},
author = {Bengio, Y and Simard, P and Frasconi, P},
doi = {10.1109/72.279181},
issn = {1045-9227},
journal = {Trans. Neur. Netw.},
number = {2},
pages = {157--166},
publisher = {IEEE Press},
title = {{Learning Long-term Dependencies with Gradient Descent is Difficult}},
url = {http://dx.doi.org/10.1109/72.279181},
volume = {5},
year = {1994}
}
@article{Simonyan2015,
abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3 × 3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16–19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisa-tion and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facili-tate further research on the use of deep visual representations in computer vision.},
archivePrefix = {arXiv},
arxivId = {arXiv:1409.1556v6},
author = {Simonyan, Karen and Zisserman, Andrew},
eprint = {arXiv:1409.1556v6},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Simonyan, Zisserman - 2015 - VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION.pdf:pdf},
keywords = {()},
title = {{VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION}},
url = {https://arxiv.org/pdf/1409.1556.pdf},
year = {2015}
}
@article{Goldberger,
abstract = {In this paper we propose a novel method for learning a Mahalanobis distance measure to be used in the KNN classification algorithm. The algorithm directly maximizes a stochastic variant of the leave-one-out KNN score on the training set. It can also learn a low-dimensional lin-ear embedding of labeled data that can be used for data visualization and fast classification. Unlike other methods, our classification model is non-parametric, making no assumptions about the shape of the class distributions or the boundaries between them. The performance of the method is demonstrated on several data sets, both for metric learning and linear dimensionality reduction.},
author = {Goldberger, Jacob and Roweis, Sam and Hinton, Geoff and Salakhutdinov, Ruslan},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goldberger et al. - 2005 - Neighbourhood Components Analysis.pdf:pdf},
title = {{Neighbourhood Components Analysis}},
url = {http://papers.nips.cc/paper/2566-neighbourhood-components-analysis.pdf},
year = {2005}
}
@article{Sauter,
abstract = {The use of digital pheromones for controlling and coordinating swarms of unmanned ve-hicles has been studied under various conditions demonstrating their effectiveness in multi-ple military scenarios in simulation. An experiment was conducted to verify that these same algorithms could effectively coordinate unmanned vehicles in a simulated exercise. Two air vehicles (modified target drones) controlled by digital pheromones and four ground robots controlled by a related stigmergic algorithm successfully executed a two-hour multi-mission surveillance, patrol, target acquisition, and tracking scenario without any scripting. The ve-hicles were given only high-level instructions, such as " survey this area and identify and track any targets " or " patrol around this convoy " . The air vehicles were able to dynamically adapt to new commands and coordinate their actions with each other and the ground robots to achieve the objectives. The algorithm's robustness was demonstrated when it dynamically adjusted to the unplanned failure of one of the ground robots without any operator interven-tion.},
author = {Sauter, John A and Matthews, Robert and {Dyke Parunak}, H Van and Brueckner, Sven A},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sauter et al. - Unknown - Demonstration of Digital Pheromone Swarming Control of Multiple Unmanned Air Vehicles.pdf:pdf},
title = {{Demonstration of Digital Pheromone Swarming Control of Multiple Unmanned Air Vehicles}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1327632/mod{\_}label/intro/Digital pheromones for vehicle control {\%}28Sauter et al{\%}2C 05{\%}29 II.pdf}
}
@article{Daly2011,
author = {Daly, R{\'{o}}n{\'{a}}n and Shen, Qiang and Aitken, Stuart},
doi = {10.1017/S0269888910000251},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daly, Shen, Aitken - 2011 - Learning Bayesian networks approaches and issues.pdf:pdf},
issn = {0269-8889},
journal = {The Knowledge Engineering Review},
month = {jun},
number = {02},
pages = {99--157},
title = {{Learning Bayesian networks: approaches and issues}},
url = {http://www.journals.cambridge.org/abstract{\_}S0269888910000251},
volume = {26},
year = {2011}
}
@inproceedings{Haus2016a,
author = {Haus, Tomislav and Orsag, Matko and Bogdan, Stjepan},
booktitle = {2016 International Conference on Unmanned Aircraft Systems (ICUAS)},
doi = {10.1109/ICUAS.2016.7502680},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haus, Orsag, Bogdan - 2016 - Design considerations for a large quadrotor with moving mass control.pdf:pdf},
isbn = {978-1-4673-9334-8},
month = {jun},
pages = {1327--1334},
publisher = {IEEE},
title = {{Design considerations for a large quadrotor with moving mass control}},
url = {http://ieeexplore.ieee.org/document/7502680/},
year = {2016}
}
@article{Bojanowski2016,
abstract = {Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character {\$}n{\$}-grams. A vector representation is associated to each character {\$}n{\$}-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.},
archivePrefix = {arXiv},
arxivId = {1607.04606},
author = {Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
eprint = {1607.04606},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bojanowski et al. - 2016 - Enriching Word Vectors with Subword Information.pdf:pdf},
month = {jul},
title = {{Enriching Word Vectors with Subword Information}},
url = {http://arxiv.org/abs/1607.04606},
year = {2016}
}
@article{raczko2017,
abstract = {ABSTRACTKnowledge of tree species composition in a forest is an important topic in forest management. Accurate tree species maps allow for much more detailed and in-depth analysis of biophysical forest variables. The paper presents a comparison of three classification algorithms: support vector machines (SVM), random forest (RF) and artificial neural networks (ANN) for tree species classification using airborne hyperspectral data from the Airborne Prism EXperiment sensor. The aim of this paper is to evaluate the three nonparametric classification algorithms (SVM, RF and ANN) in an attempt to classify the five most common tree species of the Szklarska Por{\c{e}}ba area: spruce (Picea alba L. Karst), larch (Larix decidua Mill.), alder (Alnus Mill), beech (Fagus sylvatica L.) and birch (Betula pendula Roth). To avoid human introduced biases a 0.632 bootstrap procedure was used during evaluation of each compared classifier. Of all compared classification results, ANN achieved the highest median overall classificati...},
author = {Raczko, Edwin and Zagajewski, Bogdan},
doi = {10.1080/22797254.2017.1299557},
issn = {2279-7254},
journal = {European Journal of Remote Sensing},
keywords = {Support vector machines,artificial neural networks,classification,hyperspectral data,random forest},
month = {jan},
number = {1},
pages = {144--154},
publisher = {Taylor {\&} Francis},
title = {{Comparison of support vector machine, random forest and neural network classifiers for tree species classification on airborne hyperspectral APEX images}},
url = {https://www.tandfonline.com/doi/full/10.1080/22797254.2017.1299557},
volume = {50},
year = {2017}
}
@inproceedings{P18-1001,
author = {Athiwaratkun, Ben and Wilson, Andrew and Anandkumar, Anima},
booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Athiwaratkun, Wilson, Anandkumar - 2018 - Probabilistic FastText for Multi-Sense Word Embeddings.pdf:pdf},
pages = {1--11},
publisher = {Association for Computational Linguistics},
title = {{Probabilistic FastText for Multi-Sense Word Embeddings}},
url = {http://aclweb.org/anthology/P18-1001},
year = {2018}
}
@incollection{ji2011a,
author = {Ji, Heng and Grishman, Ralph and {and Hoa Trang Dang}},
booktitle = {Proc. of the 4th Text Analysis Conference, TAC 11},
title = {{Overview of the TAC 2011 knowledge base population track}},
year = {2011}
}
@article{Zhang2019a,
abstract = {The latest work on language representations carefully integrates contextualized features into language model training, which enables a series of success especially in various machine reading comprehension and natural language inference tasks. However, the existing language representation models including ELMo, GPT and BERT only exploit plain context-sensitive features such as character or word embeddings. They rarely consider incorporating structured semantic information which can provide rich semantics for language representation. To promote natural language understanding, we propose to incorporate explicit contextual semantics from pre-trained semantic role labeling, and introduce an improved language representation model, Semantics-aware BERT (SemBERT), which is capable of explicitly absorbing contextual semantics over a BERT backbone. SemBERT keeps the convenient usability of its BERT precursor in a light fine-tuning way without substantial task-specific modifications. Compared with BERT, semantics-aware BERT is as simple in concept but more powerful. It obtains new state-of-the-art or substantially improves results on ten reading comprehension and language inference tasks.},
archivePrefix = {arXiv},
arxivId = {1909.02209},
author = {Zhang, Zhuosheng and Wu, Yuwei and Zhao, Hai and Li, Zuchao and Zhang, Shuailiang and Zhou, Xi and Zhou, Xiang},
eprint = {1909.02209},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2019 - Semantics-aware BERT for Language Understanding.pdf:pdf},
month = {sep},
title = {{Semantics-aware BERT for Language Understanding}},
url = {http://arxiv.org/abs/1909.02209},
year = {2019}
}
@inproceedings{YanKe,
author = {{Yan Ke} and Sukthankar, R.},
booktitle = {Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.},
doi = {10.1109/CVPR.2004.1315206},
isbn = {0-7695-2158-4},
pages = {506--513},
publisher = {IEEE},
title = {{PCA-SIFT: a more distinctive representation for local image descriptors}},
url = {http://ieeexplore.ieee.org/document/1315206/},
volume = {2},
year = {2004}
}
@article{Nguyen2017,
abstract = {Knowledge bases (KBs) of real-world facts about entities and their relationships are useful resources for a variety of natural language processing tasks. However, because knowledge bases are typically incomplete, it is useful to be able to perform knowledge base completion or link prediction, i.e., predict whether a relationship not in the knowledge base is likely to be true. This article serves as a brief overview of embedding models of entities and relationships for knowledge base completion, summarizing up-to-date experimental results on standard benchmark datasets FB15k, WN18, FB15k-237, WN18RR, FB13 and WN11.},
archivePrefix = {arXiv},
arxivId = {1703.08098},
author = {Nguyen, Dat Quoc},
eprint = {1703.08098},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nguyen - 2017 - An overview of embedding models of entities and relationships for knowledge base completion.pdf:pdf},
month = {mar},
title = {{An overview of embedding models of entities and relationships for knowledge base completion}},
url = {http://arxiv.org/abs/1703.08098},
year = {2017}
}
@article{Rubenstein2014a,
abstract = {only map of any DIB carrier at this scale and the only one taking the distance information as a major parameter. Together with the measured scale height, this is the first 3D study of the spa-tial distribution of the DIB-bearing ISM clouds. The projected distribution of the extinction due to the interstellar dust is markedly similar to that of the DIB carrier [see (26) for the cor-relation analysis], confirming the strong corre-spondence between the two (32). The map of the extinction is itself an advance, as it maps the regions out of the Galactic plane and probes dust to greater distances than present maps (33) of these regions and is consistent with maps in the literature. Our success in producing the maps of the DIB carrier implies good prospects for future spectroscopic surveys (14–16) that will produce similar (15) or better quality (14, 16) spectra and will also rely on DIBs to provide in-formation about the ISM. Our work opens new possibilities in the study of DIBs and also offers a unique way of comparing DIBs with other in-terstellar species by studying their out-of-plane distribution. This can be translated into the study of physical and chemical properties of DIB car-riers in the near future. The measured 3D distribution, especially the unexpectedly high scale-height of the DIB 8620 carrier, calls for a theoretical explanation. There are two options—either the DIB carriers migrate to their observed distances from the Galactic plane, or they are created at these large dis-tances, from components of the ISM having a similar distribution. The latter is simpler to discuss, as it does not require knowledge of the chemistry of the DIB carrier or processes in which the carriers are involved. Khoperskov and Shchekinov (34) showed that mechanisms res-ponsible for dust migration to high altitudes above the Galactic plane segregate small dust particles from large ones, so the small ones form a thicker disk. This is also consistent with the observations of the extinction and reddening at high Galactic latitudes (35).},
author = {Rubenstein, Michael},
doi = {10.1126/science.1254295},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rubenstein - 2014 - Programmable self-assembly in a thousand-robot swarm.pdf:pdf},
number = {36},
pages = {19--73},
title = {{Programmable self-assembly in a thousand-robot swarm - Review}},
url = {http://www.sciencemag.org/content/345/6198/795.full.html},
volume = {795},
year = {2014}
}
@article{Parpinelli2002,
abstract = {—This paper proposes an algorithm for data mining called Ant-Miner (ant-colony-based data miner). The goal of Ant-Miner is to extract classification rules from data. The algorithm is inspired by both research on the behavior of real ant colonies and some data mining concepts as well as principles. We compare the performance of Ant-Miner with CN2, a well-known data mining algorithm for classification, in six public domain data sets. The re-sults provide evidence that: 1) Ant-Miner is competitive with CN2 with respect to predictive accuracy and 2) the rule lists discovered by Ant-Miner are considerably simpler (smaller) than those dis-covered by CN2.},
author = {Parpinelli, Rafael S and Lopes, Heitor S and Freitas, Alex A},
doi = {10.1109/TEVC.2002.802452},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parpinelli, Lopes, Freitas - 2002 - Data Mining With an Ant Colony Optimization Algorithm.pdf:pdf},
journal = {IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTING},
keywords = {Index Terms—Ant colony optimization,classification,data mining,knowledge discovery},
number = {4},
title = {{Data Mining With an Ant Colony Optimization Algorithm}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132239/mod{\_}label/intro/parpineli-acoDataMining-2002.pdf},
volume = {6},
year = {2002}
}
@article{Goldbergera,
abstract = {In this paper we propose a novel method for learning a Mahalanobis distance measure to be used in the KNN classification algorithm. The algorithm directly maximizes a stochastic variant of the leave-one-out KNN score on the training set. It can also learn a low-dimensional lin-ear embedding of labeled data that can be used for data visualization and fast classification. Unlike other methods, our classification model is non-parametric, making no assumptions about the shape of the class distributions or the boundaries between them. The performance of the method is demonstrated on several data sets, both for metric learning and linear dimensionality reduction.},
author = {Goldberger, Jacob and Roweis, Sam and Hinton, Geoff and Salakhutdinov, Ruslan},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goldberger et al. - 2005 - Neighbourhood Components Analysis.pdf:pdf},
title = {{Neighbourhood Components Analysis}},
url = {http://papers.nips.cc/paper/2566-neighbourhood-components-analysis.pdf},
year = {2004}
}
@book{Blake1992,
abstract = {Tracking with Kalman snakes / Demetri Terzopolous and Richard Szeliski -- Deformable templates / Alan Yuille and Peter Hallinan -- Dynamic contours : real-time active splines / Rupert Curwen and Andrew Blake -- Tracking with rigid models / Chris Harris -- Tracking nonrigid 3D objects / Demetri Terzopoloous and Dimitri Metaxas -- Data association methods for tracking systems / Bobby Rao -- Color region tracking for vehicle guidance / Jill D. Crisman -- Real-time smooth pursuit tracking / Christopher Brown, David Coombs and John Soong -- Attentive visual servoing / James J. Clark and Nicola J. Ferrier -- Design of stereo heads / David W. Murray [and oBlake, A., {\&} Yuille, A. L. (Alan L. . (1992). Active vision. MIT Press. Retrieved from https://mitpress.mit.edu/books/active-visionthers] -- Visual exploration of free-space / Andrew Blake, Andrew Zisserman and Roberto Cipolla -- Motion planning using image divergence and deformation / Roberto Cipolla and Andrew Blake -- Adaptive local navigation / Tony Prescott and John Mayhew. Task-oriented vision with multiple Bayes nets / Raymond Rimey and Christopher Brown -- A parallel 3D vision system / Michael Rygol [and others] -- Geometry from visual motion / Chris Harris -- Medical image tracking / Nicholas Ayache, Isaac Cohen and Isabelle Herlin -- Expectation-based dynamic scene understanding / Ernst D. Dickmanns.},
author = {Blake, Andrew and Yuille, A. L. (Alan L.)},
isbn = {9780262023511},
publisher = {MIT Press},
title = {{Active vision}},
url = {https://mitpress.mit.edu/books/active-vision},
year = {1992}
}
@article{Jaakkola,
abstract = {We propose to solve the combinatorial prob-lem of finding the highest scoring Bayesian network structure from data. This structure learning problem can be viewed as an infer-ence problem where the variables specify the choice of parents for each node in the graph. The key combinatorial difficulty arises from the global constraint that the graph struc-ture has to be acyclic. We cast the structure learning problem as a linear program over the polytope defined by valid acyclic struc-tures. In relaxing this problem, we maintain an outer bound approximation to the poly-tope and iteratively tighten it by searching over a new class of valid constraints. If an integral solution is found, it is guaranteed to be the optimal Bayesian network. When the relaxation is not tight, the fast dual al-gorithms we develop remain useful in com-bination with a branch and bound method. Empirical results suggest that the method is competitive or faster than alternative exact methods based on dynamic programming.},
author = {Jaakkola, Tommi and Sontag, David and Globerson, Amir and Meila, Marina},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaakkola et al. - Unknown - Learning Bayesian Network Structure using LP Relaxations.pdf:pdf},
title = {{Learning Bayesian Network Structure using LP Relaxations}},
url = {http://proceedings.mlr.press/v9/jaakkola10a/jaakkola10a.pdf},
year = {2010}
}
@article{Haralick1973,
abstract = {Texture is one of the important characteristics used in identifying onject or regions of interest in an image, whether the image be a photomicrograph, an aerial photograph, or a satellite image. This paper describes some easily computable textural features based on gray-tone spatial dependancies, and illustrates their application in category identification tasks of three different kinds of image data: photomicrographs of five kinds of sandstones, 1:20 000 pancromatic aerial photographs of eight land-use categories, and Earth Resources Technology Satellite (ERTS) multispectral imagery containing seven land-use categories. We use two kinds of decisions rules: one for which the decision regions are convex polyhedra (a piecewise linear decision rule), and one for which the decision regions are rectangular parallelpipeds (a min-max decision rule). In each experiment the data set was divided into two parts, a training set and a test set. Test set identification accuracy is 89 percent for photomicrographs, 82 percent for aerial photographic imagery, and 83 percent for satellite imagery. These results indicate that the easily computable textural features probably have a general applicability for a wide variety of image-classification application.},
author = {Haralick, Robert M. and Shanmugam, K. and Dinstein, Its'Hak},
doi = {10.1109/TSMC.1973.4309314},
isbn = {0018-9472},
issn = {0018-9472},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
number = {6},
pages = {610--621},
pmid = {283},
title = {{Textural Features for Image Classification}},
url = {http://ieeexplore.ieee.org/document/4309314/},
volume = {SMC-3},
year = {1973}
}
@inproceedings{baldwin2015twitter,
address = {Beijing, China},
author = {Baldwin, Timothy and de Marneffe, Marie-Catherine and Han, Bo and Kim, Young-Bum and Ritter, Alan and Xu, Wei},
booktitle = {Proceedings of the Workshop on Noisy User-generated Text},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baldwin et al. - 2015 - Shared Tasks of the 2015 Workshop on Noisy User-generated Text Twitter Lexical Normalization and Named Entity Re.pdf:pdf},
pages = {126--135},
publisher = {Association for Computational Linguistics},
title = {{Shared Tasks of the 2015 Workshop on Noisy User-generated Text: Twitter Lexical Normalization and Named Entity Recognition}},
url = {http://www.aclweb.org/anthology/W15-4319},
year = {2015}
}
@article{bernard2012,
author = {Bernard, Simon and Adam, S{\'{e}}bastien and Heutte, Laurent},
doi = {10.1016/J.PATREC.2012.04.003},
issn = {0167-8655},
journal = {Pattern Recognition Letters},
month = {sep},
number = {12},
pages = {1580--1586},
publisher = {North-Holland},
title = {{Dynamic Random Forests}},
url = {http://www.sciencedirect.com/science/article/pii/S0167865512001274},
volume = {33},
year = {2012}
}
@article{Hessel2017,
abstract = {The deep reinforcement learning community has made several independent improvements to the DQN algorithm. However, it is unclear which of these extensions are complementary and can be fruitfully combined. This paper examines six extensions to the DQN algorithm and empirically studies their combination. Our experiments show that the combination provides state-of-the-art performance on the Atari 2600 benchmark, both in terms of data efficiency and final performance. We also provide results from a detailed ablation study that shows the contribution of each component to overall performance.},
archivePrefix = {arXiv},
arxivId = {1710.02298},
author = {Hessel, Matteo and Modayil, Joseph and van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
eprint = {1710.02298},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hessel et al. - 2017 - Rainbow Combining Improvements in Deep Reinforcement Learning.pdf:pdf},
month = {oct},
title = {{Rainbow: Combining Improvements in Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1710.02298},
year = {2017}
}
@article{FISHER1938,
abstract = {The articles published by the Annals of Eugenics (1925–1954) have been made available online as an historical archive intended for scholarly use. The work of eugenicists was often pervaded by prejudice against racial, ethnic and disabled groups. The online publication of this material for scholarly research purposes is not an endorsement of those views nor a promotion of eugenics in any way.},
author = {FISHER, R. A.},
doi = {10.1111/j.1469-1809.1938.tb02189.x},
issn = {20501420},
journal = {Annals of Eugenics},
number = {4},
pages = {376--386},
title = {{THE STATISTICAL UTILIZATION OF MULTIPLE MEASUREMENTS}},
url = {http://doi.wiley.com/10.1111/j.1469-1809.1938.tb02189.x},
volume = {8},
year = {1938}
}
@inproceedings{pennington2014glove,
author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pennington, Socher, Manning - 2014 - GloVe Global Vectors for Word Representation.pdf:pdf},
pages = {1532--1543},
title = {{GloVe: Global Vectors for Word Representation}},
url = {http://www.aclweb.org/anthology/D14-1162},
year = {2014}
}
@article{Sugawara,
abstract = {Collective construction is one interesting topic for swarm robots. We proposed a novel method for it introducing simple robots and relatively intelligent blocks. The blocks are assumed to have a processor, memory and communication device, and assemble the designed structure by controlling the growth direction of which the robot places the next block. The robots just load a block stochasti‐ cally, and they are conducted to unload the block by the block that forms the structure. We first explain the mechanism of our proposal, and show some funda‐ mental characteristics achieved by computer simulation. Next we explain a robot and blocks which enable to construct the small scale structure in real world.},
author = {Sugawara, Ken and Doi, Yohei},
doi = {10.1007/978-3-319-43506-0_40},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sugawara, Doi - Unknown - Collective Construction by Cooperation of Simple Robots and Intelligent Blocks.pdf:pdf},
keywords = {Collective construction {\textperiodcentered},Intelligent block,Swarm robots {\textperiodcentered}},
title = {{Collective Construction by Cooperation of Simple Robots and Intelligent Blocks}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132229/mod{\_}label/intro/chp{\%}253A10.1007{\%}252F978-3-319-43506-0{\_}40.pdf}
}
@inproceedings{Gardner2015,
address = {Stroudsburg, PA, USA},
author = {Gardner, Matt and Mitchell, Tom},
booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
doi = {10.18653/v1/D15-1173},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gardner, Mitchell - 2015 - Efficient and Expressive Knowledge Base Completion Using Subgraph Feature Extraction.pdf:pdf},
pages = {1488--1498},
publisher = {Association for Computational Linguistics},
title = {{Efficient and Expressive Knowledge Base Completion Using Subgraph Feature Extraction}},
url = {http://aclweb.org/anthology/D15-1173},
year = {2015}
}
@article{Cortes1995a,
author = {Cortes, Corinna and Vapnik, Vladimir},
doi = {10.1007/BF00994018},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cortes, Vapnik - 1995 - Support-vector networks.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
month = {sep},
number = {3},
pages = {273--297},
publisher = {Kluwer Academic Publishers},
title = {{Support-vector networks}},
url = {http://link.springer.com/10.1007/BF00994018},
volume = {20},
year = {1995}
}
@article{Sabour2017,
abstract = {A capsule is a group of neurons whose activity vector represents the instantiation parameters of a specific type of entity such as an object or an object part. We use the length of the activity vector to represent the probability that the entity exists and its orientation to represent the instantiation parameters. Active capsules at one level make predictions, via transformation matrices, for the instantiation parameters of higher-level capsules. When multiple predictions agree, a higher level capsule becomes active. We show that a discrimininatively trained, multi-layer capsule system achieves state-of-the-art performance on MNIST and is considerably better than a convolutional net at recognizing highly overlapping digits. To achieve these results we use an iterative routing-by-agreement mechanism: A lower-level capsule prefers to send its output to higher level capsules whose activity vectors have a big scalar product with the prediction coming from the lower-level capsule.},
archivePrefix = {arXiv},
arxivId = {1710.09829},
author = {Sabour, Sara and Frosst, Nicholas and Hinton, Geoffrey E},
eprint = {1710.09829},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sabour, Frosst, Hinton - 2017 - Dynamic Routing Between Capsules.pdf:pdf},
month = {oct},
title = {{Dynamic Routing Between Capsules}},
url = {http://arxiv.org/abs/1710.09829},
year = {2017}
}
@article{Hancock2019,
abstract = {The majority of conversations a dialogue agent sees over its lifetime occur after it has already been trained and deployed, leaving a vast store of potential training signal untapped. In this work, we propose the self-feeding chatbot, a dialogue agent with the ability to extract new training examples from the conversations it participates in. As our agent engages in conversation, it also estimates user satisfaction in its responses. When the conversation appears to be going well, the user's responses become new training examples to imitate. When the agent believes it has made a mistake, it asks for feedback; learning to predict the feedback that will be given improves the chatbot's dialogue abilities further. On the PersonaChat chit-chat dataset with over 131k training examples, we find that learning from dialogue with a self-feeding chatbot significantly improves performance, regardless of the amount of traditional supervision.},
archivePrefix = {arXiv},
arxivId = {1901.05415},
author = {Hancock, Braden and Bordes, Antoine and Mazare, Pierre-Emmanuel and Weston, Jason},
eprint = {1901.05415},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hancock et al. - 2019 - Learning from Dialogue after Deployment Feed Yourself, Chatbot!.pdf:pdf},
month = {jan},
title = {{Learning from Dialogue after Deployment: Feed Yourself, Chatbot!}},
url = {http://arxiv.org/abs/1901.05415},
year = {2019}
}
@article{Liu2016,
abstract = {Attention-based encoder-decoder neural network models have recently shown promising results in machine translation and speech recognition. In this work, we propose an attention-based neural network model for joint intent detection and slot filling, both of which are critical steps for many speech understanding and dialog systems. Unlike in machine translation and speech recognition, alignment is explicit in slot filling. We explore different strategies in incorporating this alignment information to the encoder-decoder framework. Learning from the attention mechanism in encoder-decoder model, we further propose introducing attention to the alignment-based RNN models. Such attentions provide additional information to the intent classification and slot label prediction. Our independent task models achieve state-of-the-art intent detection error rate and slot filling F1 score on the benchmark ATIS task. Our joint training model further obtains 0.56{\%} absolute (23.8{\%} relative) error reduction on intent detection and 0.23{\%} absolute gain on slot filling over the independent task models.},
archivePrefix = {arXiv},
arxivId = {1609.01454},
author = {Liu, Bing and Lane, Ian},
eprint = {1609.01454},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu, Lane - 2016 - Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling.pdf:pdf},
month = {sep},
title = {{Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling}},
url = {http://arxiv.org/abs/1609.01454},
year = {2016}
}
@article{Vizine2005,
abstract = {Among the many bio-inspired techniques, ant-based clustering algorithms have received special atten-tion from the community over the past few years for two main reasons. First, they are particularly suit-able to perform exploratory data analysis and, second, they still require much investigation to improve performance, stability, convergence, and other key features that would make such algorithms mature tools for diverse applications. Under this perspective, this paper proposes both a progressive vision scheme and pheromone heuristics for the standard ant-clustering algorithm, together with a cooling schedule that improves its convergence properties. The proposed algorithm is evaluated in a number of well-known benchmark data sets, as well as in a real-world bioinformatics dataset. The achieved results are compared to those obtained by the standard ant clustering algorithm, showing that significant im-provements are obtained by means of the proposed modifications. As an additional contribution, this work also provides a brief review of ant-based clustering algorithms. Povzetek: {\v{C}}lanek opisuje izbolj{\v{s}}an algoritem grupiranja na osnovi pristopa kolonij mravelj.},
author = {Vizine, Andr{\'{e}} L and {De Castro}, Leandro N and Hruschka, Eduardo R and Gudwin, Ricardo R},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vizine et al. - 2005 - Towards Improving Clustering Ants An Adaptive Ant Clustering Algorithm.pdf:pdf},
journal = {Informatica},
keywords = {Ant clustering algorithm,data clustering,visual data mining},
pages = {143--154},
title = {{Towards Improving Clustering Ants: An Adaptive Ant Clustering Algorithm}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132216/mod{\_}label/intro/vizine-improveAntCluster-05.pdf},
volume = {29},
year = {2005}
}
@article{Rubenstein,
abstract = {Ants show an incredible ability to collectively transport com-plex irregular-shaped objects with seemingly simple coor-dination. Achieving similarly effective collective transport with robots has potential applications in many settings, from agriculture to construction to disaster relief. In this pa-per we investigate a simple decentralized strategy for collec-tive transport in which each agent acts independently with-out explicit coordination. Using a physics-based model, we prove that this strategy is guaranteed to successfully trans-port a complex object to a target location, even though each agent only knows the target direction and does not know the object shape, weight, its own position, or the position and number of other agents. Using two robot hardware plat-forms, and a wide variety of complex objects, we validate the strategy through extensive experiments. Finally, we present a set of experiments to demonstrate the versatility of the simple strategy, including transport by 100 robots, trans-port of an actively moving object, adaptation to change in goal location, and dealing with partially observable goals.},
author = {Rubenstein, Michael and Cabrera, Adrian and Epfl, Harvard / and Werfel, Justin and Habibi, Golnaz and Mclurkin, James and Nagpal, Radhika},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rubenstein et al. - Unknown - Collective Transport of Complex Objects by Simple Robots Theory and Experiments.pdf:pdf},
keywords = {Collective Intelligence,Multi-Robot Systems,Multiagent systems General Terms Experimentation,Theory Keywords Transport},
title = {{Collective Transport of Complex Objects by Simple Robots: Theory and Experiments}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132253/mod{\_}label/intro/{\%}23 p47-rubenstein.pdf}
}
@article{Couchet2007,
abstract = {This paper proposes a new grammar-guided genetic programming (GGGP) system by introducing two original genetic operators: crossover and mutation, which most influence the evolution process. The first, the so-called grammar-based crossover operator, strikes a good balance between search space exploration and exploitation capabilities and, therefore, enhances GGGP system performance. And the second is a grammar-based mutation operator, based on the crossover, which has been designed to generate individuals that match the syntactical constraints of the context-free grammar that defines the programs to be handled. The use of these operators together in the same GGGP system assures a higher convergence speed and less likelihood of getting trapped in local optima than other related approaches. These features are shown throughout the comparison of the results achieved by the proposed system with other important crossover and mutation methods in two experiments: a laboratory problem and the real-world task of breast cancer prognosis.},
author = {Couchet, Jorge and Manrique, Daniel and R{\'{i}}os, Juan and Rodr{\'{i}}guez-Pat{\'{o}}n, Alfonso},
doi = {10.1007/s00500-006-0144-9},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Couchet et al. - 2007 - Crossover and mutation operators for grammar-guided genetic programming.pdf:pdf},
issn = {1433-7479},
journal = {Soft Computing},
number = {10},
pages = {943--955},
title = {{Crossover and mutation operators for grammar-guided genetic programming}},
url = {https://doi.org/10.1007/s00500-006-0144-9},
volume = {11},
year = {2007}
}
@article{He,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learn-ing residual functions with reference to the layer inputs, in-stead of learning unreferenced functions. We provide com-prehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [41] but still having lower complex-ity. An ensemble of these residual nets achieves 3.57{\%} error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our ex-tremely deep representations, we obtain a 28{\%} relative im-provement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC {\&} COCO 2015 competitions 1 , where we also won the 1st places on the tasks of ImageNet detection, ImageNet local-ization, COCO detection, and COCO segmentation.},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - Unknown - Deep Residual Learning for Image Recognition.pdf:pdf},
title = {{Deep Residual Learning for Image Recognition}},
url = {https://arxiv.org/pdf/1512.03385.pdf}
}
@article{Coradeschi2001,
abstract = {Anchoring is the process of creating and maintaining the correspondence between symbols and percepts that refer to the same physical objects. Although this process must necessarily be present in any symbolic reasoning system embedded in a physical environment (e.g., an autonomous robot), the systematic study of anchoring as a clearly separated problem is just in its initial phase. In this paper we focus on the use of symbols in actions and plans and the consequences this has for anchoring. In particular we introduce action properties and partial matching of objects descriptions. We also consider the use of indefinite references in the context of action. The use of our formalism is exemplified in a mobile robotic domain.},
author = {Coradeschi, Silvia and Saffiotti, Alessandro},
doi = {10.1.1.62.9060},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Coradeschi, Saffiotti - 2001 - Perceptual anchoring of symbols for action.pdf:pdf},
issn = {10450823},
journal = {IJCAI International Joint Conference on Artificial Intelligence},
pages = {407--412},
title = {{Perceptual anchoring of symbols for action}},
year = {2001}
}
@article{Nickel2015,
abstract = {Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be "trained" on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive datasets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Google's Knowledge Vault project as an example of such combination.},
archivePrefix = {arXiv},
arxivId = {1503.00759},
author = {Nickel, Maximilian and Murphy, Kevin and Tresp, Volker and Gabrilovich, Evgeniy},
doi = {10.1109/JPROC.2015.2483592},
eprint = {1503.00759},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nickel et al. - 2015 - A Review of Relational Machine Learning for Knowledge Graphs.pdf:pdf},
month = {mar},
title = {{A Review of Relational Machine Learning for Knowledge Graphs}},
url = {http://arxiv.org/abs/1503.00759 http://dx.doi.org/10.1109/JPROC.2015.2483592},
year = {2015}
}
@inproceedings{DeCampos2009,
address = {New York, New York, USA},
author = {de Campos, Cassio P. and Zeng, Zhi and Ji, Qiang},
booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning - ICML '09},
doi = {10.1145/1553374.1553389},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Campos, Zeng, Ji - 2009 - Structure learning of Bayesian networks using constraints(3).pdf:pdf},
isbn = {9781605585161},
pages = {1--8},
publisher = {ACM Press},
title = {{Structure learning of Bayesian networks using constraints}},
url = {http://portal.acm.org/citation.cfm?doid=1553374.1553389},
year = {2009}
}
@misc{LeonardoAraujoSantos,
abstract = {In depth study in Machine Learning and Artificial Inteligence},
author = {{Leonardo Araujo Santos}},
keywords = {AI,ML},
mendeley-tags = {AI,ML},
title = {{Machine Learning - Artificial Inteligence}},
url = {https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/},
urldate = {2017-06-06}
}
@article{ziminagqa,
author = {Zimina, Elizaveta and Nummenmaa, Jyrki and J{\"{a}}rvelin, Kalervo and Peltonen, Jaakko and Stefanidis, Kostas and Hyyr{\"{o}}, Heikki},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zimina et al. - 2018 - GQA Grammatical Question Answering for RDF Data.pdf:pdf},
title = {{GQA: Grammatical Question Answering for RDF Data}},
year = {2018}
}
@article{Ivakhnenko1971,
author = {Ivakhnenko, A. G.},
doi = {10.1109/TSMC.1971.4308320},
issn = {0018-9472},
journal = {IEEE Transactions on Systems, Man, and Cybernetics},
month = {oct},
number = {4},
pages = {364--378},
title = {{Polynomial Theory of Complex Systems}},
url = {http://ieeexplore.ieee.org/document/4308320/},
volume = {SMC-1},
year = {1971}
}
@article{Groß2010,
abstract = {Robots are said to be capable of self-assembly when they can autonomously form physical connections with each other. By examining different ways in which a system can use self-assembly (i.e., different strategies), we demonstrate and quantify the performance costs and bene-fits of (i) acting as a physically larger self-assembled entity, (ii) letting the system choose when and if to self-assemble, (iii) coordinating the sensing and actuation of the connected robots so that they respond to the environment as a sin-gle collective entity. Our analysis is primarily based on real world experiments in a hill crossing task. The configura-tion of the hill is not known by the robots in advance— the hill can be present or absent, and can vary in steepness and orientation. In some configurations, the robots can over-come the hill more quickly by navigating individually, while other configurations require the robots to self-assemble to overcome the hill. We demonstrate the applicability of our self-assembly strategies to two other tasks—hole crossing and robot rescue—for which we present further proof-of-concept experiments with real robots.},
author = {Gro{\ss}, Roderich and {Lyhne Christensen}, Anders and Dorigo, Marco and Dorigo, M and {Gro{\ss} ACSE}, R and Christensen, Al},
doi = {10.1007/s10514-010-9177-0},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gro{\ss} et al. - 2010 - Self-assembly strategies in a group of autonomous mobile robots.pdf:pdf},
journal = {Auton Robot},
keywords = {All-terrain navigation {\textperiodcentered},Autonomous robots {\textperiodcentered},Cooperation {\textperiodcentered},Modular robots {\textperiodcentered},Self-assembly {\textperiodcentered},Swarm robotics},
pages = {439--455},
title = {{Self-assembly strategies in a group of autonomous mobile robots}},
url = {http://dx.doi.org/10.1007/s10514-010-9177-0},
volume = {28},
year = {2010}
}
@article{Barsalou2003,
abstract = {After reviewing six senses of abstraction, this article focuses on abstractions that take the form of summary representations. Three central properties of these abstractions are established: ( i ) type-token interpretation; (ii) structured representation; and (iii) dynamic realization. Traditional theories of representation handle interpretation and structure well but are not sufficiently dynamical. Conversely, connectionist theories are exquisitely dynamic but have problems with structure. Perceptual symbol systems offer an approach that implements all three properties naturally. Within this framework, a loose collection of property and relation simulators develops to represent abstractions. Type-token interpretation results from binding a property simulator to a region of a perceived or simulated category member. Structured representation results from binding a configuration of property and relation simulators to multiple regions in an integrated manner. Dynamic realization results from applying different subsets of property and relation simulators to category members on different occasions. From this standpoint, there are no permanent or complete abstractions of a category in memory. Instead, abstraction is the skill to construct temporary online interpretations of a category's members. Although an infinite number of abstractions are possible, attractors develop for habitual approaches to interpretation. This approach provides new ways of thinking about abstraction phenomena in categorization, inference, background knowledge and learning.},
author = {Barsalou, LW},
doi = {10.1098/rstb.2003.1319},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barsalou - 2003 - Abstraction in perceptual symbol systems.pdf:pdf},
isbn = {0962-8436},
issn = {0962-8436},
journal = {{\ldots} Transactions of the Royal Society of {\ldots}},
keywords = {Animals,Cognition,Concept Formation,Humans,Learning,Models,Perception,Psychological,Symbolism},
number = {1435},
pages = {1177--1187},
pmid = {12903648},
title = {{Abstraction in perceptual symbol systems}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=1693222{\&}tool=pmcentrez{\&}rendertype=abstract{\%}5Cnhttp://rstb.royalsocietypublishing.org/content/358/1435/1177.short},
volume = {358},
year = {2003}
}
@article{Meyer,
abstract = {Quadrotor UAVs have successfully been used both in re-search and for commercial applications in recent years and there has been significant progress in the design of robust control software and hardware. Nevertheless, testing of prototype UAV systems still means risk of dam-age due to failures. Motivated by this, a system for the comprehensive simulation of quadrotor UAVs is presented in this paper. Unlike existing solutions, the presented system is integrated with ROS and the Gazebo simulator. This comprehensive approach allows simultaneous simulation of diverse aspects such as flight dynamics, onboard sensors like IMUs, ex-ternal imaging sensors and complex environments. The dynamics model of the quadrotor has been parameterized using wind tunnel tests and validated by a comparison of simulated and real flight data. The appli-cability for simulation of complex UAV systems is demonstrated using LIDAR-based and visual SLAM approaches available as open source soft-ware.},
author = {Meyer, Johannes and Sendobry, Alexander and Kohlbrecher, Stefan and Klingauf, Uwe and {Von Stryk}, Oskar},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meyer et al. - Unknown - Comprehensive Simulation of Quadrotor UAVs using ROS and Gazebo.pdf:pdf},
title = {{Comprehensive Simulation of Quadrotor UAVs using ROS and Gazebo}},
url = {https://pdfs.semanticscholar.org/3ed3/948827e0949770e8583b51bd0fedf4fd73fe.pdf}
}
@article{Yang2018a,
abstract = {This paper describes NCRF++, a toolkit for neural sequence labeling. NCRF++ is designed for quick implementation of different neural sequence labeling models with a CRF inference layer. It provides users with an inference for building the custom model structure through configuration file with flexible neural feature design and utilization. Built on PyTorch, the core operations are calculated in batch, making the toolkit efficient with the acceleration of GPU. It also includes the implementations of most state-of-the-art neural sequence labeling models such as LSTM-CRF, facilitating reproducing and refinement on those methods.},
archivePrefix = {arXiv},
arxivId = {1806.05626},
author = {Yang, Jie and Zhang, Yue},
eprint = {1806.05626},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Zhang - 2018 - NCRF An Open-source Neural Sequence Labeling Toolkit.pdf:pdf},
month = {jun},
title = {{NCRF++: An Open-source Neural Sequence Labeling Toolkit}},
url = {http://arxiv.org/abs/1806.05626},
year = {2018}
}
@incollection{LeCun1998,
author = {LeCun, Yann and Bottou, Leon and Orr, Genevieve B. and M?ller, Klaus -Robert},
doi = {10.1007/3-540-49430-8_2},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/LeCun et al. - 1998 - Efficient BackProp.pdf:pdf},
pages = {9--50},
publisher = {Springer Berlin Heidelberg},
title = {{Efficient BackProp}},
url = {http://link.springer.com/10.1007/3-540-49430-8{\_}2},
year = {1998}
}
@article{ScanagattaIdsia,
abstract = {We present a method for learning Bayesian networks from data sets containing thousands of variables without the need for structure constraints. Our approach is made of two parts. The first is a novel algorithm that effectively explores the space of possible parent sets of a node. It guides the exploration towards the most promising parent sets on the basis of an approximated score function that is computed in constant time. The second part is an improvement of an existing ordering-based algorithm for structure optimization. The new algorithm provably achieves a higher score compared to its original formulation. Our novel approach consistently outperforms the state of the art on very large data sets.},
author = {{Scanagatta Idsia}, Mauro and Supsi, Usi and Lugano, Switzerland and {De Campos}, Cassio P and Corani, Giorgio and {Zaffalon Idsia}, Marco},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scanagatta Idsia et al. - Unknown - Learning Bayesian Networks with Thousands of Variables.pdf:pdf},
title = {{Learning Bayesian Networks with Thousands of Variables}},
url = {http://papers.nips.cc/paper/5803-learning-bayesian-networks-with-thousands-of-variables.pdf},
year = {2015}
}
@article{Weinberg2017,
author = {Weinberg, Benjamin H and Pham, N T Hang and Caraballo, Leidy D and Lozanoski, Thomas and Engel, Adrien and Bhatia, Swapnil and Wong, Wilson W},
doi = {10.1038/nbt.3805},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weinberg et al. - 2017 - Large-scale design of robust genetic circuits with multiple inputs and outputs for mammalian cells.pdf:pdf},
issn = {1087-0156},
journal = {Nature Biotechnology},
month = {mar},
number = {5},
pages = {453--462},
title = {{Large-scale design of robust genetic circuits with multiple inputs and outputs for mammalian cells}},
url = {http://www.nature.com/doifinder/10.1038/nbt.3805},
volume = {35},
year = {2017}
}
@article{Lison2010,
abstract = {To interact naturally with humans, robots need to be aware of their own surroundings. This awareness is usually encoded in some implicit or explicit representation of the situated context. In this paper, we present a new framework for constructing rich belief models of the robot's environment. Key to our approach is the use of Markov Logic as a unified framework for inference over these beliefs. Markov Logic is a combination of first-order logic and probabilistic graphical models. Its expressive power allows us to capture both the rich relational structure of the environment and the uncertainty arising from the noise and incompleteness of low-level sensory data. The constructed belief models evolve dynamically over time and incorporate various contextual information such as spatio-temporal framing, multi-agent epistemic status, and saliency measures. Beliefs can also be referenced and extended {\&}{\#}x201C;top-down{\&}{\#}x201D; via linguistic communication. The approach is being integrated into a cognitive architecture for mobile robots interacting with humans using spoken dialogue.},
author = {Lison, Pierre and Ehrler, Carsten and Kruijff, Geert Jan M.},
doi = {10.1109/ROMAN.2010.5598723},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lison, Ehrler, Kruijff - 2010 - Belief modelling for situation awareness in human-robot interaction.pdf:pdf},
isbn = {9781424479917},
issn = {1944-9445},
journal = {Proceedings - IEEE International Workshop on Robot and Human Interactive Communication},
pages = {138--143},
title = {{Belief modelling for situation awareness in human-robot interaction}},
year = {2010}
}
@inproceedings{Haus2016,
author = {Haus, Tomislav and Prkut, Nikola and Borovina, Katarina and Maric, Bruno and Orsag, Matko and Bogdan, Stjepan},
booktitle = {2016 24th Mediterranean Conference on Control and Automation (MED)},
doi = {10.1109/MED.2016.7536068},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haus et al. - 2016 - A novel concept of attitude control for large multirotor-UAVs based on moving mass control.pdf:pdf},
isbn = {978-1-4673-8345-5},
month = {jun},
pages = {832--839},
publisher = {IEEE},
title = {{A novel concept of attitude control for large multirotor-UAVs based on moving mass control}},
url = {http://ieeexplore.ieee.org/document/7536068/},
year = {2016}
}
@article{Chen2018,
abstract = {Inferring missing links in knowledge graphs (KG) has attracted a lot of attention from the research community. In this paper, we tackle a practical query answering task involving predicting the relation of a given entity pair. We frame this prediction problem as an inference problem in a probabilistic graphical model and aim at resolving it from a variational inference perspective. In order to model the relation between the query entity pair, we assume that there exists an underlying latent variable (paths connecting two nodes) in the KG, which carries the equivalent semantics of their relations. However, due to the intractability of connections in large KGs, we propose to use variation inference to maximize the evidence lower bound. More specifically, our framework ($\backslash$textsc{\{}Diva{\}}) is composed of three modules, i.e. a posterior approximator, a prior (path finder), and a likelihood (path reasoner). By using variational inference, we are able to incorporate them closely into a unified architecture and jointly optimize them to perform KG reasoning. With active interactions among these sub-modules, $\backslash$textsc{\{}Diva{\}} is better at handling noise and coping with more complex reasoning scenarios. In order to evaluate our method, we conduct the experiment of the link prediction task on multiple datasets and achieve state-of-the-art performances on both datasets.},
archivePrefix = {arXiv},
arxivId = {1803.06581},
author = {Chen, Wenhu and Xiong, Wenhan and Yan, Xifeng and Wang, William},
eprint = {1803.06581},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2018 - Variational Knowledge Graph Reasoning.pdf:pdf},
month = {mar},
title = {{Variational Knowledge Graph Reasoning}},
url = {http://arxiv.org/abs/1803.06581},
year = {2018}
}
@article{Zhou,
abstract = {Fractals are common in nature, and can be used as well for both art and engineering. We classify those fractals that can be rep-resented by line segments into several types: tree-based fractals, curve-based fractals, and space filling fractals. We develop a set of methods to generate fractals with a swarm of robots by using robots as vertices, and line segments between selected robots as edges. We then generalize our algorithms so that new fractals can be built with only a few parameters, and we expand our methods to generate some shape-based fractals.},
author = {Zhou, Yu and Goldman, Ron},
doi = {10.1007/978-3-319-61833-3},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou, Goldman - Unknown - Building Fractals with a Robot Swarm.pdf:pdf},
keywords = {Distributed algorithm {\textperiodcentered},Fractal formation {\textperiodcentered},Multi-agent path planning {\textperiodcentered},Swarm intelligence},
title = {{Building Fractals with a Robot Swarm}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1392651/mod{\_}label/intro/978-3-319-61833-3{\_}20.pdf}
}
@misc{Gerber2011,
author = {Gerber, Daniel and Ngomo, Axel-Cyrille Ngonga},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gerber, Ngomo - 2011 - Bootstrapping the Linked Data Web.pdf:pdf},
title = {{Bootstrapping the Linked Data Web}},
url = {https://www.semanticscholar.org/paper/Bootstrapping-the-Linked-Data-Web-Gerber-Ngomo/914cfd6fb61d75608592164193f90776bef58a7e},
year = {2011}
}
@article{Trischler2016,
abstract = {We present NewsQA, a challenging machine comprehension dataset of over 100,000 human-generated question-answer pairs. Crowdworkers supply questions and answers based on a set of over 10,000 news articles from CNN, with answers consisting of spans of text from the corresponding articles. We collect this dataset through a four-stage process designed to solicit exploratory questions that require reasoning. A thorough analysis confirms that NewsQA demands abilities beyond simple word matching and recognizing textual entailment. We measure human performance on the dataset and compare it to several strong neural models. The performance gap between humans and machines (0.198 in F1) indicates that significant progress can be made on NewsQA through future research. The dataset is freely available at https://datasets.maluuba.com/NewsQA.},
archivePrefix = {arXiv},
arxivId = {1611.09830},
author = {Trischler, Adam and Wang, Tong and Yuan, Xingdi and Harris, Justin and Sordoni, Alessandro and Bachman, Philip and Suleman, Kaheer},
eprint = {1611.09830},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Trischler et al. - 2016 - NewsQA A Machine Comprehension Dataset.pdf:pdf},
month = {nov},
title = {{NewsQA: A Machine Comprehension Dataset}},
url = {http://arxiv.org/abs/1611.09830},
year = {2016}
}
@inproceedings{kartsaklis-pilehvar-collier:2018:EMNLP,
address = {Brussels, Belgium},
author = {Kartsaklis, Dimitri and Pilehvar, Mohammad Taher and Collier, Nigel},
booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kartsaklis, Pilehvar, Collier - 2018 - Mapping Text to Knowledge Graph Entities using Multi-Sense LSTMs.pdf:pdf},
pages = {1959--1970},
publisher = {Association for Computational Linguistics},
title = {{Mapping Text to Knowledge Graph Entities using Multi-Sense LSTMs}},
url = {http://www.aclweb.org/anthology/D18-1221},
year = {2018}
}
@inproceedings{Jaroszewicz2004,
address = {New York, New York, USA},
author = {Jaroszewicz, Szymon and Simovici, Dan A.},
booktitle = {Proceedings of the 2004 ACM SIGKDD international conference on Knowledge discovery and data mining  - KDD '04},
doi = {10.1145/1014052.1014074},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaroszewicz, Simovici - 2004 - Interestingness of frequent itemsets using Bayesian networks as background knowledge.pdf:pdf},
isbn = {1581138889},
keywords = {Bayesian network,association rule,background,frequent itemset,interestingness,knowledge},
pages = {178},
publisher = {ACM Press},
title = {{Interestingness of frequent itemsets using Bayesian networks as background knowledge}},
url = {http://portal.acm.org/citation.cfm?doid=1014052.1014074},
year = {2004}
}
@article{Panchal2013a,
abstract = {This paper summarizes the three robust feature detection methods: Scale Invariant Feature Transform (SIFT), Principal Component Analysis (PCA)SIFT and Speeded Up Robust Features (SURF). This paper uses KNN (K-Nearest Neighbor) and Random Sample Consensus (RANSAC) to the three methods in order to analyze the results of the methods application in recognition. KNN is used to find the matches, and RANSAC to reject inconsistent matches from which the inliers can take as correct matches. The performance of the robust feature detection methods are compared for scale changes, rotation, blur, illumination changes and affine transformations. All the experiments use repeatability measurement and the number of correct matches for the evaluation measurements. SIFT presents its stability in most situations although its slow. SURF is the fastest one with good performance as the same as SIFT. PCA-SIFT show its advantages in rotation and illumination changes.},
author = {Panchal, P.M. and Panchal, S.R. and Shah, S.K.},
doi = {10.1007/s11270-006-2859-8},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Panchal, Panchal, Shah - 2013 - A comparison of SIFT and SURF.pdf:pdf},
isbn = {1985-2304},
issn = {00496979},
journal = {International Journal of Innovative Research in Computer and Communication Engineering},
keywords = {knn,pca sift,ransac,robust detectors,sift,surf},
title = {{A comparison of SIFT and SURF}},
year = {2013}
}
@book{minsky1972perceptrons,
author = {Minsky, M L and Papert, S},
isbn = {9780262130431},
publisher = {Mit Press},
title = {{Perceptrons: An Introduction to Computational Geometry}},
url = {https://books.google.es/books?id=Ow1OAQAAIAAJ},
year = {1972}
}
@book{ivakhnenko1973cybernetic,
author = {Ivakhnenko, A G and Lapa, V G},
publisher = {CCM Information Corporation},
series = {Jprs report},
title = {{Cybernetic Predicting Devices}},
url = {https://books.google.es/books?id=FhwVNQAACAAJ},
year = {1973}
}
@article{Chapelle1999,
author = {Chapelle, O. and Haffner, P. and Vapnik, V.N.},
doi = {10.1109/72.788646},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
number = {5},
pages = {1055--1064},
title = {{Support vector machines for histogram-based image classification}},
url = {http://ieeexplore.ieee.org/document/788646/},
volume = {10},
year = {1999}
}
@article{GarciaHuertas2016,
abstract = {There is a wide variety of approaches to solve the issue of localization and orientation in an environment. Many of these approaches depend to a greater or lesser degree in information that is external to the user. In this work a localization system based only in imagenes from the environmente will be developed. To that end we have used a image classification algoritm implemented on a topological map. The classification algorithm used is a k-nearest neighbour, using the normalized histogram from the images as the characteristic to identify. The topological map has been built from the testing grounds, which is in this case the Departament of Artificial Intelligence of the Escuela Técnica Superior de Ingenieros Informáticos from the Universidad Politécnica de Madrid. It can be seen that the results shown when performing dynamic testing are promising.},
author = {{Garcia Huertas}, Carlos and Maravall, Dario and de Lope, Javier},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garcia Huertas, Maravall, de Lope - 2016 - Tesis de master master en inteligencia artificial.pdf:pdf},
pages = {52},
title = {{Tesis de master master en inteligencia artificial}},
year = {2016}
}
@inproceedings{7502591,
author = {Sanchez-Lopez, J L and Fern{\'{a}}ndez, R A S and Bavle, H and Sampedro, C and Molina, M and Pestana, J and Campoy, P},
booktitle = {2016 International Conference on Unmanned Aircraft Systems (ICUAS)},
doi = {10.1109/ICUAS.2016.7502591},
keywords = {aerospace computing;autonomous aerial vehicles;con},
pages = {332--341},
title = {{AEROSTACK: An architecture and open-source software framework for aerial robotics}},
year = {2016}
}
@article{diefenbachscalability,
author = {Diefenbach, Dennis and Singh, Kamal and Maret, Pierre},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Diefenbach, Singh, Maret - 2018 - On the scalability of the QA system WDAqua-core1.pdf:pdf},
title = {{On the scalability of the QA system WDAqua-core1}},
year = {2018}
}
@article{breiman2001a,
abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the corre-lation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund {\&} R. Schapire, Machine Learning: Proceedings of the Thirteenth Interna-tional conference, * * * , 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
author = {Breiman, Leo},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Breiman - 2001 - Random Forests.pdf:pdf},
journal = {Machine Learning},
keywords = {classification,ensemble,regression},
pages = {5--32},
title = {{Random Forests}},
url = {https://link.springer.com/content/pdf/10.1023{\%}2FA{\%}3A1010933404324.pdf},
volume = {45},
year = {2001}
}
@article{Cover1967,
abstract = {The nearest neighbor decision rule assigns to an unclassified sample point the classification of the nearest of a set of previously classified points. This rule is independent of the underlying joint distribution on the sample points and their classifications, and hence the probability of error of such a rule must be at least as great as the Bayes probability of error--the minimum probability of error over all decision rules taking underlying probability structure into account. However, in a large sample analysis, we will show in the category case that, where these bounds are the tightest possible, for all suitably smooth underlying distributions. Thus for any number of categories, the probability of error of the nearest neighbor rule is bounded above by twice the Bayes probability of error. In this sense, it may be said that half the classification information in an infinite sample set is contained in the nearest neighbor.},
author = {Cover, T. and Hart, P.},
doi = {10.1109/TIT.1967.1053964},
isbn = {0018-9448},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
number = {1},
pages = {21--27},
pmid = {21919855},
title = {{Nearest neighbor pattern classification}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1053964},
volume = {13},
year = {1967}
}
@article{DeCampos2002,
abstract = {One important approach to learning Bayesian networks (BNs) from data uses a scoring metric to evaluate the fitness of any given candidate network for the data base, and applies a search procedure to explore the set of candidate networks. The most usual search methods are greedy hill climbing, either deterministic or stochastic, although other techniques have also been used. In this paper we propose a new algorithm for learning BNs based on a recently introduced metaheuristic, which has been successfully applied to solve a variety of combinatorial optimization problems: ant colony optimization (ACO). We describe all the elements necessary to tackle our learning problem using this metaheuristic, and experimentally compare the performance of our ACO-based algorithm with other algorithms used in the literature. The experimental work is carried out using three different domains: ALARM, INSURANCE and BOBLO.},
author = {de Campos, Luis M. and Fern{\'{a}}ndez-Luna, Juan M. and G{\'{a}}mez, Jos{\'{e}} A. and Puerta, Jos{\'{e}} M.},
doi = {10.1016/S0888-613X(02)00091-9},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/de Campos et al. - 2002 - Ant colony optimization for learning Bayesian networks.pdf:pdf},
issn = {0888-613X},
journal = {International Journal of Approximate Reasoning},
month = {nov},
number = {3},
pages = {291--311},
publisher = {Elsevier},
title = {{Ant colony optimization for learning Bayesian networks}},
url = {http://www.sciencedirect.com/science/article/pii/S0888613X02000919},
volume = {31},
year = {2002}
}
@article{Friedman2003a,
author = {Friedman, Nir and Koller, Daphne},
doi = {10.1023/A:1020249912095},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Friedman, Koller - 2003 - Being Bayesian About Network Structure. A Bayesian Approach to Structure Discovery in Bayesian Networks.pdf:pdf},
issn = {08856125},
journal = {Machine Learning},
number = {1/2},
pages = {95--125},
publisher = {Kluwer Academic Publishers},
title = {{Being Bayesian About Network Structure. A Bayesian Approach to Structure Discovery in Bayesian Networks}},
url = {http://link.springer.com/10.1023/A:1020249912095},
volume = {50},
year = {2003}
}
@article{lindner2015,
author = {Lindner, Claudia and Bromiley, Paul A. and Ionita, Mircea C. and Cootes, Tim F.},
doi = {10.1109/TPAMI.2014.2382106},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lindner et al. - 2015 - Robust and Accurate Shape Model Matching Using Random Forest Regression-Voting.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
month = {sep},
number = {9},
pages = {1862--1874},
title = {{Robust and Accurate Shape Model Matching Using Random Forest Regression-Voting}},
url = {http://ieeexplore.ieee.org/document/6987312/},
volume = {37},
year = {2015}
}
@article{Weinberger,
abstract = {We show how to learn a Mahanalobis distance metric for k-nearest neigh-bor (kNN) classification by semidefinite programming. The metric is trained with the goal that the k-nearest neighbors always belong to the same class while examples from different classes are separated by a large margin. On seven data sets of varying size and difficulty, we find that metrics trained in this way lead to significant improvements in kNN classification—for example, achieving a test error rate of 1.3{\%} on the MNIST handwritten digits. As in support vector machines (SVMs), the learning problem reduces to a convex optimization based on the hinge loss. Unlike learning in SVMs, however, our framework requires no modification or extension for problems in multiway (as opposed to bi-nary) classification.},
author = {Weinberger, Kilian Q and Blitzer, John and Saul, Lawrence K},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weinberger, Blitzer, Saul - 2005 - Distance Metric Learning for Large Margin Nearest Neighbor Classification.pdf:pdf},
title = {{Distance Metric Learning for Large Margin Nearest Neighbor Classification}},
url = {http://papers.nips.cc/paper/2795-distance-metric-learning-for-large-margin-nearest-neighbor-classification.pdf},
year = {2005}
}
@article{nitze,
abstract = {See, stats, and : https : / / www . researchgate . net / publication / 275641579 COMPARISON ALGORITHMS , ARTIFICIAL NEURAL . . . Conference CITATIONS 20 READS 806 3 , including : Some : GlobPermafrost Cereal (CSISA) View Ingmar Alfred 15 SEE Urs Consultative 28 SEE All . The . ABSTRACT : The classification and recognition of agricultural crop types is an important application of remote sensing . New machine learning algorithms have emerged in the last years , but so far , few studies only have compared their performance and usability . Therefore , we compared three different state - of - the - art machine learning classifiers , namely Support Vector Machine (SVM) , Artificial Neural Network (ANN) and Random Forest (RF) as well as the traditional classification method Maximum Likelihood (ML) among each other . For this purpose we classified a dataset of more than 500 crop fields located in the Canadian Prairies with a stratified randomized sampling approach . Up to four multi - spectral RapidEye images from the 2009 growing season were used . We compared the mean overall classification accuracies as well as standard deviations . Furthermore , the classification accuracy of single crops was analysed . Support Vector Machine classifiers using radial basis function or polynomial kernels exhibited superior results to ANN and RF in terms of overall accuracy and robustness , while ML exhibited inferior accuracies and higher variability . Grassland exhibited the best results for early - season mono - temporal analysis . With a multi - temporal approach , the highest accuracies were achieved for Rapeseed and Field Peas . Other crops , such as Wheat , Flax and Lentils were also successfully classified . The user ' s and producer ' s accuracies were higher than 85 {\%} .},
author = {Nitze, I and Schulthess, U and Asche, H},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Nitze, Schulthess, Asche - Unknown - COMPARISON OF MACHINE LEARNING ALGORITHMS RANDOM FOREST , ARTIFICIAL NEURAL NETWORK AND SUPPORT VEC.pdf:pdf},
journal = {Proceedings of the 4th GEOBIA},
keywords = {Crop Classification,Machine Learning Algorithms,RapidEye,Support Vector Machine},
title = {{COMPARISON OF MACHINE LEARNING ALGORITHMS RANDOM FOREST , ARTIFICIAL NEURAL NETWORK AND SUPPORT VECTOR MACHINE TO MAXIMUM LIKELIHOOD FOR SUPERVISED CROP TYPE CLASSIFICATION}},
url = {https://www.researchgate.net/profile/Ingmar{\_}Nitze/publication/275641579{\_}COMPARISON{\_}OF{\_}MACHINE{\_}LEARNING{\_}ALGORITHMS{\_}RANDOM{\_}FOREST{\_}ARTIFICIAL{\_}NEURAL{\_}NETWORK{\_}AND{\_}SUPPORT{\_}VECTOR{\_}MACHINE{\_}TO{\_}MAXIMUM{\_}LIKELIHOOD{\_}FOR{\_}SUPERVISED{\_}CROP{\_}TYPE{\_}CLASSIFICATION/links/554123},
year = {2012}
}
@article{Camp2018,
abstract = {Learning a set of tasks over time, also known as continual learning (CL), is one of the most challenging problems in artificial intelligence. While recent approaches achieve some degree of CL in deep neural networks, they either (1) grow the network parameters linearly with the number of tasks, (2) require storing training data from previous tasks, or (3) restrict the network's ability to learn new tasks. To address these issues, we propose a novel framework, Self-Net, that uses an autoencoder to learn a set of low-dimensional representations of the weights learned for different tasks. We demonstrate that these low-dimensional vectors can then be used to generate high-fidelity recollections of the original weights. Self-Net can incorporate new tasks over time with little retraining and with minimal loss in performance for older tasks. Our system does not require storing prior training data and its parameters grow only logarithmically with the number of tasks. We show that our technique outperforms current state-of-the-art approaches on numerous datasets---including continual versions of MNIST, CIFAR10, CIFAR100, and Atari---and we demonstrate that our method can achieve over 10X storage compression in a continual fashion. To the best of our knowledge, we are the first to use autoencoders to sequentially encode sets of network weights to enable continual learning.},
archivePrefix = {arXiv},
arxivId = {1805.10354},
author = {Camp, Blake and Mandivarapu, Jaya Krishna and Estrada, Rolando},
eprint = {1805.10354},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Camp, Mandivarapu, Estrada - 2018 - Self-Net Lifelong Learning via Continual Self-Modeling.pdf:pdf},
keywords = {To-Read},
mendeley-tags = {To-Read},
month = {may},
title = {{Self-Net: Lifelong Learning via Continual Self-Modeling}},
url = {http://arxiv.org/abs/1805.10354},
year = {2018}
}
@article{Unger2014,
abstract = {With the increasing amount of semantic data available on the web there is a strong need for systems that allow common web users to access this body of knowledge. Especially question answering systems have received wide attention, as they allow users to express arbitrarily complex information needs in an easy and intuitive fashion (for an overview see [4]). The key challenge lies in translating the users' information needs into a form such that they can be evaluated using standard Semantic Web query processing and inferencing techniques. Over the past years, a range of approaches have been developed to address this challenge, showing signicant advances towards answering natural language questions with respect to large, heterogeneous sets of structured data. However, only few systems yet address the fact that the structured data available nowadays is distributed among a large collection of interconnected datasets, and that answers to questions can often only be provided if information from several sources are combined. In addition, a lot of information is still available only in textual form, both on the web and in the form of labels and abstracts in linked data sources. Therefore approaches are needed that can not only deal with the specific character of structured data but also with finding information in several sources, processing both structured and unstructured information, and combining such gathered information into one answer. The main objective of the open challenge on question answering over linked data (QALD) is to provide up-to-date, demanding benchmarks that establish a standard against which question answering systems over structured data can be evaluated and compared. QALD-4 is the fourth instalment of the QALD open challenge, comprising three tasks: multilingual question answering, biomedical question answering over interlinked data, and hybrid question answering.},
author = {Unger, Christina and Forascu, Corina and Lopez, Vanessa and Ngomo, Axel-Cyrille Ngonga and Cabrio, Elena and Cimiano, Philipp and Walter, Sebastian},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unger et al. - 2014 - Question Answering over Linked Data (QALD-4).pdf:pdf},
keywords = {DBpedia,Linked Data,Question Answering},
month = {sep},
title = {{Question Answering over Linked Data (QALD-4)}},
url = {https://hal.inria.fr/hal-01086472/},
year = {2014}
}
@article{Cirean,
abstract = {Processing Unit), training set deformations, MNIST 1 , BP (back-propagation). Abstract Good old on-line back-propagation for plain multi-layer perceptrons yields a very low 0.35{\%} error rate on the famous MNIST handwritten digits benchmark. All we need to achieve this best result so far are many hidden layers, many neurons per layer, numerous deformed training images, and graphics cards to greatly speed up learning.},
author = {Cirean, Dan Claudiu and Meier, Ueli and Gambardella, Luca Maria and Schmidhuber, Urgen},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cirean et al. - 2010 - Deep Big Simple Neural Nets Excel on Hand- written Digit Recognition.pdf:pdf},
keywords = {GPU (Graphics,MLP (Multilayer Perceptron),NN (Neural Network)},
title = {{Deep Big Simple Neural Nets Excel on Hand- written Digit Recognition}},
url = {https://arxiv.org/pdf/1003.0358.pdf},
year = {2010}
}
@inproceedings{hector_slam,
author = {Kohlbrecher, S and Meyer, J and von Stryk, O and Klingauf, U},
booktitle = {Proc. IEEE International Symposium on Safety, Security and Rescue Robotics (SSRR)},
month = {nov},
organization = {IEEE},
title = {{A Flexible and Scalable SLAM System with Full 3D Motion Estimation}},
year = {2011}
}
@article{Tufillaro1994,
abstract = {Template and prunning front are calculated for an experimental chaotic time series from a mechanical string experiment. An empirical synchronized model is also created for the data set. To appear in Physical Review E.},
archivePrefix = {arXiv},
arxivId = {chao-dyn/9411012},
author = {Tufillaro, Nicholas B.},
doi = {10.1103/PhysRevE.51.164},
eprint = {9411012},
isbn = {978-1-4799-5118-5},
issn = {10459227},
journal = {L},
keywords = {corel,histogram,image,image classification,radial basis functions,support vector machines},
month = {nov},
number = {3},
pages = {1--11},
pmid = {7491034},
primaryClass = {chao-dyn},
title = {{Topological time series analysis of a string experiment and its synchronized model}},
url = {http://arxiv.org/abs/chao-dyn/9411012 http://dx.doi.org/10.1103/PhysRevE.51.164},
year = {1994}
}
@article{Szegedy2015,
abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2{\%} top-1 and 5.6{\%} top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5{\%} top-5 error on the validation set (3.6{\%} error on the test set) and 17.3{\%} top-1 error on the validation set.},
archivePrefix = {arXiv},
arxivId = {1512.00567},
author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
eprint = {1512.00567},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Szegedy et al. - 2015 - Rethinking the Inception Architecture for Computer Vision.pdf:pdf},
month = {dec},
title = {{Rethinking the Inception Architecture for Computer Vision}},
url = {http://arxiv.org/abs/1512.00567},
year = {2015}
}
@article{Schoonderwoerd,
abstract = {This paper describes a novel method of achieving load bal-ancing in telecommunications networks. A simulated net-work models a typical distribution of calls between arbitrary nodes; nodes carrying an excess of traffic can become con-gested, causing calls to fail. In addition to calls, the network also supports a population of simple mobile agents with behaviours modelled on the trail laying abilities of ants. The agents move across the network between arbitrary pairs of nodes, selecting their path at each intermediate node accord-ing to the distribution of simulated pheromones at each node. As they move they deposit simulated pheromones as a func-tion of their distance from their source node, and the conges-tion encountered on their journey. Calls between nodes are routed as a function of the pheromone distributions at each intermediate node. The performance of the network is meas-ured by the proportion of calls which fail. The results are compared with those achieved by using fixed shortest-path routes, and also by using an alternative algorithmically-based type of mobile agent. The ant-based system is shown to drop fewer calls than the other methods, while exhibiting many attractive features of distributed control.},
author = {Schoonderwoerd, Ruud and Holland, Owen and Bruten, Janet},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - full-text.pdf:pdf},
title = {{Ant-like agents for load balancing in telecommunications networks}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132239/mod{\_}label/intro/Ant-like agents for load balancing in telecommunications {\%}28Schoonderwoerd et al{\%}2C 97{\%}29.pdf}
}
@article{Lowe2004,
abstract = {With the increasing technical sophistication of both information consumers and providers, there is increasing demand for more meaningful experiences of digital information. We present a framework that separates digital object experience, or rendering, from digital object storage and manipulation, so the rendering can be tailored to particular communities of users. Our framework also accommodates extensible digital object behaviors and interoperability. The two key components of our approach are 1) exposing structural metadata associated with digital objects -- metadata about the labeled access points within a digital object and 2) information intermediaries called context brokers that match structural characteristics of digital objects with mechanisms that produce behaviors. These context brokers allow for localized rendering of digital information stored externally.},
archivePrefix = {arXiv},
arxivId = {cs/0112017},
author = {Dushay, Naomi},
doi = {10.1023/B:VISI.0000029664.99615.94},
eprint = {0112017},
isbn = {1568811012},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {Image matching,Invariant features,Object recognition,Scale invariance},
month = {dec},
number = {2},
pages = {91--110},
pmid = {20064111},
primaryClass = {cs},
title = {{Using Structural Metadata to Localize Experience of Digital Content}},
url = {http://arxiv.org/abs/cs/0112017},
volume = {60},
year = {2001}
}
@article{Harnard1990,
abstract = {There has been much discussion recently about the scope and limits of purely symbolic models of the mind and about the proper role of connectionism in cognitive modeling. This paper describes the "symbol grounding problem": How can the semantic interpretation of a formal symbol system be made intrinsic to the system, rather than just parasitic on the meanings in our heads? How can the meanings of the meaningless symbol tokens, manipulated solely on the basis of their (arbitrary) shapes, be grounded in anything but other meaningless symbols? The problem is analogous to trying to learn Chinese from a Chinese/Chinese dictionary alone. A candidate solution is sketched: Symbolic representations must be grounded bottom-up in nonsymbolic representations of two kinds: (1) "iconic representations" , which are analogs of the proximal sensory projections of distal objects and events, and (2) "categorical representations" , which are learned and innate feature-detectors that pick out the invariant features of object and event categories from their sensory projections. Elementary symbols are the names of these object and event categories, assigned on the basis of their (nonsymbolic) categorical representations. Higher-order (3) "symbolic representations" , grounded in these elementary symbols, consist of symbol strings describing category membership relations (e.g., "An X is a Y that is Z"). Connectionism is one natural candidate for the mechanism that learns the invariant features underlying categorical representations, thereby connecting names to the proximal projections of the distal objects they stand for. In this way connectionism can be seen as a complementary component in a hybrid nonsymbolic/symbolic model of the mind, rather than a rival to purely symbolic modeling. Such a hybrid model would not have an autonomous symbolic "module," however; the symbolic functions would emerge as an intrinsically "dedicated" symbol system as a consequence of the bottom-up grounding of categories' names in their sensory representations. Symbol manipulation would be governed not just by the arbitrary shapes of the symbol tokens, but by the nonarbitrary shapes of the icons and category invariants in which they are grounded.},
archivePrefix = {arXiv},
arxivId = {cs/9906002},
author = {Harnard, Stevan and Harnad, Stevan},
doi = {10.1016/0167-2789(90)90087-6},
eprint = {9906002},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Harnard, Harnad - 1990 - The Symbol Grounding Problem.pdf:pdf},
isbn = {0167-2789},
issn = {01672789},
journal = {Physica D},
keywords = {a word refers to,categorization,computation,consciousness,illustrated using the proper,is not,its referent,language,meaning,names of concrete,perceptio,reference,robotics,sensorimotor function,that the thing that,the same as its,this is most clearly,turing test,we know since frege,words and meanings},
pages = {335--346},
primaryClass = {cs},
title = {{The Symbol Grounding Problem}},
url = {http://eprints.soton.ac.uk/258175/1/sgproblem1.html},
volume = {42},
year = {1990}
}
@article{Goel2017,
abstract = {— Ensemble is a data mining technique composed of number of individual classifiers to classify the data to generate new instances of data. Random Forest is the most popular ensemble technique of classification because of the presence of excellent features such as Variable importance measure, Out-of-bag error, Proximities etc. In this paper, the developments and improvements of Random Forest in the last 15 years are presented. This paper deals with the approach proposed by Brieman since 2001. This paper also presents the description of usage of Random Forest in various fields like Medicine, Agriculture, Astronomy, etc. Keywords— Meta Random Forest, RelieF Random Forest, Dynamic Integration of Random Forest, Small Random Forest, Forest-RK, BAGA Algorithm, Dynamic Random Forest, CUDA. I. INTRODUCTION In the current century, numerous of classification problems are observed that consist of large amount of data. Most commonly used algorithms are failed to classify data with better accuracy. Therefore, Random forest is introduced for the classification and regression of large amount of data. Random forest is an ensemble Machine Learning Technique. Machine Leaning Techniques are one of the applications of Data Mining. Data Mining Techniques are classified into two groups that are described below:},
author = {Goel, Eesha and Abhilasha, Er},
doi = {10.23956/ijarcsse/V7I1/01113},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Goel, Abhilasha - 2017 - International Journal of Advanced Research in Computer Science and Software Engineering Random Forest A Review.pdf:pdf},
number = {1},
title = {{International Journal of Advanced Research in Computer Science and Software Engineering Random Forest: A Review}},
url = {http://ijarcsse.com/Before{\_}August{\_}2017/docs/papers/Volume{\_}7/1{\_}January2017/V7I1-01113.pdf},
volume = {7},
year = {2017}
}
@inproceedings{Diefenbach2018,
address = {New York, New York, USA},
author = {Diefenbach, Dennis and Singh, Kamal and Maret, Pierre},
booktitle = {Companion of the The Web Conference 2018 on The Web Conference 2018  - WWW '18},
doi = {10.1145/3184558.3191541},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Diefenbach, Singh, Maret - 2018 - WDAqua-core1.pdf:pdf},
isbn = {9781450356404},
keywords = {QALD,mutlilinguality,portability,question answering over knowledge bases,robustness},
pages = {1087--1091},
publisher = {ACM Press},
title = {{WDAqua-core1}},
url = {http://dl.acm.org/citation.cfm?doid=3184558.3191541},
year = {2018}
}
@article{Grave2018,
abstract = {Distributed word representations, or word vectors, have recently been applied to many tasks in natural language processing, leading to state-of-the-art performance. A key ingredient to the successful application of these representations is to train them on very large corpora, and use these pre-trained models in downstream tasks. In this paper, we describe how we trained such high quality word representations for 157 languages. We used two sources of data to train these models: the free online encyclopedia Wikipedia and data from the common crawl project. We also introduce three new word analogy datasets to evaluate these word vectors, for French, Hindi and Polish. Finally, we evaluate our pre-trained word vectors on 10 languages for which evaluation datasets exists, showing very strong performance compared to previous models.},
archivePrefix = {arXiv},
arxivId = {1802.06893},
author = {Grave, Edouard and Bojanowski, Piotr and Gupta, Prakhar and Joulin, Armand and Mikolov, Tomas},
eprint = {1802.06893},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grave et al. - 2018 - Learning Word Vectors for 157 Languages.pdf:pdf},
month = {feb},
title = {{Learning Word Vectors for 157 Languages}},
url = {http://arxiv.org/abs/1802.06893},
year = {2018}
}
@article{Reynolds1987,
abstract = {The aggregate motion of a flock of birds, a herd of land ani-mals, or a school of fish is a beautiful and familiar part of the natural world. But this type of complex motion is rarely seen in computer animation. This paper explores an approach based on simulation as an alternative to scripting the paths of each bird individually. The simulated flock is an elaboration of a particle system, with the simulated birds being the particles. The aggregate motion of the simulated flock is created by a distributed behavioral model much like that at work in a natu-ral flock; the birds choose their own course. Each simulated bird is implemented as an independent actor that navigates ac-cording to its local perception of the dynamic environment, the laws of simulated physics that rule its motion, and a set of behaviors programmed into it by the "animator." The aggre-gate motion of the simulated flock is the result of the dense interaction of the relatively simple behaviors of the individual simulated birds.},
author = {Reynolds, Craig W},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Reynolds - 1987 - Flocks, Herds, and Schools A Distributed Behavioral Model.pdf:pdf},
keywords = {1210 [Artificial Intelli-gence],135 [Computer Graphics],137 [Computer Graphics],163 [Simulation and Modeling[,Algorithms,Appli-cations General Terms,Categories and Subject Descriptors,Computational Geometry and Object Modeling,Three-Dimensional Graphics and Realism--Animation,Vision and Scene Understanding,actor,aggregate motion,and Phrases,behav-ioral animation,bird,constraints,design Additional Key Words,fish,flight,flock,herd,particle system,path planning,school},
number = {4},
title = {{Flocks, Herds, and Schools: A Distributed Behavioral Model}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/583185/mod{\_}label/intro/reynolds-flock87.pdf},
volume = {21},
year = {1987}
}
@article{Coates,
abstract = {Scaling up deep learning algorithms has been shown to lead to increased performance in benchmark tasks and to enable discovery of complex high-level features. Recent efforts to train extremely large networks (with over 1 billion parameters) have relied on cloud-like computing infrastructure and thousands of CPU cores. In this paper, we present tech-nical details and results from our own sys-tem based on Commodity Off-The-Shelf High Performance Computing (COTS HPC) tech-nology: a cluster of GPU servers with Infini-band interconnects and MPI. Our system is able to train 1 billion parameter networks on just 3 machines in a couple of days, and we show that it can scale to networks with over 11 billion parameters using just 16 machines. As this infrastructure is much more easily marshaled by others, the approach enables much wider-spread research with extremely large neural networks.},
author = {Coates, Adam and Huval, Brody and Wang, Tao and Wu, David J and Ng, Andrew Y and Catanzaro, Bryan},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Coates et al. - 2013 - Deep learning with COTS HPC systems.pdf:pdf},
title = {{Deep learning with COTS HPC systems}},
url = {http://ai.stanford.edu/{~}acoates/papers/CoatesHuvalWangWuNgCatanzaro{\_}icml2013.pdf},
year = {2013}
}
@inproceedings{Singh2018,
address = {New York, New York, USA},
author = {Singh, Kuldeep and Lange, Christoph and Vidal, Maria Esther and Lehmann, Jens and Auer, S{\"{o}}ren and Radhakrishna, Arun Sethupat and Both, Andreas and Shekarpour, Saeedeh and Lytra, Ioanna and Usbeck, Ricardo and Vyas, Akhilesh and Khikmatullaev, Akmal and Punjani, Dharmen},
booktitle = {Proceedings of the 2018 World Wide Web Conference on World Wide Web - WWW '18},
doi = {10.1145/3178876.3186023},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh et al. - 2018 - Why Reinvent the Wheel.pdf:pdf},
isbn = {9781450356398},
pages = {1247--1256},
publisher = {ACM Press},
title = {{Why Reinvent the Wheel}},
url = {http://dl.acm.org/citation.cfm?doid=3178876.3186023},
year = {2018}
}
@article{Xu2014,
abstract = {Understanding natural language questions and converting them into structured queries have been considered as a crucial way to help users access large scale structured knowledge bases. However, the task usually involves two main challenges: recognizing users' query intention and mapping the involved semantic items against a given knowledge base (KB). In this paper, we propose an efficient pipeline framework to model a user's query intention as a phrase level dependency DAG which is then instantiated regarding a specific KB to construct the final structured query. Our model benefits from the efficiency of linear struc- tured prediction models and the separation of KB-independent and KB-related modelings. We evaluate our model on two datasets, and the experimental results showed that our method outperforms the state-of-the-art methods on the Free917 dataset, and, with limited training data from Free917, our model can smoothly adapt to new challenging dataset, WebQuestion, without extra training efforts while maintaining promising performance.},
author = {Xu, Kun and Zhang, Sheng and Feng, Yansong and Zhao, Dongyan},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2014 - Answering Natural Language Questions via Phrasal Semantic Parsing.pdf:pdf},
keywords = {Joint Disambiguation},
mendeley-tags = {Joint Disambiguation},
number = {2012},
pages = {333--344},
title = {{Answering Natural Language Questions via Phrasal Semantic Parsing}},
year = {2014}
}
@article{Xing2017,
abstract = {The reconstruction of gene regulatory network (GRN) from gene expression data can discover regulatory relationships among genes and gain deep insights into the complicated regulation mechanism of life. However, it is still a great challenge in systems biology and bioinformatics. During the past years, numerous computational approaches have been developed for this goal, and Bayesian network (BN) methods draw most of attention among these methods because of its inherent probability characteristics. However, Bayesian network methods are time consuming and cannot handle large-scale networks due to their high computational complexity, while the mutual information-based methods are highly effective but directionless and have a high false-positive rate. To solve these problems, we propose a Candidate Auto Selection algorithm (CAS) based on mutual information and breakpoint detection to restrict the search space in order to accelerate the learning process of Bayesian network. First, the proposed CAS algorithm automatically selects the neighbor candidates of each node before searching the best structure of GRN. Then based on CAS algorithm, we propose a globally optimal greedy search method (CAS + G), which focuses on finding the highest rated network structure, and a local learning method (CAS + L), which focuses on faster learning the structure with little loss of quality. Results show that the proposed CAS algorithm can effectively reduce the search space of Bayesian networks through identifying the neighbor candidates of each node. In our experiments, the CAS + G method outperforms the state-of-the-art method on simulation data for inferring GRNs, and the CAS + L method is significantly faster than the state-of-the-art method with little loss of accuracy. Hence, the CAS based methods effectively decrease the computational complexity of Bayesian network and are more suitable for GRN inference.},
author = {Xing, Linlin and Guo, Maozu and Liu, Xiaoyan and Wang, Chunyu and Wang, Lei and Zhang, Yin},
doi = {10.1186/s12864-017-4228-y},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xing et al. - 2017 - An improved Bayesian network method for reconstructing gene regulatory network based on candidate auto selection(2).pdf:pdf},
issn = {1471-2164},
journal = {BMC Genomics},
keywords = {Animal Genetics and Genomics,Life Sciences,Microarrays,Microbial Genetics and Genomics,Plant Genetics and Genomics,Proteomics,general},
month = {nov},
number = {S9},
pages = {844},
publisher = {BioMed Central},
title = {{An improved Bayesian network method for reconstructing gene regulatory network based on candidate auto selection}},
url = {https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-017-4228-y},
volume = {18},
year = {2017}
}
@article{Schwarz1978,
author = {Schwarz, Gideon},
doi = {10.1214/aos/1176344136},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schwarz - 1978 - Estimating the Dimension of a Model.pdf:pdf},
issn = {0090-5364},
journal = {The Annals of Statistics},
keywords = {Akaike information criterion,Dimension,asymptotics},
month = {mar},
number = {2},
pages = {461--464},
publisher = {Institute of Mathematical Statistics},
title = {{Estimating the Dimension of a Model}},
url = {http://projecteuclid.org/euclid.aos/1176344136},
volume = {6},
year = {1978}
}
@article{Hoffart2011,
author = {Hoffart, Johannes and Yosef, Mohamed Amir and Bordino, Ilaria and F{\"{u}}rstenau, Hagen and Pinkal, Manfred and Spaniol, Marc and Taneva, Bilyana and Thater, Stefan and Weikum, Gerhard},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoffart et al. - 2011 - Robust disambiguation of named entities in text.pdf:pdf},
isbn = {978-1-937284-11-4},
journal = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
pages = {782--792},
publisher = {Association for Computational Linguistics},
title = {{Robust disambiguation of named entities in text}},
url = {https://dl.acm.org/citation.cfm?id=2145521},
year = {2011}
}
@article{Mikolov2017,
abstract = {Many Natural Language Processing applications nowadays rely on pre-trained word representations estimated from large text corpora such as news collections, Wikipedia and Web Crawl. In this paper, we show how to train high-quality word vector representations by using a combination of known tricks that are however rarely used together. The main result of our work is the new set of publicly available pre-trained models that outperform the current state of the art by a large margin on a number of tasks.},
archivePrefix = {arXiv},
arxivId = {1712.09405},
author = {Mikolov, Tomas and Grave, Edouard and Bojanowski, Piotr and Puhrsch, Christian and Joulin, Armand},
eprint = {1712.09405},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mikolov et al. - 2017 - Advances in Pre-Training Distributed Word Representations.pdf:pdf},
month = {dec},
title = {{Advances in Pre-Training Distributed Word Representations}},
url = {http://arxiv.org/abs/1712.09405},
year = {2017}
}
@article{Guo,
abstract = {Swarm intelligence algorithms are wildly used in different areas. The bare bones particle swarm optimization (BBPSO) is one of them. In the BBPSO, the next position of a particle is chosen from the Gaussian distribution. However, all particles learning from the only global best particle may cause the premature convergence and rapid diversity-losing. Thus, a BBPSO with dynamic local search (DLS-BBPSO) is proposed to solve these problems. Also, because the blind setting of local group may cause the time complexity an unpredictable increase, a dynamic strategy is used in the process of local group cre-ation to avoid this situation. Moreover, to confirm the searching ability of the proposed algorithm, a set of well-known benchmark functions are used in the experiments. Both unimodal and multimodal functions are considered to enhance the persuasion of the test. Meanwhile, the BBPSO and several other evolutionary algorithms are used as the control group. At last, the results of the experiment confirm the searching ability of the proposed algorithm in the test functions.},
author = {Guo, Jia and Sato, Yuji},
doi = {10.1007/978-3-319-61824-1},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo, Sato - Unknown - A Bare Bones Particle Swarm Optimization Algorithm with Dynamic Local Search.pdf:pdf},
keywords = {Bare bones {\textperiodcentered},Diversity,Dynamic local search {\textperiodcentered},Swarm intelligence {\textperiodcentered}},
title = {{A Bare Bones Particle Swarm Optimization Algorithm with Dynamic Local Search}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1327619/mod{\_}label/intro/guo-bareBonespsoWithDynamicLocalSearch-2017.pdf}
}
@incollection{Dietterich2000,
author = {Dietterich, Thomas G.},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dietterich - 2000 - Ensemble Methods in Machine Learning.pdf:pdf},
pages = {1--15},
title = {{Ensemble Methods in Machine Learning}},
url = {http://link.springer.com/10.1007/3-540-45014-9{\_}1},
year = {2000}
}
@article{Chen2018a,
abstract = {Abstract Lifelong Machine Learning, Second Edition is an introduction to an advanced machine learning paradigm that continuously learns by accumulating past knowledge that it then uses in future le...},
author = {Chen, Zhiyuan and Liu, Bing},
doi = {10.2200/S00832ED1V01Y201802AIM037},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Liu - 2018 - Lifelong Machine Learning, Second Edition.pdf:pdf},
issn = {1939-4608},
journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
keywords = {continual learning,continuous learning,lifelong learning,lifelong machine learning,meta-learning,multi-task learning,never-ending learning,transfer learning},
month = {aug},
number = {3},
pages = {1--207},
publisher = {Morgan {\&} Claypool Publishers},
title = {{Lifelong Machine Learning, Second Edition}},
url = {https://www.morganclaypool.com/doi/10.2200/S00832ED1V01Y201802AIM037},
volume = {12},
year = {2018}
}
@inproceedings{Roos2008,
author = {Roos, Teemu and Silander, Tomi and Kontkanen, Petri and Myllymaki, Petri},
booktitle = {2008 Information Theory and Applications Workshop},
doi = {10.1109/ITA.2008.4601061},
isbn = {978-1-4244-2670-6},
month = {jan},
pages = {272--276},
publisher = {IEEE},
title = {{Bayesian network structure learning using factorized NML universal models}},
url = {http://ieeexplore.ieee.org/document/4601061/},
year = {2008}
}
@incollection{Tsymbal2006,
author = {Tsymbal, Alexey and Pechenizkiy, Mykola and Cunningham, P{\'{a}}draig},
doi = {10.1007/11871842_82},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tsymbal, Pechenizkiy, Cunningham - 2006 - Dynamic Integration with Random Forests.pdf:pdf},
pages = {801--808},
title = {{Dynamic Integration with Random Forests}},
url = {http://link.springer.com/10.1007/11871842{\_}82},
year = {2006}
}
@inproceedings{Lukovnikov2017,
address = {New York, New York, USA},
author = {Lukovnikov, Denis and Fischer, Asja and Lehmann, Jens and Auer, S{\"{o}}ren},
booktitle = {Proceedings of the 26th International Conference on World Wide Web - WWW '17},
doi = {10.1145/3038912.3052675},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lukovnikov et al. - 2017 - Neural Network-based Question Answering over Knowledge Graphs on Word and Character Level.pdf:pdf},
isbn = {9781450349130},
keywords = {knowledge graphs,question answering},
pages = {1211--1220},
publisher = {ACM Press},
title = {{Neural Network-based Question Answering over Knowledge Graphs on Word and Character Level}},
url = {http://dl.acm.org/citation.cfm?doid=3038912.3052675},
year = {2017}
}
@article{Vaswani2017,
abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
archivePrefix = {arXiv},
arxivId = {1706.03762},
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
eprint = {1706.03762},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Vaswani et al. - 2017 - Attention Is All You Need.pdf:pdf},
month = {jun},
title = {{Attention Is All You Need}},
url = {http://arxiv.org/abs/1706.03762},
year = {2017}
}
@article{Martinez2001,
author = {Martinez, A.M. and Kak, A.C.},
doi = {10.1109/34.908974},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
number = {2},
pages = {228--233},
title = {{PCA versus LDA}},
url = {http://ieeexplore.ieee.org/document/908974/},
volume = {23},
year = {2001}
}
@inproceedings{gabor2018semeval,
author = {G{\'{a}}bor, Kata and Buscaldi, Davide and Schumann, Anne-Kathrin and QasemiZadeh, Behrang and Zargayouna, Haifa and Charnois, Thierry},
booktitle = {Proceedings of The 12th International Workshop on Semantic Evaluation},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/G{\'{a}}bor et al. - 2018 - Semeval-2018 Task 7 Semantic relation extraction and classification in scientific papers.pdf:pdf},
pages = {679--688},
title = {{Semeval-2018 Task 7: Semantic relation extraction and classification in scientific papers}},
year = {2018}
}
@article{Silver,
abstract = {In this paper we consider deterministic policy gradient algorithms for reinforcement learning with continuous actions. The deterministic pol-icy gradient has a particularly appealing form: it is the expected gradient of the action-value func-tion. This simple form means that the deter-ministic policy gradient can be estimated much more efficiently than the usual stochastic pol-icy gradient. To ensure adequate exploration, we introduce an off-policy actor-critic algorithm that learns a deterministic target policy from an exploratory behaviour policy. We demonstrate that deterministic policy gradient algorithms can significantly outperform their stochastic counter-parts in high-dimensional action spaces.},
author = {Silver, David and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Silver et al. - Unknown - Deterministic Policy Gradient Algorithms.pdf:pdf},
title = {{Deterministic Policy Gradient Algorithms}},
url = {http://proceedings.mlr.press/v32/silver14.pdf}
}
@article{DykeParunak,
abstract = {The individual agents that interact in a multi-agent system typically exist along a continuum ranging from heavyweight cognitive agents (often of the " BDI " type) to lightweight agents with limited individual processing (digital ants). Most systems use agents from a single position along this spectrum. We have successfully implemented several systems in which agents of very different degrees of internal sophistication interact with one another. Based on this experience, we identify several different ways in which agents of different kinds can be integrated in a single system, and offer observations and lessons from our experiences.},
author = {{Dyke Parunak}, H Van and Nielsen, Paul and Brueckner, Sven and Alonso, Rafael},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dyke Parunak et al. - Unknown - Hybrid Multi-Agent Systems Integrating Swarming and BDI Agents.pdf:pdf},
title = {{Hybrid Multi-Agent Systems: Integrating Swarming and BDI Agents}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1327632/mod{\_}label/intro/vanParunak-engineeringSelfOrganisingSystems-hybridMultiAgent-2007.pdf}
}
@article{doi:10.1080/14786440109462720,
author = {F.R.S., Karl Pearson},
doi = {10.1080/14786440109462720},
journal = {Philosophical Magazine},
number = {11},
pages = {559--572},
title = {{LIII. On lines and planes of closest fit to systems of points in space}},
url = {http://dx.doi.org/10.1080/14786440109462720},
volume = {2},
year = {1901}
}
@article{Krizhevsky,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 dif-ferent classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%} which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make train-ing faster, we used non-saturating neurons and a very efficient GPU implemen-tation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called " dropout " that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krizhevsky, Sutskever, Hinton - 2012 - ImageNet Classification with Deep Convolutional Neural Networks.pdf:pdf},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
url = {https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
year = {2012}
}
@misc{callan2009clueweb09,
author = {Callan, Jamie and Hoy, Mark and Yoo, Changkuk and Zhao, Le},
title = {{Clueweb09 data set}},
year = {2009}
}
@article{AraujodosSantosa,
author = {{Araujo dos Santos}, Leonardo},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Araujo dos Santos - Unknown - Artificial Intelligence and Deep Learning.pdf:pdf},
title = {{Artificial Intelligence and Deep Learning}}
}
@article{Hoffmann,
abstract = {Particle swarm optimization (PSO) is a nature-inspired tech-nique originally designed for solving continuous optimization problems. There already exist several approaches that use PSO also as basis for solving discrete optimization problems, in particular the Traveling Sales-person Problem (TSP). In this paper, (i) we present the first theoretical analysis of a discrete PSO algorithm for TSP which also provides insight into the convergence behavior of the swarm. In particular, we prove that the popular choice of using " sequences of transpositions " as the difference between tours tends to decrease the convergence rate. (ii) In the light of this observation, we present a new notion of difference between tours based on " edge exchanges " and a new method to combine differences by computing their " centroid. " This leads to a more PSO-like behavior of the algorithm and avoids the observed slow down effect. (iii) Then, we investigate implementations of our methods and compare them with previous implementations showing the competitiveness of our new ap-proaches.},
author = {Hoffmann, Matthias and M{\"{u}}hlenthaler, Moritz and Helwig, Sabine and Wanka, Rolf},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoffmann et al. - Unknown - Discrete Particle Swarm Optimization for TSP Theoretical Results and Experimental Evaluations.pdf:pdf},
title = {{Discrete Particle Swarm Optimization for TSP: Theoretical Results and Experimental Evaluations}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132260/mod{\_}label/intro/hoffmann-discretePSO{\_}TSP-2011.pdf}
}
@article{Bahdanau2014,
abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
archivePrefix = {arXiv},
arxivId = {1409.0473},
author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
eprint = {1409.0473},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bahdanau, Cho, Bengio - 2014 - Neural Machine Translation by Jointly Learning to Align and Translate.pdf:pdf},
month = {sep},
title = {{Neural Machine Translation by Jointly Learning to Align and Translate}},
url = {http://arxiv.org/abs/1409.0473},
year = {2014}
}
@article{Bautista2002,
abstract = {The present work is focused on the assembly line balancing design problems whose objective is to minimize the number of stations needed to manufacture a product in a line given a fixed cycle time, equivalent to a fixed production rate. The problem is solved using an ACO metaheuristic implementation with different features, obtaining good results. Afterwards, an adaptation of the previous implementation is used to solve a real case problem found in a bike assembly line with a hierarchical multi-objective function and additional constraints between tasks.},
author = {Bautista, Joaqu{\'{i}}n and Pereira, Jordi},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bautista, Pereira - 2002 - Ant Algorithms for Assembly Line Balancing.pdf:pdf},
journal = {LNCS},
pages = {65--75},
title = {{Ant Algorithms for Assembly Line Balancing}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132239/mod{\_}label/intro/Ant algorithms for assembly line balancing {\%}28Bautista{\%}2C Pereira{\%}2C 02{\%}29.pdf},
volume = {2463},
year = {2002}
}
@article{kuncheva2003,
abstract = {Diversity among the members of a team of classifiers is deemed to be a key issue in classifier combination. However, measuring diversity is not straightforward because there is no generally accepted formal definition. We have found and studied ten statistics which can measure diversity among binary classifier outputs (correct or incorrect vote for the class label): four averaged pairwise measures (the Q statistic, the correlation, the disagreement and the double fault) and six non-pairwise measures (the entropy of the votes, the difficulty index, the Kohavi-Wolpert variance, the interrater agreement, the generalized diversity, and the coincident failure diversity). Four experiments have been designed to examine the relationship between the accuracy of the team and the measures of diversity, and among the measures themselves. Although there are proven connections between diversity and accuracy in some special cases, our results raise some doubts about the usefulness of diversity measures in building classifier ensembles in real-life pattern recognition problems.},
author = {Kuncheva, Ludmila I and Whitaker, Christopher},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/KUNCHEVA likuncheva, CHRISTOPHER WHITAKER cjwhitaker - 2003 - Measures of Diversity in Classifier Ensembles and Their Relationship with.pdf:pdf},
journal = {Machine Learning},
keywords = {dependency and diversity,majority vote,pattern recognition},
pages = {181--207},
title = {{Measures of Diversity in Classifier Ensembles and Their Relationship with the Ensemble Accuracy}},
url = {https://link.springer.com/content/pdf/10.1023/A:1022859003006.pdf},
volume = {51},
year = {2003}
}
@article{Ioffe2015,
abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on ImageNet classification: reaching 4.9{\%} top-5 validation error (and 4.8{\%} test error), exceeding the accuracy of human raters.},
archivePrefix = {arXiv},
arxivId = {1502.03167},
author = {Ioffe, Sergey and Szegedy, Christian},
eprint = {1502.03167},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ioffe, Szegedy - 2015 - Batch Normalization Accelerating Deep Network Training by Reducing Internal Covariate Shift.pdf:pdf},
month = {feb},
title = {{Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift}},
url = {http://arxiv.org/abs/1502.03167},
year = {2015}
}
@article{McCloskey1989,
abstract = {Connectionist networks in which information is stored in weights on connections among simple processing units have attracted considerable interest in cognitive science. Much of the interest centers around two characteristics of these networks. First, the weights on connections between units need not be prewired by the model builder but rather may be established through training in which items to be learned are presented repeatedly to the network and the connection weights are adjusted in small increments according to a learning algorithm. Second, the networks may represent information in a distributed fashion. This chapter discusses the catastrophic interference in connectionist networks. Distributed representations established through the application of learning algorithms have several properties that are claimed to be desirable from the standpoint of modeling human cognition. These properties include content-addressable memory and so-called automatic generalization in which a network trained on a set of items responds correctly to other untrained items within the same domain. New learning may interfere catastrophically with old learning when networks are trained sequentially. The analysis of the causes of interference implies that at least some interference will occur whenever new learning may alter weights involved in representing old learning, and the simulation results demonstrate only that interference is catastrophic in some specific networks.},
author = {McCloskey, Michael and Cohen, Neal J.},
doi = {10.1016/S0079-7421(08)60536-8},
isbn = {9780125433242},
issn = {0079-7421},
journal = {Psychology of Learning and Motivation},
month = {jan},
pages = {109--165},
publisher = {Academic Press},
title = {{Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem}},
url = {https://www.sciencedirect.com/science/article/pii/S0079742108605368},
volume = {24},
year = {1989}
}
@article{Joshi2017,
abstract = {We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23{\%} and 40{\%} vs. 80{\%}), suggesting that TriviaQA is a challenging testbed that is worth significant future study. Data and code available at -- http://nlp.cs.washington.edu/triviaqa/},
archivePrefix = {arXiv},
arxivId = {1705.03551},
author = {Joshi, Mandar and Choi, Eunsol and Weld, Daniel S. and Zettlemoyer, Luke},
eprint = {1705.03551},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Joshi et al. - 2017 - TriviaQA A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension.pdf:pdf},
month = {may},
title = {{TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension}},
url = {http://arxiv.org/abs/1705.03551},
year = {2017}
}
@article{Kadlec2017,
abstract = {Many papers have been published on the knowledge base completion task in the past few years. Most of these introduce novel architectures for relation learning that are evaluated on standard datasets such as FB15k and WN18. This paper shows that the accuracy of almost all models published on the FB15k can be outperformed by an appropriately tuned baseline - our reimplementation of the DistMult model. Our findings cast doubt on the claim that the performance improvements of recent models are due to architectural changes as opposed to hyper-parameter tuning or different training objectives. This should prompt future research to re-consider how the performance of models is evaluated and reported.},
archivePrefix = {arXiv},
arxivId = {1705.10744},
author = {Kadlec, Rudolf and Bajgar, Ondrej and Kleindienst, Jan},
eprint = {1705.10744},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kadlec, Bajgar, Kleindienst - 2017 - Knowledge Base Completion Baselines Strike Back.pdf:pdf},
month = {may},
title = {{Knowledge Base Completion: Baselines Strike Back}},
url = {http://arxiv.org/abs/1705.10744},
year = {2017}
}
@article{Cortes1995,
author = {Cortes, Corinna and Vapnik, Vladimir},
doi = {10.1007/BF00994018},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cortes, Vapnik - 1995 - Support-vector networks.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
month = {sep},
number = {3},
pages = {273--297},
publisher = {Kluwer Academic Publishers},
title = {{Support-vector networks}},
url = {http://link.springer.com/10.1007/BF00994018},
volume = {20},
year = {1995}
}
@article{Salman,
abstract = {Task assignment is one of the core steps to effectively exploit the capabilities of distributed or parallel computing systems. The task assignment problem is an NP-complete problem. In this paper, we present a new task assignment algorithm that is based on the principles of particle swarm optimization (PSO). PSO follows a collaborative population-based search, which models over the social behavior of bird flocking and fish schooling. PSO system combines local search methods (through self experience) with global search methods (through neighboring experience), attempting to balance exploration and exploitation. We discuss the adaptation and implementation of the PSO search strategy to the task assignment problem. The effectiveness of the proposed PSO-based algorithm is demonstrated by comparing it with the genetic algorithm, which is well-known population-based probabilistic heuristic, on randomly generated task interaction graphs. Simulation results indicate that PSO-based algorithm is a viable approach for the task assignment problem. q},
author = {Salman, Ayed and Ahmad, Imtiaz and Al-Madani, Sabah},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Salman, Ahmad, Al-Madani - Unknown - Particle swarm optimization for task assignment problem.pdf:pdf},
keywords = {Particle swarm optimization,Task assignment problem,Task interaction graph},
title = {{Particle swarm optimization for task assignment problem}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132260/mod{\_}label/intro/salman-particleSwarmAssignment-02.pdf}
}
@incollection{and1995b,
author = {{R. C. Eberhart}, J.Kennedy},
booktitle = {Proc. IEEE International Conference on Neural Networks},
pages = {1942--1948},
title = {{Particle swarm optimization}},
volume = {4}
}
@article{Scherer2012,
abstract = {Most clustering methods rely on central data structures and/or cannot cope with dynamically changing settings. Besides, these methods need some hints about the target clustering. However, issues related to the current use of Internet resources (distribution of data, privacy, etc.) require new ways of dealing with data clustering. In multiagent systems this is also becoming an issue as one wishes to group agents according to some features of the environment in order to have agents accomplishing the available tasks in an efficient way. In this paper we discuss the application of a clustering algorithm that is inspired by swarm intelligence techniques such as organization of bee colonies and task allocation among social insects. This application involves a complex task allocation scenario, the RoboCup Rescue, where tasks with different characteristics must be allocated to agents with different capabilities. Our results have shown that clustering agents is effective in this scenario as agents act in a more coordinated way.},
author = {Scherer, Daniela and Santos, Dos and Bazzan, Ana L C},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scherer, Santos, Bazzan - 2012 - Distributed clustering for group formation and task allocation in multiagent systems A swarm intelligen.pdf:pdf},
journal = {Applied Soft Computing},
pages = {2123--2131},
title = {{Distributed clustering for group formation and task allocation in multiagent systems: A swarm intelligence approach}},
url = {http://www.elsevier.com/copyright},
volume = {12},
year = {2012}
}
@article{KoivistoMIKKOKOIVISTO2004,
abstract = {Learning a Bayesian network structure from data is a well-motivated but computationally hard task. We present an algorithm that computes the exact posterior probability of a subnetwork, e.g., a di-rected edge; a modified version of the algorithm finds one of the most probable network structures. This algorithm runs in time O(n2 n + n k+1 C(m)), where n is the number of network variables, k is a constant maximum in-degree, and C(m) is the cost of computing a single local marginal condi-tional likelihood for m data instances. This is the first algorithm with less than super-exponential complexity with respect to n. Exact computation allows us to tackle complex cases where existing Monte Carlo methods and local search procedures potentially fail. We show that also in domains with a large number of variables, exact computation is feasible, given suitable a priori restrictions on the structures; combining exact and inexact methods is also possible. We demonstrate the appli-cability of the presented algorithm on four synthetic data sets with 17, 22, 37, and 100 variables.},
author = {Koivisto, Mikko and Sood, Kismat},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Koivisto MIKKOKOIVISTO, Sood KISMATSOOD - 2004 - Exact Bayesian Structure Discovery in Bayesian Networks.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {complex interactions,dynamic programming,layering,structure learning},
pages = {549--573},
title = {{Exact Bayesian Structure Discovery in Bayesian Networks}},
url = {http://www.jmlr.org/papers/volume5/koivisto04a/koivisto04a.pdf},
volume = {5},
year = {2004}
}
@article{Spirtes,
abstract = {This paper describes a new greedy Bayesian search algorithm (GBPS) and a new "combined" algorithm PC+GBPS for learning Bayesian net-works. Simulation tests of these algorithms with previously published algorithms are presented. Introduction A Bayesian network consists of two distinct parts: a directed acyclic graph (DAG or belief-network struc-ture) and a set of parameters for the DAG. The DAG in a Bayesian network can be used to represent both causal hypotheses and sets of probability distributions. Under the causal interpretation, a DAG represents the causal relations in a given population with a set of ver-tices V when there is an edge from a to b if and only if a is a direct cause of b relative to V. (We adopt the convention that sets of variables are capitalized and italicized, and individual variables are italicized.) Un-der the statistical interpretation (in the discrete case considered in this article) a DAG G can be taken to represent the set of all distributions that factor accord-ing to G in the following way: P(V) = II P(x]H{\~{}})},
author = {Spirtes, Peter},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Spirtes - Unknown - Learning Bayesian Networks with Discrete Variables from Data.pdf:pdf},
title = {{Learning Bayesian Networks with Discrete Variables from Data*}},
url = {http://www.aaai.org/Papers/KDD/1995/KDD95-048.pdf},
year = {1995}
}
@article{Cheng,
abstract = {We describe a decentralized algorithm for coordinating a swarm of identically-programmed mobile agents to spatially self-aggregate into arbitrary shapes using only local interactions. Our approach, called SHAPEBUGS, generates a consensus coordinate system by agents continually performing local trilaterations, and achieves shape formation by simultaneously allowing agents to disperse within the defined 2D shape using a Contained Gas Model. This approach has several novel features (1) agents can easily aggregate into arbitrary user-specified shapes, using a formation process that is independent of the number of agents (2) the system automatically adapts to influx and death of agents, as well as accidental displacement. We show that the consensus coordinate system is robust and provides reasonable accuracy in the face of significant sensor and movement error.},
author = {Cheng, Jimming and Cheng, Winston and Nagpal, Radhika},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cheng, Cheng, Nagpal - Unknown - Robust and self-repairing formation control for swarms of mobile agents.pdf:pdf},
title = {{Robust and self-repairing formation control for swarms of mobile agents}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132229/mod{\_}label/intro/Shapebugs {\%}28Cheng et al 05{\%}29.pdf}
}
@inproceedings{li-etal-2018-seq2seq,
abstract = {This paper presents a sequence to sequence (seq2seq) dependency parser by directly predicting the relative position of head for each given word, which therefore results in a truly end-to-end seq2seq dependency parser for the first time. Enjoying the advantage of seq2seq modeling, we enrich a series of embedding enhancement, including firstly introduced subword and node2vec augmentation. Meanwhile, we propose a beam search decoder with tree constraint and subroot decomposition over the sequence to furthermore enhance our seq2seq parser. Our parser is evaluated on benchmark treebanks, being on par with the state-of-the-art parsers by achieving 94.11{\%} UAS on PTB and 88.78{\%} UAS on CTB, respectively.},
address = {Santa Fe, New Mexico, USA},
author = {Li, Zuchao and Cai, Jiaxun and He, Shexia and Zhao, Hai},
booktitle = {Proceedings of the 27th International Conference on Computational Linguistics},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - 2018 - Seq2seq Dependency Parsing(2).pdf:pdf},
pages = {3203--3214},
publisher = {Association for Computational Linguistics},
title = {{Seq2seq Dependency Parsing}},
url = {https://www.aclweb.org/anthology/C18-1271},
year = {2018}
}
@inproceedings{mikolov2013distributed,
author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
booktitle = {Advances in neural information processing systems},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mikolov et al. - 2013 - Distributed representations of words and phrases and their compositionality.pdf:pdf},
pages = {3111--3119},
title = {{Distributed representations of words and phrases and their compositionality}},
year = {2013}
}
@article{Rusu2016,
abstract = {Learning to solve complex sequences of tasks--while both leveraging transfer and avoiding catastrophic forgetting--remains a key obstacle to achieving human-level intelligence. The progressive networks approach represents a step forward in this direction: they are immune to forgetting and can leverage prior knowledge via lateral connections to previously learned features. We evaluate this architecture extensively on a wide variety of reinforcement learning tasks (Atari and 3D maze games), and show that it outperforms common baselines based on pretraining and finetuning. Using a novel sensitivity measure, we demonstrate that transfer occurs at both low-level sensory and high-level control layers of the learned policy.},
archivePrefix = {arXiv},
arxivId = {1606.04671},
author = {Rusu, Andrei A. and Rabinowitz, Neil C. and Desjardins, Guillaume and Soyer, Hubert and Kirkpatrick, James and Kavukcuoglu, Koray and Pascanu, Razvan and Hadsell, Raia},
eprint = {1606.04671},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rusu et al. - 2016 - Progressive Neural Networks.pdf:pdf},
month = {jun},
title = {{Progressive Neural Networks}},
url = {http://arxiv.org/abs/1606.04671},
year = {2016}
}
@book{choset2005a,
address = {Cambridge, Mass},
author = {Choset, Howie M},
publisher = {MIT Press},
title = {{Principles of Robot Motion: Theory, Algorithms, and Implementation}}
}
@article{Mazumder2018,
abstract = {Although chatbots have been very popular in recent years, they still have some serious weaknesses which limit the scope of their applications. One major weakness is that they cannot learn new knowledge during the conversation process, i.e., their knowledge is fixed beforehand and cannot be expanded or updated during conversation. In this paper, we propose to build a general knowledge learning engine for chatbots to enable them to continuously and interactively learn new knowledge during conversations. As time goes by, they become more and more knowledgeable and better and better at learning and conversation. We model the task as an open-world knowledge base completion problem and propose a novel technique called lifelong interactive learning and inference (LiLi) to solve it. LiLi works by imitating how humans acquire knowledge and perform inference during an interactive conversation. Our experimental results show LiLi is highly promising.},
archivePrefix = {arXiv},
arxivId = {1802.06024},
author = {Mazumder, Sahisnu and Ma, Nianzu and Liu, Bing},
eprint = {1802.06024},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mazumder, Ma, Liu - 2018 - Towards a Continuous Knowledge Learning Engine for Chatbots(2).pdf:pdf},
month = {feb},
title = {{Towards a Continuous Knowledge Learning Engine for Chatbots}},
url = {http://arxiv.org/abs/1802.06024},
year = {2018}
}
@article{Mnih,
abstract = {We present the first deep learning model to successfully learn control policies di-rectly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learn-ing Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mnih et al. - Unknown - Playing Atari with Deep Reinforcement Learning.pdf:pdf},
title = {{Playing Atari with Deep Reinforcement Learning}},
url = {https://arxiv.org/pdf/1312.5602.pdf}
}
@inproceedings{eband,
author = {Quinlan, S and Khatib, O},
booktitle = {[1993] Proceedings IEEE International Conference on Robotics and Automation},
doi = {10.1109/ROBOT.1993.291936},
keywords = {Computer science,Control systems,Control theory,Joining processes,Laboratories,Path planning,Robot control,Robot sensing systems,Shape,Uncertainty,bubbles,computerised control,deformable collision-free path,elastic band,global path planning,path planning,real-time sensor-based robot control,robots,uncertainties},
month = {may},
pages = {802--807 vol.2},
title = {{Elastic bands: connecting path planning and control}},
year = {1993}
}
@article{Glorot,
abstract = {Whereas before 2006 it appears that deep multi-layer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experi-mental results showing the superiority of deeper vs less deep architectures. All these experimen-tal results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future. We first observe the influence of the non-linear activations func-tions. We find that the logistic sigmoid activation is unsuited for deep networks with random ini-tialization because of its mean value, which can drive especially the top hidden layer into satu-ration. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during train-ing, with the idea that training may be more dif-ficult when the singular values of the Jacobian associated with each layer are far from 1. Based on these considerations, we propose a new ini-tialization scheme that brings substantially faster convergence.},
author = {Glorot, Xavier and Bengio, Yoshua},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Glorot, Bengio - 2010 - Understanding the difficulty of training deep feedforward neural networks.pdf:pdf},
title = {{Understanding the difficulty of training deep feedforward neural networks}},
url = {http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf},
year = {2010}
}
@article{Scanagatta2017,
abstract = {We present a novel approach for score-based structure learning of Bayesian network, which couples an existing ordering-based algorithm for structure optimization with a novel op-erator for exploring the neighborhood of a given order in the space of the orderings. Our approach achieves state-of-the-art performances in data sets containing thousands of vari-ables.},
author = {Scanagatta, Mauro and {Ch Idsia}, Mauro@idsia and Supsi, Usi-Lugano and Corani, Switzerland Giorgio and {Ch Idsia}, Giorgio@idsia and Marco, Switzerland and {Ch Idsia}, Zaffalon Zaffalon@idsia and -Lugano, Switzerland},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scanagatta et al. - 2017 - Improved Local Search in Bayesian Networks Structure Learning(2).pdf:pdf},
journal = {Proceedings of Machine Learning Research},
keywords = {Bayesian networks,Heuristic Search,Learning Graphical Models},
pages = {45--56},
title = {{Improved Local Search in Bayesian Networks Structure Learning}},
url = {http://proceedings.mlr.press/v73/scanagatta17a/scanagatta17a.pdf},
volume = {73},
year = {2017}
}
@incollection{latinne2001,
author = {Latinne, Patrice and Debeir, Olivier and Decaestecker, Christine},
doi = {10.1007/3-540-48219-9_18},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Latinne, Debeir, Decaestecker - 2001 - Limiting the Number of Trees in Random Forests.pdf:pdf},
pages = {178--187},
title = {{Limiting the Number of Trees in Random Forests}},
url = {http://link.springer.com/10.1007/3-540-48219-9{\_}18},
year = {2001}
}
@inproceedings{zhang2013query,
author = {Zhang, N and Creput, J C and Hongjian, W and Meurie, C and Ruichek, Y},
booktitle = {3rd International Conference on Advanced Communications and Computation, INFOCOMP, pages p33--38},
title = {{Query Answering using user feedback and context gathering for Web of Data}},
year = {2013}
}
@incollection{mayfield2012a,
author = {Mayfield, James and Artiles, Javier and {and Hoa Trang Dang}},
booktitle = {Proc. of the 5th Text Analysis Conference, TAC},
title = {{Overview of the TAC 2012 knowledge base population track}},
volume = {12},
year = {2012}
}
@misc{Karpathy,
author = {Karpathy, Christian (stanford)},
title = {{CS231n Convolutional Neural Networks for Visual Recognition}},
url = {http://cs231n.github.io/convolutional-networks/{\#}fc},
urldate = {2017-06-09}
}
@article{Luo,
abstract = {Grey wolf optimization (GWO) algorithm is a novel nature-inspired heuristic paradigm. GWO was inspired by grey wolves, which mimics the leadership hierarchy and hunting mechanism of grey wolves in nature. It has exhibited promising performance in many fields. However, GWO algorithm has the drawback of slow convergence and low precision. In order to overcome this drawback, we propose an improved version of GWO enhanced by the L{\'{e}}vy-flight strategy, termed as LGWO. L{\'{e}}vy-flight strategy was introduced into the GWO to find better solutions when the grey wolves fall into the local optimums. The effectiveness of LGWO has been rigorously evaluated against ten bench-mark functions. The experimental results demonstrate that the proposed approach outperforms the other three counterparts.},
author = {Luo, Jie and Chen, Huiling and Wang, Kejie and Tong, Changfei and Li, Jun and Cai, Zhennao},
doi = {10.1007/978-3-319-61824-1_11},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Luo et al. - Unknown - LGWO An Improved Grey Wolf Optimization for Function Optimization.pdf:pdf},
keywords = {Function optimization {\'{A}} L{\'{e}}vy-flight,Grey wolf optimization {\'{A}}},
title = {{LGWO: An Improved Grey Wolf Optimization for Function Optimization}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1327619/mod{\_}label/intro/luo-lgwo-improvedGreyWolf-2017.pdf}
}
@article{Rumelhart1986,
annote = {10.1038/323533a0},
author = {Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
journal = {Nature},
month = {oct},
number = {6088},
pages = {533--536},
title = {{Learning representations by back-propagating errors}},
url = {http://dx.doi.org/10.1038/323533a0},
volume = {323},
year = {1986}
}
@inproceedings{Ding-BingLin,
author = {{Ding-Bing Lin} and {Rong-Terng Juang} and {Hsin-Piao Lin}},
booktitle = {2005 IEEE 61st Vehicular Technology Conference},
doi = {10.1109/VETECS.2005.1543770},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ding-Bing Lin, Rong-Terng Juang, Hsin-Piao Lin - Unknown - Robust Mobile Location Estimation Based on Signal Attenuation for Cellular Co.pdf:pdf},
isbn = {0-7803-8887-9},
pages = {2425--2428},
publisher = {IEEE},
title = {{Robust Mobile Location Estimation Based on Signal Attenuation for Cellular Communication Systems}},
url = {http://ieeexplore.ieee.org/document/1543770/},
volume = {4}
}
@article{Szegedy2014,
abstract = {We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
archivePrefix = {arXiv},
arxivId = {1409.4842},
author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
eprint = {1409.4842},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Szegedy et al. - 2014 - Going Deeper with Convolutions.pdf:pdf},
month = {sep},
title = {{Going Deeper with Convolutions}},
url = {http://arxiv.org/abs/1409.4842},
year = {2014}
}
@article{Rosenfeld1989,
author = {Rosenfeld, A.},
doi = {10.1109/10.16452},
issn = {00189294},
journal = {IEEE Transactions on Biomedical Engineering},
number = {1},
pages = {93--96},
title = {{Computer vision: a source of models for biological visual processes?}},
url = {http://ieeexplore.ieee.org/document/16452/},
volume = {36},
year = {1989}
}
@article{Sanchez-Lopez2017,
abstract = {To achieve fully autonomous operation for Unmanned Aerial Systems (UAS) it is necessary to integrate multiple and heterogeneous technical solutions (e.g., control-based methods, computer vision methods, automated planning, coordination algorithms, etc.). The combination of such methods in an operational system is a technical challenge that requires efficient architectural solutions. In a robotic engineering context, where productivity is important, it is also important to minimize the effort for the development of new systems. As a response to these needs, this paper presents Aerostack, an open-source software framework for the development of aerial robotic systems. This framework facilitates the creation of UAS by providing a set of reusable components specialized in functional tasks of aerial robotics (trajectory planning, self localization, etc.) together with an integration method in a multi-layered cognitive architecture based on five layers: reactive, executive, deliberative, reflective and social. Compared to other software frameworks for UAS, Aerostack can provide higher degrees of autonomy and it is more versatile to be applied to different types of hardware (aerial platforms and sensors) and different types of missions (e.g. multi robot swarm systems). Aerostack has been validated during four years (since February 2013) by its successful use on many research projects, international competitions and public exhibitions. As a representative example of system development, this paper also presents how Aerostack was used to develop a system for a (fictional) fully autonomous indoors search and rescue mission.},
author = {Sanchez-Lopez, Jose Luis and Molina, Martin and Bavle, Hriday and Sampedro, Carlos and {Su{\'{a}}rez Fern{\'{a}}ndez}, Ram{\'{o}}n A and Campoy, Pascual},
doi = {10.1007/s10846-017-0551-4},
issn = {1573-0409},
journal = {Journal of Intelligent {\&} Robotic Systems},
number = {2},
pages = {683--709},
title = {{A Multi-Layered Component-Based Approach for the Development of Aerial Robotic Systems: The Aerostack Framework}},
url = {https://doi.org/10.1007/s10846-017-0551-4},
volume = {88},
year = {2017}
}
@incollection{Azuma2017,
author = {Azuma, Godai and Kitakoshi, Daisuke and Suzuki, Masato},
doi = {10.1007/978-981-10-4154-9_62},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Azuma, Kitakoshi, Suzuki - 2017 - Stepwise Structure Learning Using Probabilistic Pruning for Bayesian Networks Improving Efficiency and.pdf:pdf},
month = {mar},
pages = {533--543},
publisher = {Springer, Singapore},
title = {{Stepwise Structure Learning Using Probabilistic Pruning for Bayesian Networks: Improving Efficiency and Comparing Characteristics}},
url = {http://link.springer.com/10.1007/978-981-10-4154-9{\_}62},
year = {2017}
}
@article{kasai2018end,
author = {Kasai, Jungo and Frank, Robert and Xu, Pauli and Merrill, William and Rambow, Owen},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kasai et al. - 2018 - End-to-end Graph-based TAG Parsing with Neural Networks.pdf:pdf},
journal = {arXiv preprint arXiv:1804.06610},
title = {{End-to-end Graph-based TAG Parsing with Neural Networks}},
year = {2018}
}
@inproceedings{10.1007/978-3-642-15754-7_21,
abstract = {This paper describes the first round of ResPubliQA, a Question Answering (QA) evaluation task over European legislation, proposed at the Cross Language Evaluation Forum (CLEF) 2009. The exercise consists of extracting a relevant paragraph of text that satisfies completely the information need expressed by a natural language question. The general goals of this exercise are (i) to study if the current QA technologies tuned for newswire collections and Wikipedia can be adapted to a new domain (law in this case); (ii) to move to a more realistic scenario, considering people close to law as users, and paragraphs as system output; (iii) to compare current QA technologies with pure Information Retrieval (IR) approaches; and (iv) to introduce in QA systems the Answer Validation technologies developed in the past three years. The paper describes the task in more detail, presenting the different types of questions, the methodology for the creation of the test sets and the new evaluation measure, and analyzing the results obtained by systems and the more successful approaches. Eleven groups participated with 28 runs. In addition, we evaluated 16 baseline runs (2 per language) based only in pure IR approach, for comparison purposes. Considering accuracy, scores were generally higher than in previous QA campaigns.},
address = {Berlin, Heidelberg},
author = {Pe{\~{n}}as, Anselmo and Forner, Pamela and Sutcliffe, Richard and Rodrigo, {\'{A}}lvaro and For$\backslash$uascu, Corina and Alegria, I{\~{n}}aki and Giampiccolo, Danilo and Moreau, Nicolas and Osenova, Petya},
booktitle = {Multilingual Information Access Evaluation I. Text Retrieval Experiments},
editor = {Peters, Carol and {Di Nunzio}, Giorgio Maria and Kurimo, Mikko and Mandl, Thomas and Mostefa, Djamel and Pe{\~{n}}as, Anselmo and Roda, Giovanna},
isbn = {978-3-642-15754-7},
pages = {174--196},
publisher = {Springer Berlin Heidelberg},
title = {{Overview of ResPubliQA 2009: Question Answering Evaluation over European Legislation}},
year = {2010}
}
@inproceedings{voorhees2004overview,
author = {Voorhees, Ellen M and Harman, Donna},
booktitle = {TREC},
title = {{Overview of TREC 2004.}},
year = {2004}
}
@article{Montemerlo2002,
author = {Montemerlo, Michael and Montemerlo, Michael and Thrun, Sebastian and Koller, Daphne and Wegbreit, Ben},
journal = {IN PROCEEDINGS OF THE AAAI NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE},
pages = {593----598},
title = {{FastSLAM: A Factored Solution to the Simultaneous Localization and Mapping Problem}},
url = {http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.16.2153},
year = {2002}
}
@inproceedings{W16-1403,
author = {{Pouran Ben Veyseh}, Amir},
booktitle = {Proceedings of TextGraphs-10: the Workshop on Graph-based Methods for Natural Language Processing},
doi = {10.18653/v1/W16-1403},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pouran Ben Veyseh - 2016 - Cross-Lingual Question Answering Using Common Semantic Space.pdf:pdf},
pages = {15--19},
publisher = {Association for Computational Linguistics},
title = {{Cross-Lingual Question Answering Using Common Semantic Space}},
url = {http://www.aclweb.org/anthology/W16-1403},
year = {2016}
}
@article{Krizhevsky2012,
abstract = {We present a fast, fully parameterizable GPU implementation of Convolutional Neural Network variants. Our feature extractors are neither carefully designed nor pre-wired, but rather learned in a supervised way. Our deep hierarchical architectures achieve the best published results on benchmarks for object classification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with error rates of 2.53{\%}, 19.51{\%}, 0.35{\%}, respectively. Deep nets trained by simple back-propagation perform better than more shallow ones. Learning is surprisingly rapid. NORB is completely trained within five epochs. Test error rates on MNIST drop to 2.42{\%}, 0.97{\%} and 0.48{\%} after 1, 3 and 17 epochs, respectively.},
archivePrefix = {arXiv},
arxivId = {1102.0183},
author = {Cireşan, Dan C. and Meier, Ueli and Masci, Jonathan and Gambardella, Luca M. and Schmidhuber, J{\"{u}}rgen},
doi = {http://dx.doi.org/10.1016/j.protcy.2014.09.007},
eprint = {1102.0183},
isbn = {9781627480031},
issn = {10495258},
journal = {Advances In Neural Information Processing Systems},
month = {feb},
pages = {1--9},
pmid = {7491034},
title = {{High-Performance Neural Networks for Visual Object Classification}},
url = {http://arxiv.org/abs/1102.0183},
year = {2011}
}
@inproceedings{Harris88acombined,
author = {Harris, Chris and Stephens, Mike},
booktitle = {In Proc. of Fourth Alvey Vision Conference},
pages = {147--151},
title = {{A combined corner and edge detector}},
year = {1988}
}
@article{Da,
abstract = {Swarm Intelligence is the emergent collective intelligence of groups of simple agents acting almost independently. Algorithms follow-ing this paradigm have many desirable properties: flexibility, decentral-ized control, robustness, and fault tolerance. This paper presents a novel agent coordination model inspired by the way ants collectively transport large preys. In our model a swarm of agents, each having a different destination to reach, moves with no centralized control in the direction indicated by the majority of agents keeping its initial shape. The model is used to build an algorithm for the problems of image alignment and image matching. The novelty of the approach and its effectiveness are discussed.},
author = {Da, G and Martino, San and Cardillo, F A and Starita, A},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Da et al. - Unknown - A New Swarm Intelligence Coordination Model Inspired by Collective Prey Retrieval and Its Application to Image Ali.pdf:pdf},
title = {{A New Swarm Intelligence Coordination Model Inspired by Collective Prey Retrieval and Its Application to Image Alignment}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132253/mod{\_}label/intro/{\%}23 application to image alignment {\%}28San Martino et al{\%}2C 06{\%}29.pdf}
}
@article{Qin2018,
abstract = {Distant supervision can effectively label data for relation extraction, but suffers from the noise labeling problem. Recent works mainly perform soft bag-level noise reduction strategies to find the relatively better samples in a sentence bag, which is suboptimal compared with making a hard decision of false positive samples in sentence level. In this paper, we introduce an adversarial learning framework, which we named DSGAN, to learn a sentence-level true-positive generator. Inspired by Generative Adversarial Networks, we regard the positive samples generated by the generator as the negative samples to train the discriminator. The optimal generator is obtained until the discrimination ability of the discriminator has the greatest decline. We adopt the generator to filter distant supervision training dataset and redistribute the false positive instances into the negative set, in which way to provide a cleaned dataset for relation classification. The experimental results show that the proposed strategy significantly improves the performance of distant supervision relation extraction comparing to state-of-the-art systems.},
archivePrefix = {arXiv},
arxivId = {1805.09929},
author = {Qin, Pengda and Xu, Weiran and Wang, William Yang},
eprint = {1805.09929},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Qin, Xu, Wang - 2018 - DSGAN Generative Adversarial Training for Distant Supervision Relation Extraction.pdf:pdf},
month = {may},
title = {{DSGAN: Generative Adversarial Training for Distant Supervision Relation Extraction}},
url = {http://arxiv.org/abs/1805.09929},
year = {2018}
}
@article{Kocisky2017,
abstract = {Reading comprehension (RC)---in contrast to information retrieval---requires integrating information and reasoning about events, entities, and their relations across a full document. Question answering is conventionally used to assess RC ability, in both artificial agents and children learning to read. However, existing RC datasets and tasks are dominated by questions that can be solved by selecting answers using superficial information (e.g., local context similarity or global term frequency); they thus fail to test for the essential integrative aspect of RC. To encourage progress on deeper comprehension of language, we present a new dataset and set of tasks in which the reader must answer questions about stories by reading entire books or movie scripts. These tasks are designed so that successfully answering their questions requires understanding the underlying narrative rather than relying on shallow pattern matching or salience. We show that although humans solve the tasks easily, standard RC models struggle on the tasks presented here. We provide an analysis of the dataset and the challenges it presents.},
archivePrefix = {arXiv},
arxivId = {1712.07040},
author = {Ko{\v{c}}isk{\'{y}}, Tom{\'{a}}{\v{s}} and Schwarz, Jonathan and Blunsom, Phil and Dyer, Chris and Hermann, Karl Moritz and Melis, G{\'{a}}bor and Grefenstette, Edward},
eprint = {1712.07040},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ko{\v{c}}isk{\'{y}} et al. - 2017 - The NarrativeQA Reading Comprehension Challenge.pdf:pdf},
month = {dec},
title = {{The NarrativeQA Reading Comprehension Challenge}},
url = {http://arxiv.org/abs/1712.07040},
year = {2017}
}
@article{lehmann2014DBPedia,
author = {Lehmann, Jens and Isele, Robert and Jakob, Max and Jentzsch, Anja and Kontokostas, Dimitris and Mendes, Pablo and Hellmann, Sebastian and Morsey, Mohamed and {Van Kleef}, Patrick and Auer, S{\"{o}}ren and Bizer, Christian},
doi = {10.3233/SW-140134},
journal = {Semantic Web Journal},
title = {{DBpedia - A Large-scale, Multilingual Knowledge Base Extracted from Wikipedia}},
volume = {6},
year = {2014}
}
@inproceedings{tjong2003introduction,
abstract = {We describe the CoNLL-2003 shared task: language-independent named entity recognition. We give background information on the data sets (English and German) and the evaluation method, present a general overview of the systems that have taken part in the task and discuss their performance.},
archivePrefix = {arXiv},
arxivId = {cs/0306050},
author = {Sang, Erik F. Tjong Kim and {De Meulder}, Fien},
booktitle = {Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003-Volume 4},
doi = {10.3115/1119176.1119195},
eprint = {0306050},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sang, De Meulder - 2003 - Introduction to the CoNLL-2003 Shared Task Language-Independent Named Entity Recognition(2).pdf:pdf},
organization = {Association for Computational Linguistics},
pages = {142--147},
primaryClass = {cs},
title = {{Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition}},
url = {http://arxiv.org/abs/cs/0306050},
year = {2003}
}
@article{Baker,
abstract = {1 Abstract This paper analyzes the circumstances under which Bayesian networks can be pruned in or­ der to reduce computational complexity with­ out altering the computation for variables of interest. Given a problem instance which con­ sists of a query .and evidence for a set of nones in the network, it is possible to deiete portions of the network which do not participate in the computation for the query. Savings in com­ putational complexity can be large when the original network is not singly connected. Results analogous to those described in this paper have been derived before [Geiger, Verma, and Pearl 89, Shachter 88] but the im­ plications for reducing complexity of the com­ putations in Bayesian networks have not been stated explicitly. We show how a preprocess­ ing step can be used to prune a Bayesian net­ work prior to using standard algorithms to solve a given problem instance. We also show how our results can be used in a parallel distributed implementation in order to achieve greater savings. We define a minimal com­ putationally equivalent subgraph of a Bayesian network. The algorithm developed in [Geiger, Verma, and Pearl 89] is modified to construct the subgraphs described in this paper with O(e) complexity, where e is the number of edges in the Bayesian network. Finally, we define a minimal computationally equivalent subgraph and prove that the sub­ graphs described are minimal.},
author = {Baker, Michelle and Boult, Terrance E},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baker, Boult - Unknown - Pruning Bayesian Networks for Efficient Computation.pdf:pdf},
title = {{Pruning Bayesian Networks for Efficient Computation}},
url = {https://arxiv.org/pdf/1304.1112.pdf}
}
@book{robust-technique-matching-two-uncalibrated-images-recovery-unknown-epipolar-geometry,
abstract = {This paper proposes a robust approach to image matching by exploiting the only available geometric constraint, namely, the epipolar constraint. The images are uncalibrated, namely the motion between them and the camera parameters are not known. Thus, the images can be taken by different cameras or a single camera at different time instants. If we make an exhaustive search for the epipolar geometry, the complexity is prohibitively high. The idea underlying our approach is to use classical techniques (correlation and relaxation methods in our particular implementation) to find an initial set of matches, and then use a robust technique—the Least Median of Squares (LMedS)—to discard false matches in this set. The epipolar geometry can then be accurately estimated using a meaningful image criterion. More matches are eventually found, as in stereo matching, by using the recovered epipolar geometry. A large number of experiments have been carried out, and very good results have been obtained.

Regarding the relaxation technique, we define a new measure of matching support, which allows a higher tolerance to deformation with respect to rigid transformations in the image plane and a smaller contribution for distant matches than for nearby ones. A new strategy for updating matches is developed, which only selects those matches having both high matching support and low matching ambiguity. The update strategy is different from the classical “winner-take-all”, which is easily stuck at a local minimum, and also from “loser-take-nothing”, which is usually very slow. The proposed algorithm has been widely tested and works remarkably well in a scene with many repetitive patterns.},
author = {Zhang, Zhengyou and Deriche, Rachid and Faugeras, Olivier and Luong, Quang-Tuan},
booktitle = {Artificial Intelligence},
pages = {87--119},
publisher = {Elsevier},
title = {{A Robust Technique for Matching Two Uncalibrated Images Through the Recovery of the Unknown Epipolar Geometry}},
url = {https://www.microsoft.com/en-us/research/publication/robust-technique-matching-two-uncalibrated-images-recovery-unknown-epipolar-geometry/},
volume = {78},
year = {1995}
}
@article{Rajpurkar2018,
abstract = {Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuAD 2.0, the latest version of the Stanford Question Answering Dataset (SQuAD). SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD 2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuAD 2.0 is a challenging natural language understanding task for existing models: a strong neural system that gets 86{\%} F1 on SQuAD 1.1 achieves only 66{\%} F1 on SQuAD 2.0.},
archivePrefix = {arXiv},
arxivId = {1806.03822},
author = {Rajpurkar, Pranav and Jia, Robin and Liang, Percy},
eprint = {1806.03822},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rajpurkar, Jia, Liang - 2018 - Know What You Don't Know Unanswerable Questions for SQuAD.pdf:pdf},
month = {jun},
title = {{Know What You Don't Know: Unanswerable Questions for SQuAD}},
url = {http://arxiv.org/abs/1806.03822},
year = {2018}
}
@article{probabilistic_rmaps,
author = {Kavraki, L E and Svestka, P and Latombe, J C and Overmars, M H},
doi = {10.1109/70.508439},
issn = {1042-296X},
journal = {IEEE Transactions on Robotics and Automation},
keywords = {graph theory,learning (artificial intelligence),mo},
number = {4},
pages = {566--580},
title = {{Probabilistic roadmaps for path planning in high-dimensional configuration spaces}},
volume = {12},
year = {1996}
}
@article{doi:10.1080/0020716022000005546,
author = {Barrios, Dolores and Carrascal, Alberto and Manrique, Daniel and R{\'{I}}OS, Juan},
doi = {10.1080/0020716022000005546},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barrios et al. - 2003 - Optimisation With Real-Coded Genetic Algorithms Based On Mathematical Morphology.pdf:pdf},
journal = {International Journal of Computer Mathematics},
number = {3},
pages = {275--293},
publisher = {Taylor {\&} Francis},
title = {{Optimisation With Real-Coded Genetic Algorithms Based On Mathematical Morphology}},
url = {http://dx.doi.org/10.1080/0020716022000005546},
volume = {80},
year = {2003}
}
@article{Rubenstein2014,
author = {Rubenstein, Michael and Cornejo, Alejandro and Nagpal, Radhika},
doi = {10.1126/science.1254295},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rubenstein, Cornejo, Nagpal - 2014 - Programmable self-assembly in a thousand-robot swarm.pdf:pdf},
journal = {Science},
number = {795},
title = {{Programmable self-assembly in a thousand-robot swarm}},
url = {www.sciencemag.org/content/345/6198/795/suppl/DC1},
volume = {345},
year = {2014}
}
@article{y1997b,
author = {Y., Freund and Schapire, R E},
doi = {doi},
journal = {Journal of Computer and System Sciences},
number = {1},
pages = {119--139},
title = {{A decision-theoretic generalization of on-line learning and an application to boosting}},
volume = {55},
year = {1997}
}
@article{Yang2018,
archivePrefix = {arXiv},
arxivId = {1806.04470},
author = {Yang, Jie and Liang, Shuailong and Zhang, Yue},
eprint = {1806.04470},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Liang, Zhang - 2018 - Design Challenges and Misconceptions in Neural Sequence Labeling.pdf:pdf},
month = {jun},
title = {{Design Challenges and Misconceptions in Neural Sequence Labeling}},
url = {https://arxiv.org/abs/1806.04470},
year = {2018}
}
@article{Sorokin2018,
archivePrefix = {arXiv},
arxivId = {1808.04126},
author = {Sorokin, Daniil and Gurevych, Iryna},
eprint = {1808.04126},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sorokin, Gurevych - 2018 - Modeling Semantics with Gated Graph Neural Networks for Knowledge Base Question Answering.pdf:pdf},
month = {aug},
title = {{Modeling Semantics with Gated Graph Neural Networks for Knowledge Base Question Answering}},
url = {https://arxiv.org/abs/1808.04126},
year = {2018}
}
@article{Beretta2017,
abstract = {One of the most challenging tasks when adopting Bayesian Networks (BNs) is the one of learning their structure from data. This task is complicated by the huge search space of possible solutions and turned out to be a well-known N P -hard problem and, hence, approximations are required. However, to the best of our knowledge, a quantitative analysis of the performance and characteristics of the different heuristics to solve this problem has never been done before. For this reason, in this work, we provide a detailed study of the different state-of-the-arts methods for structural learning on simulated data consid-ering both BNs with discrete and continuous variables, and with different rates of noise in the data. In particular, we investigate the characteristics of different widespread scores proposed for the inference and the statistical pitfalls within them.},
archivePrefix = {arXiv},
arxivId = {arXiv:1704.08676v1},
author = {Beretta, Stefano and Castelli, Mauro and Gon{\c{c}}alves, Ivo and Ramazzotti, Daniele},
eprint = {arXiv:1704.08676v1},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beretta et al. - 2017 - A quantitative assessment of the effect of different algorithmic schemes to the task of learning the structure o.pdf:pdf},
keywords = {Bayesian Networks,Evolutionary Computation,Genetic Algorithms,Heuristic Search,Structure Learning},
title = {{A quantitative assessment of the effect of different algorithmic schemes to the task of learning the structure of Bayesian Networks}},
url = {https://arxiv.org/pdf/1704.08676.pdf},
year = {2017}
}
@article{breiman1996a,
author = {Breiman, L},
journal = {[Web of Science {\textregistered}]},
number = {2},
pages = {123--140},
title = {{Bagging predictors}},
volume = {24},
year = {1996}
}
@incollection{Bay2006,
author = {Bay, Herbert and Tuytelaars, Tinne and {Van Gool}, Luc},
doi = {10.1007/11744023_32},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bay, Tuytelaars, Van Gool - 2006 - SURF Speeded Up Robust Features.pdf:pdf},
pages = {404--417},
publisher = {Springer, Berlin, Heidelberg},
title = {{SURF: Speeded Up Robust Features}},
url = {http://link.springer.com/10.1007/11744023{\_}32},
year = {2006}
}
@article{Heckerman1995,
author = {Heckerman, David and Geiger, Dan and Chickering, David M.},
doi = {10.1007/BF00994016},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Heckerman, Geiger, Chickering - 1995 - Learning Bayesian networks The combination of knowledge and statistical data.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
month = {sep},
number = {3},
pages = {197--243},
publisher = {Kluwer Academic Publishers},
title = {{Learning Bayesian networks: The combination of knowledge and statistical data}},
url = {http://link.springer.com/10.1007/BF00994016},
volume = {20},
year = {1995}
}
@misc{H.Hexmoor1993,
author = {{H. Hexmoor}, Henry and {M. Lammens}, Johan and {C. Shapiro}, Stuart},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/H. Hexmoor, M. Lammens, C. Shapiro - 1993 - An autonomous agent architecture for integrating unconscious and conscious reasoned behavior.pdf:pdf},
pages = {9},
title = {{An autonomous agent architecture for integrating unconscious and conscious reasoned behaviors}},
year = {1993}
}
@article{gromping2009,
abstract = {Relative importance of regressor variables is an old topic that still awaits a satisfactory solution. When interest is in attributing importance in linear regression, averaging over orderings methods for decomposing R2 are among the state-of-the-art methods, although the mechanism behind their behavior is not (yet) completely understood. Random forests—a machine-learning tool for classification and regression proposed a few years ago—have an inherent procedure of producing variable importances. This article compares the two approaches (linear model on the one hand and two versions of random forests on the other hand) and finds both striking similarities and differences, some of which can be explained whereas others remain a challenge. The investigation improves understanding of the nature of variable importance in random forests. This article has supplementary material online.},
author = {Gr{\"{o}}mping, Ulrike},
doi = {10.1198/tast.2009.08199},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gr{\"{o}}mping - 2009 - Variable Importance Assessment in Regression Linear Regression versus Random Forest.pdf:pdf},
issn = {0003-1305},
journal = {The American Statistician},
keywords = {Linear model,Random forest,Variable importance},
month = {nov},
number = {4},
pages = {308--319},
publisher = {Taylor {\&} Francis},
title = {{Variable Importance Assessment in Regression: Linear Regression versus Random Forest}},
url = {http://www.tandfonline.com/doi/abs/10.1198/tast.2009.08199},
volume = {63},
year = {2009}
}
@article{Campos2011,
author = {de Campos, Cassio P. and Ji, Qiang},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Campos, Ji - 2011 - Efficient Structure Learning of Bayesian Networks using Constraints.pdf:pdf},
issn = {ISSN 1533-7928},
journal = {Journal of Machine Learning Research},
number = {Mar},
pages = {663--689},
title = {{Efficient Structure Learning of Bayesian Networks using Constraints}},
url = {http://www.jmlr.org/papers/v12/decampos11a.html},
volume = {12},
year = {2011}
}
@article{Barsalou2005,
abstract = {After reviewing six senses of abstraction, this article focuses on abstractions that take the form of summary representations. Three central properties of these abstractions are established: ( i ) type-token interpretation; (ii) structured representation; and (iii) dynamic realization. Traditional theories of representation handle interpretation and structure well but are not sufficiently dynamical. Conversely, connectionist theories are exquisitely dynamic but have problems with structure. Perceptual symbol systems offer an approach that implements all three properties naturally. Within this framework, a loose collection of property and relation simulators develops to represent abstractions. Type-token interpretation results from binding a property simulator to a region of a perceived or simulated category member. Structured representation results from binding a configuration of property and relation simulators to multiple regions in an integrated manner. Dynamic realization results from applying different subsets of property and relation simulators to category members on different occasions. From this standpoint, there are no permanent or complete abstractions of a category in memory. Instead, abstraction is the skill to construct temporary online interpretations of a category's members. Although an infinite number of abstractions are possible, attractors develop for habitual approaches to interpretation. This approach provides new ways of thinking about abstraction phenomena in categorization, inference, background knowledge and learning.},
author = {Barsalou, Lawrence W.},
doi = {10.4324/9781410612908},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barsalou - 2005 - Abstraction as dynamic interpretation in perceptual symbol systems.pdf:pdf},
isbn = {1410612902},
issn = {0962-8436},
journal = {Building Object Categories in Developmental Time},
keywords = {abstraction,concept,dynamic,embodiment,interpretation,simulation},
number = {May},
pages = {389--431},
pmid = {12903648},
title = {{Abstraction as dynamic interpretation in perceptual symbol systems}},
year = {2005}
}
@inproceedings{Hoffart2012,
address = {New York, New York, USA},
author = {Hoffart, Johannes and Seufert, Stephan and Nguyen, Dat Ba and Theobald, Martin and Weikum, Gerhard},
booktitle = {Proceedings of the 21st ACM international conference on Information and knowledge management - CIKM '12},
doi = {10.1145/2396761.2396832},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoffart et al. - 2012 - KORE.pdf:pdf},
isbn = {9781450311564},
pages = {545},
publisher = {ACM Press},
title = {{KORE}},
url = {http://dl.acm.org/citation.cfm?doid=2396761.2396832},
year = {2012}
}
@article{pal2005,
author = {Pal, M.},
doi = {10.1080/01431160412331269698},
issn = {0143-1161},
journal = {International Journal of Remote Sensing},
month = {jan},
number = {1},
pages = {217--222},
title = {{Random forest classifier for remote sensing classification}},
url = {http://www.tandfonline.com/doi/abs/10.1080/01431160412331269698},
volume = {26},
year = {2005}
}
@article{AraujodosSantos,
abstract = {In depth study in Machine Learning and Artificial Inteligence},
author = {{Araujo dos Santos}, Leonardo},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Araujo dos Santos - Unknown - Artificial Intelligence and Deep Learning.pdf:pdf},
keywords = {AI,ML},
mendeley-tags = {AI,ML},
title = {{Artificial Intelligence and Deep Learning}},
url = {https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/}
}
@article{Komendera2011,
abstract = {—We propose a novel class of algorithms for au-tonomously assembling structures from inert building blocks guided by intelligent scaffolding components. Intelligent scaffold units are equipped with sensing, actuation, computation and communication abilities and facilitate the attachment of inert building blocks to the structure. After attaching an inert building block, the scaffold structure reconfigures to attach the next block until the structure is completed. The proposed algorithms are scale-free and independent of the implementation of the locomotion of building blocks and intelligent scaffolding blocks. For example, movement of building and scaffold blocks can be achieved using manipulating robots or self-assembly in a well-stirred liquid. In a robotic assembly context, the intelligent scaffolds take the role of markers on the structure and allow for reducing the perception and coordination requirements on the robotic team. In this paper, we describe algorithms for converting any desired structure that can be represented as 3D lattice into a finite state machine that is executed by intelligent scaffolding blocks; we prove that all finite structures can be assembled using intelligent scaffolds; and we provide examples of simulations that assemble a square, a fractal structure, and a model of a space station, each using only three intelligent scaffold components.},
author = {Komendera, Erik and Reishus, Dustin and Correll, Nikolaus},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Komendera, Reishus, Correll - 2011 - Assembly by Intelligent Scaffolding.pdf:pdf},
title = {{Assembly by Intelligent Scaffolding}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132229/mod{\_}label/intro/Komendera11.pdf},
year = {2011}
}
@article{Deb2002,
author = {Deb, K. and Pratap, A. and Agarwal, S. and Meyarivan, T.},
doi = {10.1109/4235.996017},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Deb et al. - 2002 - A fast and elitist multiobjective genetic algorithm NSGA-II.pdf:pdf},
issn = {1089778X},
journal = {IEEE Transactions on Evolutionary Computation},
month = {apr},
number = {2},
pages = {182--197},
title = {{A fast and elitist multiobjective genetic algorithm: NSGA-II}},
url = {http://ieeexplore.ieee.org/document/996017/},
volume = {6},
year = {2002}
}
@article{Zhang2017,
abstract = {Ensemble learning has attracted significant interest in the literature of variable selection due to its great potential to reduce false discovery rate and to stabilize selection results. In this paper, a novel ensemble pruning technique called PST2E (i.e., pruned ST2E) is introduced to obtain smaller but stronger variable selection ensembles. For the ensemble members generated by the ST2E algorithm [3], we sort them in descending order according to the prediction errors associated with their determined models. Subsequently, only a desired number of members ranked ahead are integrated to compose a subensemble. On the basis of the average importance measures produced by the pruned ensemble, all candidate variables are then ranked and decided to be important or not. In the context of linear and logistic regression models, the experiments conducted with both simulated and real-world data illustrate that PST2E significantly outperforms several other popular techniques in most cases when evaluating them with multiple measures. Another advantage of PST2E is that it admits easy implementation. As a result, PST2E can be deemed as an attractive alternative to tackle variable selection tasks in real applications.},
author = {Zhang, Chun-Xia and Zhang, Jiang-She and Yin, Qing-Yan},
doi = {10.1016/J.KNOSYS.2017.03.031},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang, Zhang, Yin - 2017 - A ranking-based strategy to prune variable selection ensembles.pdf:pdf},
issn = {0950-7051},
journal = {Knowledge-Based Systems},
month = {jun},
pages = {13--25},
publisher = {Elsevier},
title = {{A ranking-based strategy to prune variable selection ensembles}},
url = {http://www.sciencedirect.com/science/article/pii/S0950705117301521?via{\%}3Dihub},
volume = {125},
year = {2017}
}
@article{Lowe2004a,
author = {Lowe, David G.},
doi = {10.1023/B:VISI.0000029664.99615.94},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lowe - 2004 - Distinctive Image Features from Scale-Invariant Keypoints.pdf:pdf},
issn = {0920-5691},
journal = {International Journal of Computer Vision},
month = {nov},
number = {2},
pages = {91--110},
publisher = {Kluwer Academic Publishers},
title = {{Distinctive Image Features from Scale-Invariant Keypoints}},
url = {http://link.springer.com/10.1023/B:VISI.0000029664.99615.94},
volume = {60},
year = {2004}
}
@article{Zahadat,
abstract = {Adaptive Behavior XX(X):1–?? c [The Author(s) 2015 Reprints and permission: sagepub.co.uk/journalsPermissions.nav Abstract In this paper, a distributed algorithm for adaptive task allocation and adaptable partitioning of a swarm into different work-groups is proposed and used in a swarm of underwater robots. The algorithm is based on local interactions of agents and is inspired by honeybee age-polyethism. It is adaptive to changes in the swarm size (workforce) and relative demands (workload) for different tasks and it limits the number of switchings of agents between different tasks enabling specialization of agents. The preliminary version of the algorithm was introduced in the past. Here a fully decentralized version of the algorithm is proposed that improves the previous version by removing the need to global information. The algorithm is successfully implemented in swarms of physically-embodied underwater robots while the swarm size and the demands for the tasks change over the course of the experiments.},
author = {Zahadat, Payam and Schmickl, Thomas},
doi = {10.1177/ToBeAssigned},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zahadat, Schmickl - Unknown - Division of Labor in a Swarm of Autonomous Underwater Robots by Improved Partitioning Social Inhibition.pdf:pdf},
keywords = {adaptive division of labor,bio-inspired algorithm,distributed partitioning,social inhibition,swarm intelligence,swarm robotics},
title = {{Division of Labor in a Swarm of Autonomous Underwater Robots by Improved Partitioning Social Inhibition}},
url = {www.sagepub.com/}
}
@article{Liaw,
abstract = {The pickup and delivery problem (PDP) is relevant to many real-world problems, e.g., logistic and transportation problems. The problem is to find the shortest route to gain commodities from the pickup nodes and supply them to the delivery nodes. The amount of commodities of pickup nodes and delivery nodes is usually assumed to be in equilibrium; thus, all pickup nodes have to be visited for collecting all commodities required. However, some real-world applications, such as rental bikes and wholesaling business, need only to gain sufficient commodities from certain pickup nodes. A variant of PDP, namely the selective pickup and delivery problem (SPDP), is formulated to address the above scenarios. The major difference of SPDP from PDP lies in the requirement of visiting all pickup nodes. The SPDP relaxes this require-ment to achieve more efficient transportation. The goal of the SPDP is to seek the shortest path that satisfies the load constraint to sup-ply the commodities demanded by all delivery nodes with some pickup nodes. This study proposes a max-min ant system (MMAS) to solve the SPDP. The ants aim to construct the shortest route for the SPDP con-sidering the number of selected pickup nodes and all delivery nodes. This study conducts experiments to examine the performance of the proposed MMAS, in comparison with genetic algorithm and memetic algorithm. The experimental results validate the effectiveness and efficiency of the proposed MMAS in route length and convergence speed for the SPDP.},
author = {Liaw, Rung-Tzuo and Chang, Yu-Wei and Ting, Chuan-Kang},
doi = {10.1007/978-3-319-61824-1},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Liaw, Chang, Ting - Unknown - Solving the Selective Pickup and Delivery Problem Using Max-Min Ant System.pdf:pdf},
title = {{Solving the Selective Pickup and Delivery Problem Using Max-Min Ant System}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1327619/mod{\_}label/intro/liaw-selectivePickupDelivery-mmas-2017.pdf}
}
@incollection{and1995a,
author = {{J. Kennedy}, R.C.Eberhart},
booktitle = {Proc. 6th International Symposium on Micro Machine and Human Science},
pages = {39--43},
title = {{A new optimizer using particle swarm theory}}
}
@inproceedings{berant2013semantic,
author = {Berant, Jonathan and Chou, Andrew and Frostig, Roy and Liang, Percy},
booktitle = {Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing},
pages = {1533--1544},
title = {{Semantic parsing on freebase from question-answer pairs}},
year = {2013}
}
@article{Santos,
abstract = {Gameplay in real-time strategy games seems somehow to be confined to a de facto standard where economical micro-management is equally important as combat strategy, if not more important. To enable stronger combat-oriented game-play without sacrificing other key aspects of the genre, we propose an automated system for scheduling unit train-ing, which we believe may allow the exploration of new paradigms of play. To be accepted by the player, such a sys-tem must, among other things, be efficient and reliable, which is a non-trivial task considering the highly dynamic nature of the environment in this genre of games. To overcome such a challenge, we propose a system inspired in the swarm in-telligence demonstrated by social insects, namely wasps, and describe its limitations and benefits, based on the evaluation of an implementation of the approach as a mod(ification) of the game Warcraft III The Frozen Throne.},
author = {Santos, Marco and Martinho, Carlos},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Santos, Martinho - Unknown - Wasp-Like Scheduling for Unit Training in Real-Time Strategy Games.pdf:pdf},
keywords = {Poster Papers},
title = {{Wasp-Like Scheduling for Unit Training in Real-Time Strategy Games}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132216/mod{\_}label/intro/santosMartinho-waspSchedulingWarcraft.pdf}
}
@article{Pugh,
abstract = {— Within the field of multi-robot systems, multi-robot search is one area which is currently receiving a lot of research attention. One major challenge within this area is to design effective algorithms that allow a team of robots to work together to find their targets. Recently, techniques have been adopted for multi-robot search from the Particle Swarm Optimization algorithm, which uses a virtual multi-agent search to find optima in a multi-dimensional function space. We present here a multi-search algorithm inspired by Particle Swarm Optimization. Additionally, we exploit this inspiration by modifying the Particle Swarm Optimization algorithm to mimic the multi-robot search process, thereby allowing us to model at an abstracted level the effects of changing aspects and parameters of the system such as number of robots and communication range.},
author = {Pugh, Jim and Martinoli, Alcherio},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pugh, Martinoli - Unknown - Inspiring and Modeling Multi-Robot Search with Particle Swarm Optimization.pdf:pdf},
title = {{Inspiring and Modeling Multi-Robot Search with Particle Swarm Optimization}},
url = {https://moodle.upm.es/titulaciones/oficiales/pluginfile.php/1132260/mod{\_}label/intro/pugh-pso-multiRobotExploration-2007.pdf}
}
@article{DeCampos2017,
abstract = {For decomposable score-based structure learning of Bayesian networks, existing approaches first compute a collection of candidate parent sets for each variable and then optimize over this collection by choosing one parent set for each variable without creating directed cycles while maximizing the total score. We target the task of constructing the collection of candidate parent sets when the score of choice is the Bayesian Information Criterion (BIC). We provide new non-trivial results that can be used to prune the search space of candidate parent sets of each node. We analyze how these new results relate to previous ideas in the literature both theoretically and empirically. We show in experiments with UCI data sets that gains can be significant. Since the new pruning rules are easy to implement and have low computational costs, they can be promptly integrated into all state-of-the-art methods for structure learning of Bayesian networks.},
archivePrefix = {arXiv},
arxivId = {arXiv:1707.06194v1},
author = {{De Campos}, Cassio P and Scanagatta, Mauro and Corani, Giorgio and Zaffalon, Marco},
eprint = {arXiv:1707.06194v1},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/De Campos et al. - 2017 - Entropy-based Pruning for Learning Bayesian Networks using BIC.pdf:pdf},
keywords = {BIC,Bayesian networks,Parent set pruning,Structure learning},
title = {{Entropy-based Pruning for Learning Bayesian Networks using BIC}},
url = {https://arxiv.org/pdf/1707.06194.pdf},
year = {2017}
}
@article{Ganea2017,
abstract = {We propose a novel deep learning model for joint document-level entity disambiguation, which leverages learned neural representations. Key components are entity embeddings, a neural attention mechanism over local context windows, and a differentiable joint inference stage for disambiguation. Our approach thereby combines benefits of deep learning with more traditional approaches such as graphical models and probabilistic mention-entity maps. Extensive experiments show that we are able to obtain competitive or state-of-the-art accuracy at moderate computational costs.},
archivePrefix = {arXiv},
arxivId = {1704.04920},
author = {Ganea, Octavian-Eugen and Hofmann, Thomas},
eprint = {1704.04920},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ganea, Hofmann - 2017 - Deep Joint Entity Disambiguation with Local Neural Attention.pdf:pdf},
month = {apr},
title = {{Deep Joint Entity Disambiguation with Local Neural Attention}},
url = {http://arxiv.org/abs/1704.04920},
year = {2017}
}
@article{Zhang2019,
abstract = {For machine reading comprehension, the capacity of effectively modeling the linguistic knowledge from the detail-riddled and lengthy passages and getting ride of the noises is essential to improve its performance. Traditional attentive models attend to all words without explicit constraint, which results in inaccurate concentration on some dispensable words. In this work, we propose using syntax to guide the text modeling of both passages and questions by incorporating explicit syntactic constraints into attention mechanism for better linguistically motivated word representations. To serve such a purpose, we propose a novel dual contextual architecture called syntax-guided network (SG-Net), which consists of a BERT context vector and a syntax-guided context vector, to provide more fine-grained representation. Extensive experiments on popular benchmarks including SQuAD 2.0 and RACE show that the proposed approach achieves a substantial and significant improvement over the fine-tuned BERT baseline.},
archivePrefix = {arXiv},
arxivId = {1908.05147},
author = {Zhang, Zhuosheng and Wu, Yuwei and Zhou, Junru and Duan, Sufeng and Zhao, Hai and Wang, Rui},
eprint = {1908.05147},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2019 - SG-Net Syntax-Guided Machine Reading Comprehension.pdf:pdf},
month = {aug},
title = {{SG-Net: Syntax-Guided Machine Reading Comprehension}},
url = {http://arxiv.org/abs/1908.05147},
year = {2019}
}
@article{Diefenbach2018a,
author = {Diefenbach, Dennis and Lopez, Vanessa and Singh, Kamal and Maret, Pierre},
doi = {10.1007/s10115-017-1100-y},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Diefenbach et al. - 2018 - Core techniques of question answering systems over knowledge bases a survey(2).pdf:pdf},
issn = {0219-1377},
journal = {Knowledge and Information Systems},
keywords = {Knowledge base,QALD,Question answering,Semantic Web,SimpleQuestions,Survey,WebQuestions},
month = {jun},
number = {3},
pages = {529--569},
publisher = {Springer-Verlag},
title = {{Core techniques of question answering systems over knowledge bases: a survey}},
url = {http://link.springer.com/10.1007/s10115-017-1100-y},
volume = {55},
year = {2018}
}
@article{Hassas2006,
abstract = {This paper discusses examples of socially inspired self-organisation approaches and their use to build socially-aware, self-organising computing systems. The paper presents different mechanisms originating from existing social systems, such as stigmergy from social insects behaviours, epidemic spreading, gos-siping, trust and reputation inspired by human social behaviours, as well as other approaches from social science related to business and economics. It also elaborates on issues related to social network dynamics, social network patterns, social networks analysis, and their relation to the process of self-organisation. The applicability of socially inspired approaches in the engineering of self-organising computing systems is then illustrated with applications concerning WWW, computer networks and business communities. Povzetek: Podani so primeri mehanizmov samoorganizacije.},
author = {Hassas, Salima and {Di Marzo-Serugendo}, Giovanna and Karageorgos, Anthony and Castelfranchi, Cristiano},
file = {:home/gb/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hassas et al. - 2006 - On Self-Organising Mechanisms from Social, Business and Economic Domains.pdf:pdf},
journal = {Informatica},
keywords = {business networks,networks,self-organisation,social functions,social learning},
pages = {63--71},
title = {{On Self-Organising Mechanisms from Social, Business and Economic Domains}},
url = {http://www710.univ-lyon1.fr/{~}hassas http://cui.unige.ch/{~}dimarzo/ http://inf-server.inf.uth.gr/{~}karageorgos/ http://www.istc.cnr.it/},
volume = {30},
year = {2006}
}
@article{Wang2018,
abstract = {Many analysis methods exist to extract graphs of functional connectivity from neuronal networks. Confidence in the results is limited because, (i) different methods give different results, (ii) parameter setting directly influences the final result, and (iii) systematic evaluation of the results is not always performed. Here, we introduce MULAN (MULtiple method ANalysis), which assumes an ensemble based approach combining multiple analysis methods and fuzzy logic to extract graphs with the most probable structure. In order to reduce the dependency on parameter settings, we determine the best set of parameters using a genetic algorithm on simulated datasets, whose temporal structure is similar to the experimental one. After a validation step, the selected set of parameters is used to analyze experimental data. The final step cross-validates experimental subsets of data and provides a direct estimate of the most likely graph and our confidence in the proposed connectivity. A systematic evaluation validates our strategy against empirical stereotactic electroencephalography (SEEG) and functional magnetic resonance imaging (fMRI) data.},
author = {Wang, Huifang E and Friston, Karl J and Enar, Christian G B and Woodman, Marmaduke M and Chauvel, Patrick and Jirsa, Viktor and Bernard, Christophe},
doi = {10.1016/j.neuroimage.2017.10.036},
journal = {NeuroImage},
pages = {167--184},
title = {{MULAN: Evaluation and ensemble statistical inference for functional connectivity}},
url = {https://ac.els-cdn.com/S1053811917308637/1-s2.0-S1053811917308637-main.pdf?{\_}tid=8c271ffc-0285-11e8-a3d8-00000aab0f6c{\&}acdnat=1516963504{\_}e4c7634990ffec253cad1beea225e2d2},
volume = {166},
year = {2018}
}
@article{Vidaurre2017,
abstract = {Brain activity is a dynamic combination of the responses to sensory inputs and its own spontaneous processing. Consequently, such brain activity is continuously changing whether or not one is focusing on an externally imposed task. Previously, we have introduced an analysis method that allows us, using Hidden Markov Models (HMM), to model task or rest brain activity as a dynamic sequence of distinct brain networks, overcoming many of the limitations posed by sliding window approaches. Here, we present an advance that enables the HMM to handle very large amounts of data, making possible the inference of very reproducible and interpretable dynamic brain networks in a range of different datasets, including task, rest, MEG and fMRI, with potentially thousands of subjects. We anticipate that the generation of large and publicly available datasets from initiatives such as the Human Connectome Project and UK Biobank, in combination with computational methods that can work at this scale, will bring a breakthrough in our understanding of brain function in both health and disease.},
author = {Vidaurre, Diego and Abeysuriya, Romesh and Becker, Robert and Quinn, Andrew J and Alfaro-Almagro, Fidel and Smith, Stephen M and Woolrich, Mark W},
doi = {10.1016/j.neuroimage.2017.06.077},
journal = {NeuroImage},
keywords = {Hidden Markov Models,MEG,Machine Learning,Resting State},
mendeley-tags = {Hidden Markov Models,MEG,Machine Learning,Resting State},
title = {{Discovering dynamic brain networks from big data in rest and task}},
url = {https://ac.els-cdn.com/S1053811917305487/1-s2.0-S1053811917305487-main.pdf?{\_}tid=aed16712-028d-11e8-bce2-00000aacb35d{\&}acdnat=1516966998{\_}cf024a25460b888adbbe083c93a125fd},
year = {2017}
}
@article{Farahibozorg2018,
abstract = {There is growing interest in the rich temporal and spectral properties of the functional connectome of the brain that are provided by Electro-and Magnetoencephalography (EEG/MEG). However, the problem of leakage be-tween brain sources that arises when reconstructing brain activity from EEG/MEG recordings outside the head makes it difficult to distinguish true connections from spurious connections, even when connections are based on measures that ignore zero-lag dependencies. In particular, standard anatomical parcellations for potential cortical sources tend to over-or under-sample the real spatial resolution of EEG/MEG. By using information from cross-talk functions (CTFs) that objectively describe leakage for a given sensor configuration and distributed source reconstruction method, we introduce methods for optimising the number of parcels while simultaneously mini-mising the leakage between them. More specifically, we compare two image segmentation algorithms: 1) a split-and-merge (SaM) algorithm based on standard anatomical parcellations and 2) a region growing (RG) algorithm based on all the brain vertices with no prior parcellation. Interestingly, when applied to minimum-norm re-constructions for EEG/MEG configurations from real data, both algorithms yielded approximately 70 parcels despite their different starting points, suggesting that this reflects the resolution limit of this particular sensor configuration and reconstruction method. Importantly, when compared against standard anatomical parcella-tions, resolution matrices of adaptive parcellations showed notably higher sensitivity and distinguishability of parcels. Furthermore, extensive simulations of realistic networks revealed significant improvements in network reconstruction accuracies, particularly in reducing false leakage-induced connections. Adaptive parcellations therefore allow a more accurate reconstruction of functional EEG/MEG connectomes.},
author = {Farahibozorg, Seyedeh-Rezvan and Henson, Richard N and Hauk, Olaf},
doi = {10.1016/j.neuroimage.2017.09.009},
journal = {NeuroImage},
keywords = {Adaptive parcellation,Connectomics,Cross-talk functions,Functional connectome,MEG,MEG/EEG,Machine Learning,Source reconstruction,Whole-brain connectivity},
mendeley-tags = {Connectomics,MEG,Machine Learning},
title = {{Adaptive cortical parcellations for source reconstructed EEG/MEG connectomes}},
url = {https://ac.els-cdn.com/S1053811917307474/1-s2.0-S1053811917307474-main.pdf?{\_}tid=902daad2-028d-11e8-8c31-00000aab0f6c{\&}acdnat=1516966947{\_}08b06ff4987011f2c49433cbf91b9dbc},
volume = {169},
year = {2018}
}
@article{Cabral2017,
abstract = {Over the last decade, we have observed a revolution in brain structural and functional Connectomics. On one hand, we have an ever-more detailed characterization of the brain's white matter structural connectome. On the other, we have a repertoire of consistent functional networks that form and dissipate over time during rest. Despite the evident spatial similarities between structural and functional connectivity, understanding how different time-evolving functional networks spontaneously emerge from a single structural network requires analyzing the problem from the perspective of complex network dynamics and dynamical system's theory. In that direction, bottom-up computational models are useful tools to test theoretical scenarios and depict the mechanisms at the genesis of resting-state activity. Here, we provide an overview of the different mechanistic scenarios proposed over the last decade via computational models. Importantly, we highlight the need of incorporating additional model constraints considering the properties observed at finer temporal scales with MEG and the dynamical properties of FC in order to refresh the list of candidate scenarios.},
author = {Cabral, Joana and Kringelbach, Morten L and Deco, Gustavo},
doi = {10.1016/j.neuroimage.2017.03.045},
journal = {NeuroImage},
keywords = {Dynamic FC,Envelope FC,Network Models,Network model,Resting State,Resting-state},
mendeley-tags = {Dynamic FC,Network Models,Resting State},
pages = {84--96},
title = {{Functional connectivity dynamically evolves on multiple time-scales over a static structural connectome: Models and mechanisms}},
url = {www.elsevier.com/locate/neuroimage},
volume = {160},
year = {2017}
}
